2024-01-20 19:06:23,352 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:06:23,353 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:06:23,362 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 19:06:23,363 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 19:06:23,363 - INFO -  * Restarting with stat
2024-01-20 19:06:23,623 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:06:23,624 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:06:23,632 - WARNING -  * Debugger is active!
2024-01-20 19:06:23,639 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:06:39,941 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 19:06:39,941 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:06:39,941 - INFO - Received local_dir: ./output
2024-01-20 19:06:39,941 - INFO - Received gitHubAccessToken: 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
2024-01-20 19:06:39,942 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:06:39,944 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 19:06:39,945 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpbbekutlj'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:06:44,334 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpbbekutlj'])'s unused stdout: 
2024-01-20 19:06:44,335 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:06:44,335 - INFO - Attempting to checkout branch: master
2024-01-20 19:06:44,335 - DEBUG - Popen(['git', 'fetch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpbbekutlj, stdin=None, shell=False, universal_newlines=False)
2024-01-20 19:06:44,749 - DEBUG - Popen(['git', 'checkout', 'master'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpbbekutlj, stdin=None, shell=False, universal_newlines=False)
2024-01-20 19:06:44,851 - INFO - Successfully checked out branch: master
2024-01-20 19:06:44,852 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpbbekutlj, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:06:44,858 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpbbekutlj, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:06:44,863 - INFO - Cleaning up temporary directory
2024-01-20 19:06:44,863 - INFO - Cloning repository: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:06:44,864 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpkqfxvvxf'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:06:49,875 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpkqfxvvxf'])'s unused stdout: 
2024-01-20 19:06:49,877 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpkqfxvvxf, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:06:49,884 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpkqfxvvxf, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:06:49,890 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 19:06:49,891 - DEBUG - Value of included_files: {}
2024-01-20 19:06:49,891 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 19:06:49,891 - INFO - Files to process: {}
2024-01-20 19:06:49,891 - INFO - Generated file paths: []
2024-01-20 19:06:49,891 - INFO - Final output paths: []
2024-01-20 19:06:49,891 - INFO - Cleaning up temporary directory
2024-01-20 19:06:50,049 - INFO - 127.0.0.1 - - [20/Jan/2024 19:06:50] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 19:14:43,342 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:14:43,343 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:14:43,354 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 19:14:43,355 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 19:14:43,355 - INFO -  * Restarting with stat
2024-01-20 19:14:43,612 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:14:43,613 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:14:43,621 - WARNING -  * Debugger is active!
2024-01-20 19:14:43,626 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:14:49,817 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 19:14:49,817 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:14:49,817 - INFO - Received local_dir: ./output
2024-01-20 19:14:49,817 - INFO - Received gitHubAccessToken: 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
2024-01-20 19:14:49,819 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:14:49,822 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 19:14:49,823 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpkyeff0se'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:14:54,258 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpkyeff0se'])'s unused stdout: 
2024-01-20 19:14:54,259 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:14:54,260 - INFO - Attempting to checkout branch: master
2024-01-20 19:14:54,260 - DEBUG - Popen(['git', 'fetch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpkyeff0se, stdin=None, shell=False, universal_newlines=False)
2024-01-20 19:14:54,535 - DEBUG - Popen(['git', 'checkout', 'master'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpkyeff0se, stdin=None, shell=False, universal_newlines=False)
2024-01-20 19:14:54,624 - INFO - Successfully checked out branch: master
2024-01-20 19:14:54,625 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpkyeff0se, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:14:54,630 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpkyeff0se, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:14:54,636 - INFO - Cleaning up temporary directory
2024-01-20 19:14:54,636 - INFO - Cloning repository: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:14:54,636 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpj9hnqzng'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:15:07,373 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpj9hnqzng'])'s unused stdout: 
2024-01-20 19:15:07,375 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpj9hnqzng, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:15:07,381 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpj9hnqzng, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:15:07,385 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 19:15:07,385 - DEBUG - Value of included_files: {}
2024-01-20 19:15:07,385 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 19:15:07,385 - INFO - Files to process: {}
2024-01-20 19:15:07,386 - INFO - Generated file paths: []
2024-01-20 19:15:07,386 - INFO - Final output paths: []
2024-01-20 19:15:07,386 - INFO - Cleaning up temporary directory
2024-01-20 19:15:07,546 - INFO - 127.0.0.1 - - [20/Jan/2024 19:15:07] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 19:20:39,641 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/app.py', reloading
2024-01-20 19:20:39,709 - INFO -  * Restarting with stat
2024-01-20 19:20:39,993 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:20:39,994 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:20:40,002 - WARNING -  * Debugger is active!
2024-01-20 19:20:40,006 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:21:44,199 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/app.py', reloading
2024-01-20 19:21:44,257 - INFO -  * Restarting with stat
2024-01-20 19:21:44,522 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:21:44,523 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:21:44,531 - WARNING -  * Debugger is active!
2024-01-20 19:21:44,536 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:22:04,223 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/app.py', reloading
2024-01-20 19:22:04,280 - INFO -  * Restarting with stat
2024-01-20 19:22:04,563 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:22:04,564 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:22:04,572 - WARNING -  * Debugger is active!
2024-01-20 19:22:04,578 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:22:20,632 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:22:20,633 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:22:20,642 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 19:22:20,643 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 19:22:20,643 - INFO -  * Restarting with stat
2024-01-20 19:22:20,899 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:22:20,900 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:22:20,907 - WARNING -  * Debugger is active!
2024-01-20 19:22:20,912 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:22:27,706 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 19:22:27,706 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:22:27,706 - INFO - Received local_dir: ./output
2024-01-20 19:22:27,706 - INFO - Received gitHubAccessToken: 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
2024-01-20 19:22:27,707 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:22:27,709 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 19:22:27,709 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpbfhv9_pg'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:22:33,419 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpbfhv9_pg'])'s unused stdout: 
2024-01-20 19:22:33,420 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:22:33,420 - INFO - Contents of the cloned repository: ['.DS_Store', 'requirements.txt', '__init__.py', 'README.md', 'logs', '.gitignore', 'execute_generate_uml.log', 'uml_generation.log', '.github', 'venv', '.git', 'main.log', 'src']
2024-01-20 19:22:33,421 - INFO - Cleaning up temporary directory
2024-01-20 19:22:33,421 - INFO - Cloning repository: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:22:33,421 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpnrnlm8d7'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:22:37,997 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpnrnlm8d7'])'s unused stdout: 
2024-01-20 19:22:37,999 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpnrnlm8d7, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:22:38,005 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpnrnlm8d7, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:22:38,010 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 19:22:38,010 - DEBUG - Value of included_files: {}
2024-01-20 19:22:38,010 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 19:22:38,010 - INFO - Files to process: {}
2024-01-20 19:22:38,010 - INFO - Generated file paths: []
2024-01-20 19:22:38,010 - INFO - Final output paths: []
2024-01-20 19:22:38,010 - INFO - Cleaning up temporary directory
2024-01-20 19:22:38,158 - ERROR - Error: name 'code' is not defined
2024-01-20 19:22:38,158 - INFO - 127.0.0.1 - - [20/Jan/2024 19:22:38] "[35m[1mPOST /generate-uml HTTP/1.1[0m" 500 -
2024-01-20 19:22:50,918 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/app.py', reloading
2024-01-20 19:22:50,978 - INFO -  * Restarting with stat
2024-01-20 19:22:51,265 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:22:51,266 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:22:51,274 - WARNING -  * Debugger is active!
2024-01-20 19:22:51,280 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:22:55,970 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:22:55,971 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:22:55,980 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 19:22:55,980 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 19:22:55,981 - INFO -  * Restarting with stat
2024-01-20 19:22:56,236 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:22:56,237 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:22:56,245 - WARNING -  * Debugger is active!
2024-01-20 19:22:56,250 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:23:00,209 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 19:23:00,209 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:23:00,209 - INFO - Received local_dir: ./output
2024-01-20 19:23:00,209 - INFO - Received gitHubAccessToken: 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
2024-01-20 19:23:00,210 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:23:00,212 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 19:23:00,213 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpltewl2rw'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:23:04,901 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpltewl2rw'])'s unused stdout: 
2024-01-20 19:23:04,903 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:23:04,903 - INFO - Contents of the cloned repository: ['.DS_Store', 'requirements.txt', '__init__.py', 'README.md', 'logs', '.gitignore', 'execute_generate_uml.log', 'uml_generation.log', '.github', 'venv', '.git', 'main.log', 'src']
2024-01-20 19:23:04,903 - INFO - Cleaning up temporary directory
2024-01-20 19:23:04,903 - INFO - Cloning repository: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:23:04,903 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp_nhmnihp'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:23:08,782 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp_nhmnihp'])'s unused stdout: 
2024-01-20 19:23:08,784 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp_nhmnihp, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:23:08,790 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp_nhmnihp, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:23:08,795 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 19:23:08,795 - DEBUG - Value of included_files: {}
2024-01-20 19:23:08,795 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 19:23:08,795 - INFO - Files to process: {}
2024-01-20 19:23:08,795 - INFO - Generated file paths: []
2024-01-20 19:23:08,795 - INFO - Final output paths: []
2024-01-20 19:23:08,795 - INFO - Cleaning up temporary directory
2024-01-20 19:23:08,950 - INFO - 127.0.0.1 - - [20/Jan/2024 19:23:08] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 19:23:29,321 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/app.py', reloading
2024-01-20 19:23:29,375 - INFO -  * Restarting with stat
2024-01-20 19:23:29,640 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:23:29,641 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:23:29,649 - WARNING -  * Debugger is active!
2024-01-20 19:23:29,655 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:26:11,297 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/code_to_uml.py', reloading
2024-01-20 19:26:11,360 - INFO -  * Restarting with stat
2024-01-20 19:26:11,633 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:26:11,634 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:26:11,643 - WARNING -  * Debugger is active!
2024-01-20 19:26:11,648 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:26:19,435 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:26:19,436 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:26:19,446 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 19:26:19,446 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 19:26:19,446 - INFO -  * Restarting with stat
2024-01-20 19:26:19,703 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:26:19,704 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:26:19,712 - WARNING -  * Debugger is active!
2024-01-20 19:26:19,718 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:26:24,391 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 19:26:24,392 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:26:24,392 - INFO - Received local_dir: ./output
2024-01-20 19:26:24,392 - INFO - Received gitHubAccessToken: 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
2024-01-20 19:26:24,393 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:26:24,395 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 19:26:24,395 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpzbjl28j2'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:26:29,634 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpzbjl28j2'])'s unused stdout: 
2024-01-20 19:26:29,635 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:26:29,635 - INFO - Contents of the cloned repository: ['.DS_Store', 'requirements.txt', '__init__.py', 'README.md', 'logs', '.gitignore', 'execute_generate_uml.log', 'uml_generation.log', '.github', 'venv', '.git', 'main.log', 'src']
2024-01-20 19:26:29,635 - INFO - Attempting to checkout branch: master
2024-01-20 19:26:29,636 - DEBUG - Popen(['git', 'fetch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpzbjl28j2, stdin=None, shell=False, universal_newlines=False)
2024-01-20 19:26:29,949 - DEBUG - Popen(['git', 'checkout', 'master'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpzbjl28j2, stdin=None, shell=False, universal_newlines=False)
2024-01-20 19:26:30,043 - INFO - Successfully checked out branch: master
2024-01-20 19:26:30,043 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpzbjl28j2, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:26:30,049 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpzbjl28j2, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:26:30,054 - ERROR - Error: process_request() takes 1 positional argument but 2 were given
2024-01-20 19:26:30,054 - INFO - 127.0.0.1 - - [20/Jan/2024 19:26:30] "[35m[1mPOST /generate-uml HTTP/1.1[0m" 500 -
2024-01-20 19:31:04,270 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/app.py', reloading
2024-01-20 19:31:04,330 - INFO -  * Restarting with stat
2024-01-20 19:31:04,608 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:31:04,609 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:31:04,617 - WARNING -  * Debugger is active!
2024-01-20 19:31:04,622 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:31:14,957 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:31:14,958 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:31:14,967 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 19:31:14,967 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 19:31:14,968 - INFO -  * Restarting with stat
2024-01-20 19:31:15,223 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:31:15,224 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:31:15,232 - WARNING -  * Debugger is active!
2024-01-20 19:31:15,237 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:31:24,442 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 19:31:24,442 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:31:24,443 - INFO - Received local_dir: ./output
2024-01-20 19:31:24,443 - INFO - Received gitHubAccessToken: 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
2024-01-20 19:31:24,443 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:31:24,446 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 19:31:24,447 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpufc_pf4i'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:31:29,434 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpufc_pf4i'])'s unused stdout: 
2024-01-20 19:31:29,435 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:31:29,435 - INFO - Contents of the cloned repository: ['.DS_Store', 'requirements.txt', '__init__.py', 'README.md', 'logs', '.gitignore', 'execute_generate_uml.log', 'uml_generation.log', '.github', 'venv', '.git', 'main.log', 'src']
2024-01-20 19:31:29,435 - INFO - Attempting to checkout branch: master
2024-01-20 19:31:29,435 - DEBUG - Popen(['git', 'fetch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpufc_pf4i, stdin=None, shell=False, universal_newlines=False)
2024-01-20 19:31:29,745 - DEBUG - Popen(['git', 'checkout', 'master'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpufc_pf4i, stdin=None, shell=False, universal_newlines=False)
2024-01-20 19:31:29,838 - INFO - Successfully checked out branch: master
2024-01-20 19:31:29,839 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpufc_pf4i, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:31:29,845 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpufc_pf4i, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:31:29,850 - INFO - Cleaning up temporary directory
2024-01-20 19:31:29,850 - INFO - Cloning repository: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:31:29,851 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpjdls_qbx'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:31:34,222 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpjdls_qbx'])'s unused stdout: 
2024-01-20 19:31:34,224 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpjdls_qbx, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:31:34,230 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpjdls_qbx, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:31:34,234 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 19:31:34,234 - DEBUG - Value of included_files: {}
2024-01-20 19:31:34,235 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 19:31:34,235 - INFO - Files to process: {}
2024-01-20 19:31:34,235 - INFO - Generated file paths: []
2024-01-20 19:31:34,235 - INFO - Final output paths: ([], '')
2024-01-20 19:31:34,235 - INFO - UML diagram saved at: []
2024-01-20 19:31:34,235 - INFO - UML diagram saved at: 
2024-01-20 19:31:34,235 - INFO - Cleaning up temporary directory
2024-01-20 19:31:34,385 - INFO - 127.0.0.1 - - [20/Jan/2024 19:31:34] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 19:35:18,830 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/app.py', reloading
2024-01-20 19:35:18,887 - INFO -  * Restarting with stat
2024-01-20 19:35:19,170 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:35:19,171 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:35:19,179 - WARNING -  * Debugger is active!
2024-01-20 19:35:19,185 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:35:23,402 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:35:23,403 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:35:23,413 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 19:35:23,413 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 19:35:23,413 - INFO -  * Restarting with stat
2024-01-20 19:35:23,669 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:35:23,670 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:35:23,677 - WARNING -  * Debugger is active!
2024-01-20 19:35:23,682 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:35:32,258 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 19:35:32,258 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:35:32,258 - INFO - Received local_dir: ./output
2024-01-20 19:35:32,258 - INFO - Received gitHubAccessToken: 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
2024-01-20 19:35:32,259 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:35:32,261 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 19:35:32,261 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpai7vxoeh'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:35:36,722 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpai7vxoeh'])'s unused stdout: 
2024-01-20 19:35:36,724 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:35:36,724 - INFO - Contents of the cloned repository: ['.DS_Store', 'requirements.txt', '__init__.py', 'README.md', 'logs', '.gitignore', 'execute_generate_uml.log', 'uml_generation.log', '.github', 'venv', '.git', 'main.log', 'src']
2024-01-20 19:35:36,725 - INFO - Cleaning up temporary directory
2024-01-20 19:35:36,725 - INFO - Cloning repository: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:35:36,725 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpgn_teuz6'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:35:43,242 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpgn_teuz6'])'s unused stdout: 
2024-01-20 19:35:43,244 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpgn_teuz6, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:35:43,250 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpgn_teuz6, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:35:43,254 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 19:35:43,255 - DEBUG - Value of included_files: {}
2024-01-20 19:35:43,255 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 19:35:43,255 - INFO - Files to process: {}
2024-01-20 19:35:43,255 - INFO - Generated file paths: []
2024-01-20 19:35:43,255 - INFO - Final output paths: ([], '')
2024-01-20 19:35:43,255 - INFO - UML diagram saved at: []
2024-01-20 19:35:43,255 - INFO - UML diagram saved at: 
2024-01-20 19:35:43,255 - INFO - Cleaning up temporary directory
2024-01-20 19:35:43,409 - INFO - 127.0.0.1 - - [20/Jan/2024 19:35:43] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 19:49:18,443 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/uml_from_repo.py', reloading
2024-01-20 19:49:18,510 - INFO -  * Restarting with stat
2024-01-20 19:49:18,774 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:49:18,774 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:49:18,782 - WARNING -  * Debugger is active!
2024-01-20 19:49:18,787 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:49:31,685 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:49:31,686 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:49:31,696 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 19:49:31,697 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 19:49:31,697 - INFO -  * Restarting with stat
2024-01-20 19:49:31,951 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:49:31,951 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:49:31,959 - WARNING -  * Debugger is active!
2024-01-20 19:49:31,964 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:49:38,540 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 19:49:38,540 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:49:38,540 - INFO - Received local_dir: ./output
2024-01-20 19:49:38,540 - INFO - Received gitHubAccessToken: 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
2024-01-20 19:49:38,542 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:49:38,544 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 19:49:38,545 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpssd6vdkj'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:49:43,344 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpssd6vdkj'])'s unused stdout: 
2024-01-20 19:49:43,346 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:49:43,346 - INFO - Contents of the cloned repository: ['.DS_Store', 'requirements.txt', '__init__.py', 'README.md', 'logs', '.gitignore', 'execute_generate_uml.log', 'uml_generation.log', '.github', 'venv', '.git', 'main.log', 'src']
2024-01-20 19:49:43,347 - INFO - Cleaning up temporary directory
2024-01-20 19:49:43,347 - INFO - Cloning repository: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:49:43,347 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp4re89e9f'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:49:48,290 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp4re89e9f'])'s unused stdout: 
2024-01-20 19:49:48,292 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp4re89e9f, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:49:48,298 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp4re89e9f, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:49:48,319 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 19:49:48,319 - DEBUG - Value of included_files: {}
2024-01-20 19:49:48,319 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 19:49:48,319 - INFO - Files to process: {}
2024-01-20 19:49:48,319 - INFO - Generated file paths: []
2024-01-20 19:49:48,319 - INFO - Final output paths: ([], '')
2024-01-20 19:49:48,319 - INFO - UML diagram saved at: []
2024-01-20 19:49:48,319 - INFO - UML diagram saved at: 
2024-01-20 19:49:48,319 - INFO - Cleaning up temporary directory
2024-01-20 19:49:48,477 - INFO - 127.0.0.1 - - [20/Jan/2024 19:49:48] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 19:51:36,839 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:51:36,840 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:51:36,849 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 19:51:36,849 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 19:51:36,850 - INFO -  * Restarting with stat
2024-01-20 19:51:37,104 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 19:51:37,105 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 19:51:37,113 - WARNING -  * Debugger is active!
2024-01-20 19:51:37,119 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 19:51:45,760 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 19:51:45,761 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:51:45,761 - INFO - Received local_dir: ./output
2024-01-20 19:51:45,761 - INFO - Received gitHubAccessToken: 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
2024-01-20 19:51:45,762 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:51:45,764 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 19:51:45,765 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpvi030e1h'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:51:50,464 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpvi030e1h'])'s unused stdout: 
2024-01-20 19:51:50,465 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 19:51:50,465 - INFO - Contents of the cloned repository: ['.DS_Store', 'requirements.txt', '__init__.py', 'README.md', 'logs', '.gitignore', 'execute_generate_uml.log', 'uml_generation.log', '.github', 'venv', '.git', 'main.log', 'src']
2024-01-20 19:51:50,465 - INFO - Cleaning up temporary directory
2024-01-20 19:51:50,466 - INFO - Cloning repository: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 19:51:50,466 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmprkzfgz_2'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 19:51:54,932 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmprkzfgz_2'])'s unused stdout: 
2024-01-20 19:51:54,934 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmprkzfgz_2, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:51:54,939 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmprkzfgz_2, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 19:51:54,960 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 19:51:54,960 - DEBUG - Value of included_files: {}
2024-01-20 19:51:54,960 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 19:51:54,960 - INFO - Files to process: {}
2024-01-20 19:51:54,960 - INFO - Generated file paths: []
2024-01-20 19:51:54,960 - INFO - Final output paths: ([], '')
2024-01-20 19:51:54,960 - INFO - UML diagram saved at: []
2024-01-20 19:51:54,960 - INFO - UML diagram saved at: 
2024-01-20 19:51:54,960 - INFO - Cleaning up temporary directory
2024-01-20 19:51:55,113 - INFO - 127.0.0.1 - - [20/Jan/2024 19:51:55] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 20:05:43,263 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/uml_from_repo.py', reloading
2024-01-20 20:05:43,324 - INFO -  * Restarting with stat
2024-01-20 20:05:43,608 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:05:43,609 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:05:43,617 - WARNING -  * Debugger is active!
2024-01-20 20:05:43,624 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:11:08,593 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/uml_from_repo.py', reloading
2024-01-20 20:11:08,658 - INFO -  * Restarting with stat
2024-01-20 20:11:08,957 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:11:08,958 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:11:08,967 - WARNING -  * Debugger is active!
2024-01-20 20:11:08,972 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:11:15,338 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:11:15,339 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:11:15,349 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 20:11:15,349 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 20:11:15,349 - INFO -  * Restarting with stat
2024-01-20 20:11:15,617 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:11:15,617 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:11:15,626 - WARNING -  * Debugger is active!
2024-01-20 20:11:15,631 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:11:20,107 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 20:11:20,108 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 20:11:20,108 - INFO - Received local_dir: ./output
2024-01-20 20:11:20,108 - INFO - Received gitHubAccessToken: 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
2024-01-20 20:11:20,108 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:11:20,111 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 20:11:20,112 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp6b5zvdg_'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 20:11:24,584 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp6b5zvdg_'])'s unused stdout: 
2024-01-20 20:11:24,585 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:11:24,585 - INFO - Contents of the cloned repository: ['.DS_Store', 'requirements.txt', '__init__.py', 'README.md', 'logs', '.gitignore', 'execute_generate_uml.log', 'uml_generation.log', '.github', 'venv', '.git', 'main.log', 'src']
2024-01-20 20:11:24,585 - INFO - Cleaning up temporary directory
2024-01-20 20:11:24,586 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:11:24,586 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpolen6soa'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 20:11:29,769 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpolen6soa'])'s unused stdout: 
2024-01-20 20:11:29,770 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:11:29,770 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpolen6soa, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 20:11:29,776 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpolen6soa, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 20:11:29,797 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 20:11:29,797 - DEBUG - Value of included_files: {}
2024-01-20 20:11:29,798 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 20:11:29,798 - INFO - Files to process: {}
2024-01-20 20:11:29,798 - INFO - Generated file paths: []
2024-01-20 20:11:29,798 - INFO - Final output paths: ([], '')
2024-01-20 20:11:29,798 - INFO - UML diagram saved at: []
2024-01-20 20:11:29,798 - INFO - UML diagram saved at: 
2024-01-20 20:11:29,798 - INFO - Cleaning up temporary directory
2024-01-20 20:11:29,945 - INFO - 127.0.0.1 - - [20/Jan/2024 20:11:29] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 20:16:42,592 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/uml_from_repo.py', reloading
2024-01-20 20:16:42,651 - INFO -  * Restarting with stat
2024-01-20 20:16:42,926 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:16:42,927 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:16:42,936 - WARNING -  * Debugger is active!
2024-01-20 20:16:42,942 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:16:54,607 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:16:54,607 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:16:54,617 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 20:16:54,618 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 20:16:54,618 - INFO -  * Restarting with stat
2024-01-20 20:16:54,878 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:16:54,879 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:16:54,888 - WARNING -  * Debugger is active!
2024-01-20 20:16:54,893 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:16:58,558 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 20:16:58,558 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 20:16:58,558 - INFO - Received local_dir: ./output
2024-01-20 20:16:58,558 - INFO - Received gitHubAccessToken: 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
2024-01-20 20:16:58,560 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:16:58,563 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 20:16:58,563 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpas95f0q6'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 20:17:03,094 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpas95f0q6'])'s unused stdout: 
2024-01-20 20:17:03,095 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:17:03,095 - INFO - Contents of the cloned repository: ['.DS_Store', 'requirements.txt', '__init__.py', 'README.md', 'logs', '.gitignore', 'execute_generate_uml.log', 'uml_generation.log', '.github', 'venv', '.git', 'main.log', 'src']
2024-01-20 20:17:03,096 - INFO - Cleaning up temporary directory
2024-01-20 20:17:03,096 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:17:03,096 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpwcmy8olf'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 20:17:07,689 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpwcmy8olf'])'s unused stdout: 
2024-01-20 20:17:07,690 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:17:07,691 - ERROR - Error during UML generation: name 'branch_name' is not defined
2024-01-20 20:17:07,691 - INFO - Cleaning up temporary directory
2024-01-20 20:17:07,836 - INFO - 127.0.0.1 - - [20/Jan/2024 20:17:07] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 20:19:48,666 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/uml_from_repo.py', reloading
2024-01-20 20:19:48,722 - INFO -  * Restarting with stat
2024-01-20 20:19:48,991 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:19:48,992 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:19:49,001 - WARNING -  * Debugger is active!
2024-01-20 20:19:49,005 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:22:18,079 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/uml_from_repo.py', reloading
2024-01-20 20:22:18,131 - INFO -  * Restarting with stat
2024-01-20 20:22:18,404 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:22:18,405 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:22:18,413 - WARNING -  * Debugger is active!
2024-01-20 20:22:18,419 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:22:23,590 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/uml_from_repo.py', reloading
2024-01-20 20:22:23,645 - INFO -  * Restarting with stat
2024-01-20 20:22:23,922 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:22:23,923 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:22:23,931 - WARNING -  * Debugger is active!
2024-01-20 20:22:23,937 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:22:30,251 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:22:30,252 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:22:30,262 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 20:22:30,262 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 20:22:30,263 - INFO -  * Restarting with stat
2024-01-20 20:22:30,519 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:22:30,520 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:22:30,528 - WARNING -  * Debugger is active!
2024-01-20 20:22:30,533 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:23:21,812 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 20:23:21,812 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 20:23:21,812 - INFO - Received local_dir: ./output
2024-01-20 20:23:21,812 - INFO - Received gitHubAccessToken: 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
2024-01-20 20:23:21,813 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:23:21,815 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 20:23:21,816 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpuwckklzw'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 20:23:26,140 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpuwckklzw'])'s unused stdout: 
2024-01-20 20:23:26,141 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:23:26,142 - INFO - Contents of the cloned repository: ['.DS_Store', 'requirements.txt', '__init__.py', 'README.md', 'logs', '.gitignore', 'execute_generate_uml.log', 'uml_generation.log', '.github', 'venv', '.git', 'main.log', 'src']
2024-01-20 20:23:26,142 - INFO - Cleaning up temporary directory
2024-01-20 20:23:26,142 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:23:26,142 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpi2vx16fa'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 20:23:31,993 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpi2vx16fa'])'s unused stdout: 
2024-01-20 20:23:31,994 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:23:31,995 - INFO - Attempting to checkout branch: master
2024-01-20 20:23:31,995 - DEBUG - Popen(['git', 'fetch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpi2vx16fa, stdin=None, shell=False, universal_newlines=False)
2024-01-20 20:23:32,235 - DEBUG - Popen(['git', 'checkout', 'master'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpi2vx16fa, stdin=None, shell=False, universal_newlines=False)
2024-01-20 20:23:32,336 - INFO - Successfully checked out branch: master
2024-01-20 20:23:32,337 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpi2vx16fa, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 20:23:32,343 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpi2vx16fa, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 20:23:32,365 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 20:23:32,365 - DEBUG - Value of included_files: {}
2024-01-20 20:23:32,365 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 20:23:32,366 - INFO - Files to process: {}
2024-01-20 20:23:32,366 - INFO - Generated file paths: []
2024-01-20 20:23:32,366 - INFO - Final output paths: ([], '')
2024-01-20 20:23:32,366 - INFO - UML diagram saved at: []
2024-01-20 20:23:32,366 - INFO - UML diagram saved at: 
2024-01-20 20:23:32,366 - INFO - Cleaning up temporary directory
2024-01-20 20:23:32,518 - INFO - 127.0.0.1 - - [20/Jan/2024 20:23:32] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 20:32:16,150 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/uml_from_repo.py', reloading
2024-01-20 20:32:16,203 - INFO -  * Restarting with stat
2024-01-20 20:32:16,466 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:32:16,467 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:32:16,475 - WARNING -  * Debugger is active!
2024-01-20 20:32:16,480 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:32:33,390 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:32:33,391 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:32:33,400 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 20:32:33,401 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 20:32:33,401 - INFO -  * Restarting with stat
2024-01-20 20:32:33,654 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:32:33,655 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:32:33,663 - WARNING -  * Debugger is active!
2024-01-20 20:32:33,667 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:32:43,702 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 20:32:43,703 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 20:32:43,703 - INFO - Received local_dir: ./output
2024-01-20 20:32:43,703 - INFO - Received gitHubAccessToken: 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
2024-01-20 20:32:43,704 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:32:43,706 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 20:32:43,707 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp825eem3e'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 20:32:47,156 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp825eem3e'])'s unused stdout: 
2024-01-20 20:32:47,159 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:32:47,159 - INFO - Contents of the cloned repository: ['.DS_Store', 'requirements.txt', '__init__.py', 'README.md', 'logs', '.gitignore', 'execute_generate_uml.log', 'uml_generation.log', '.github', 'venv', '.git', 'main.log', 'src']
2024-01-20 20:32:47,159 - INFO - Cleaning up temporary directory
2024-01-20 20:32:47,159 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:32:47,159 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpg0i_4v3d'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 20:32:51,291 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpg0i_4v3d'])'s unused stdout: 
2024-01-20 20:32:51,293 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:32:51,293 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpg0i_4v3d, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 20:32:51,301 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpg0i_4v3d, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 20:32:51,330 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 20:32:51,330 - DEBUG - Value of included_files: {}
2024-01-20 20:32:51,330 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 20:32:51,331 - INFO - Files to process: {}
2024-01-20 20:32:51,331 - INFO - Generated file paths: []
2024-01-20 20:32:51,331 - INFO - Final output paths: ([], '')
2024-01-20 20:32:51,331 - INFO - UML diagram saved at: []
2024-01-20 20:32:51,331 - INFO - UML diagram saved at: 
2024-01-20 20:32:51,331 - INFO - Cleaning up temporary directory
2024-01-20 20:32:51,489 - INFO - 127.0.0.1 - - [20/Jan/2024 20:32:51] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 20:37:48,904 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/uml_from_repo.py', reloading
2024-01-20 20:37:48,958 - INFO -  * Restarting with stat
2024-01-20 20:37:49,241 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:37:49,242 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:37:49,250 - WARNING -  * Debugger is active!
2024-01-20 20:37:49,256 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:46:07,516 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:46:07,517 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:46:07,526 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 20:46:07,527 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 20:46:07,527 - INFO -  * Restarting with stat
2024-01-20 20:46:07,781 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:46:07,782 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:46:07,789 - WARNING -  * Debugger is active!
2024-01-20 20:46:07,794 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:46:18,891 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 20:46:18,891 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 20:46:18,891 - INFO - Received local_dir: ./output
2024-01-20 20:46:18,891 - INFO - Received gitHubAccessToken: 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
2024-01-20 20:46:18,892 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:46:18,895 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 20:46:18,896 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp3s3khqlm'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 20:46:24,091 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp3s3khqlm'])'s unused stdout: 
2024-01-20 20:46:24,093 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:46:24,093 - INFO - Contents of the cloned repository: ['.DS_Store', 'requirements.txt', '__init__.py', 'README.md', 'logs', '.gitignore', 'execute_generate_uml.log', 'uml_generation.log', '.github', 'venv', '.git', 'main.log', 'src']
2024-01-20 20:46:24,093 - INFO - Cleaning up temporary directory
2024-01-20 20:46:24,093 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:46:24,093 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp2g9xsu3h'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 20:46:28,037 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp2g9xsu3h'])'s unused stdout: 
2024-01-20 20:46:28,038 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:46:28,039 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp2g9xsu3h, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 20:46:28,044 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp2g9xsu3h, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 20:46:28,066 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 20:46:28,067 - DEBUG - Value of included_files: {}
2024-01-20 20:46:28,067 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 20:46:28,067 - INFO - Files to process: {}
2024-01-20 20:46:28,067 - INFO - Generated file paths: []
2024-01-20 20:46:28,067 - INFO - Final output paths: ([], '')
2024-01-20 20:46:28,067 - INFO - UML diagram saved at: []
2024-01-20 20:46:28,067 - INFO - UML diagram saved at: 
2024-01-20 20:46:28,067 - INFO - Cleaning up temporary directory
2024-01-20 20:46:28,226 - INFO - 127.0.0.1 - - [20/Jan/2024 20:46:28] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 20:52:32,883 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/uml_from_repo.py', reloading
2024-01-20 20:52:32,946 - INFO -  * Restarting with stat
2024-01-20 20:52:33,218 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:52:33,219 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:52:33,227 - WARNING -  * Debugger is active!
2024-01-20 20:52:33,233 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:52:42,313 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:52:42,314 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:52:42,324 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 20:52:42,324 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 20:52:42,324 - INFO -  * Restarting with stat
2024-01-20 20:52:42,583 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 20:52:42,584 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 20:52:42,592 - WARNING -  * Debugger is active!
2024-01-20 20:52:42,597 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 20:52:46,235 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 20:52:46,235 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 20:52:46,235 - INFO - Received local_dir: ./output
2024-01-20 20:52:46,235 - INFO - Received gitHubAccessToken: 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
2024-01-20 20:52:46,236 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:52:46,238 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 20:52:46,239 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpwuv96fws'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 20:52:50,910 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpwuv96fws'])'s unused stdout: 
2024-01-20 20:52:50,913 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:52:50,913 - INFO - Contents of the cloned repository: ['.DS_Store', 'requirements.txt', '__init__.py', 'README.md', 'logs', '.gitignore', 'execute_generate_uml.log', 'uml_generation.log', '.github', 'venv', '.git', 'main.log', 'src']
2024-01-20 20:52:50,913 - INFO - Cleaning up temporary directory
2024-01-20 20:52:50,913 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:52:50,914 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpl6lanf6n'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 20:52:56,195 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpl6lanf6n'])'s unused stdout: 
2024-01-20 20:52:56,196 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 20:52:56,197 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpl6lanf6n, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 20:52:56,202 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpl6lanf6n, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 20:52:56,225 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 20:52:56,226 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/generate_uml_diagram.py': 'import os\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport openai\nimport logging\nfrom logging import handlers  \nfrom openai_api import OpenAIAPI \nfrom routes.retrieve_code import retrieve_code\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_filename = \'uml_generation.log\'\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n# Assume OPENAI_API_KEY is set in the environment variables\nopenai.api_key = os.getenv("OPENAI_API_KEY")\n\ndef process_uml_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = "./output"\n    github_access_token = data.get(\'gitHubAccessToken\')\n    if not git_repo_url or not output_directory or not github_access_token:\n        logging.error("Missing required parameters")\n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = tempfile.mkdtemp()\n\n        # Clone the repository\n        logging.info(f"Cloning repository: {git_repo_url}")\n        repo = git.Repo.clone_from(git_repo_url, temp_dir, github_access_token)\n        \n        # Load the config\n        with open(\'config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        # Create a new object with the files to include\n        files_to_include = {}\n        for file in repo.tree():\n            if file.path in config[\'include\']:\n                with open(file.abspath, \'r\') as f:\n                    files_to_include[file.path] = f.read()\n\n        logging.debug(f"Type of files_to_include: {type(files_to_include)}")  # Debugging statement\n        logging.debug(f"Value of files_to_include: {files_to_include}")  # Debugging statement\n\n        uml_code = generate_uml_content(files_to_include)\n\n        # Save the UML diagram to a file\n        logging.info(f"Saving UML diagram to {output_directory}")\n        final_output_path = api.save_uml_diagram(uml_code, output_directory)\n        logging.info(f"UML diagram saved at: {final_output_path}")  # Log the path where the UML diagram was saved\n\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Path": final_output_path\n            }\n        }, 200\n\n    except Exception as e:\n        logging.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logging.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n\ndef generate_uml_content(files):\n    uml_code = ""\n    for file_path, code in files.items():\n        # Call OpenAI API to generate UML diagram for each file\n        logging.info(f"Calling OpenAI API to generate UML diagram for {file_path}")\n        uml_code_for_file = api.generate_uml_diagram(code)\n        logging.info(f"Received UML code for {file_path}: {uml_code_for_file}")  # Log the UML code received for each file\n        if not uml_code_for_file or "UML generation failed" in uml_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        uml_code += uml_code_for_file\n    return uml_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        return repo\n    except Exception as e:\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        files_to_include = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        files_to_include[file.path] = f.read()\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n\n        return files_to_include\n    except Exception as e:\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport tempfile\nimport logging\nfrom dotenv import load_dotenv\n\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token in the config data\nconfig_data['gitHubAccessToken'] = github_token\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')\n"}
2024-01-20 20:52:56,226 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 20:52:56,226 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/generate_uml_diagram.py': 'import os\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport openai\nimport logging\nfrom logging import handlers  \nfrom openai_api import OpenAIAPI \nfrom routes.retrieve_code import retrieve_code\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_filename = \'uml_generation.log\'\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n# Assume OPENAI_API_KEY is set in the environment variables\nopenai.api_key = os.getenv("OPENAI_API_KEY")\n\ndef process_uml_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = "./output"\n    github_access_token = data.get(\'gitHubAccessToken\')\n    if not git_repo_url or not output_directory or not github_access_token:\n        logging.error("Missing required parameters")\n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = tempfile.mkdtemp()\n\n        # Clone the repository\n        logging.info(f"Cloning repository: {git_repo_url}")\n        repo = git.Repo.clone_from(git_repo_url, temp_dir, github_access_token)\n        \n        # Load the config\n        with open(\'config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        # Create a new object with the files to include\n        files_to_include = {}\n        for file in repo.tree():\n            if file.path in config[\'include\']:\n                with open(file.abspath, \'r\') as f:\n                    files_to_include[file.path] = f.read()\n\n        logging.debug(f"Type of files_to_include: {type(files_to_include)}")  # Debugging statement\n        logging.debug(f"Value of files_to_include: {files_to_include}")  # Debugging statement\n\n        uml_code = generate_uml_content(files_to_include)\n\n        # Save the UML diagram to a file\n        logging.info(f"Saving UML diagram to {output_directory}")\n        final_output_path = api.save_uml_diagram(uml_code, output_directory)\n        logging.info(f"UML diagram saved at: {final_output_path}")  # Log the path where the UML diagram was saved\n\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Path": final_output_path\n            }\n        }, 200\n\n    except Exception as e:\n        logging.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logging.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n\ndef generate_uml_content(files):\n    uml_code = ""\n    for file_path, code in files.items():\n        # Call OpenAI API to generate UML diagram for each file\n        logging.info(f"Calling OpenAI API to generate UML diagram for {file_path}")\n        uml_code_for_file = api.generate_uml_diagram(code)\n        logging.info(f"Received UML code for {file_path}: {uml_code_for_file}")  # Log the UML code received for each file\n        if not uml_code_for_file or "UML generation failed" in uml_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        uml_code += uml_code_for_file\n    return uml_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        return repo\n    except Exception as e:\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        files_to_include = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        files_to_include[file.path] = f.read()\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n\n        return files_to_include\n    except Exception as e:\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport tempfile\nimport logging\nfrom dotenv import load_dotenv\n\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token in the config data\nconfig_data['gitHubAccessToken'] = github_token\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')\n"}
2024-01-20 20:52:56,226 - INFO - Processing file: src/routes/__init__.py
2024-01-20 20:52:56,226 - INFO - UML code generated for src/routes/__init__.py: 
2024-01-20 20:52:56,226 - ERROR - Failed to generate UML diagram for src/routes/__init__.py
2024-01-20 20:52:56,226 - ERROR - Error during UML generation: Failed to generate UML diagram for src/routes/__init__.py
2024-01-20 20:52:56,226 - INFO - Cleaning up temporary directory
2024-01-20 20:52:56,386 - INFO - 127.0.0.1 - - [20/Jan/2024 20:52:56] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 21:06:14,219 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/code_to_uml.py', reloading
2024-01-20 21:06:14,280 - INFO -  * Restarting with stat
2024-01-20 21:06:14,551 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:06:14,552 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 21:06:14,561 - WARNING -  * Debugger is active!
2024-01-20 21:06:14,566 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 21:07:01,706 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:07:01,707 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 21:07:01,716 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 21:07:01,716 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 21:07:01,717 - INFO -  * Restarting with stat
2024-01-20 21:07:01,969 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:07:01,970 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 21:07:01,978 - WARNING -  * Debugger is active!
2024-01-20 21:07:01,983 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 21:07:10,652 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 21:07:10,652 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 21:07:10,652 - INFO - Received local_dir: ./output
2024-01-20 21:07:10,653 - INFO - Received gitHubAccessToken: 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
2024-01-20 21:07:10,653 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 21:07:10,655 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 21:07:10,656 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmprah9fq_5'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 21:07:16,648 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmprah9fq_5'])'s unused stdout: 
2024-01-20 21:07:16,650 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 21:07:16,650 - INFO - Contents of the cloned repository: ['.DS_Store', 'requirements.txt', 'output', '__init__.py', 'README.md', 'logs', '.gitignore', '.github', 'venv', '.git', 'src']
2024-01-20 21:07:16,650 - INFO - Cleaning up temporary directory
2024-01-20 21:07:16,650 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 21:07:16,650 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmppzv3twqm'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 21:07:21,380 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmppzv3twqm'])'s unused stdout: 
2024-01-20 21:07:21,381 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 21:07:21,382 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmppzv3twqm, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 21:07:21,387 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmppzv3twqm, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 21:07:21,410 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 21:07:21,411 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n# code_to_uml.py\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-20 21:07:21,411 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 21:07:21,411 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n# code_to_uml.py\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-20 21:07:21,411 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-20 21:07:21,411 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-20 21:07:21,411 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

# code_to_uml.py
def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        logging.in
2024-01-20 21:07:21,413 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n# code_to_uml.py\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        logging.in', 'max_tokens': 1024}}
2024-01-20 21:07:21,430 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:07:21,510 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105691150>
2024-01-20 21:07:21,510 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105599b50> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:07:21,551 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10a310ad0>
2024-01-20 21:07:21,552 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:07:21,552 - DEBUG - send_request_headers.complete
2024-01-20 21:07:21,552 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 21:07:21,552 - DEBUG - send_request_body.complete
2024-01-20 21:07:21,553 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:07:21,890 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 03:07:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'86'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'712220cdab056f85b2b80cd89d41b26b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=z66C3rveUareJVjOQB8ZdR9p41KFuDB455gxQKzuVQc-1705806441-1-AZ6lKer3PTJTffuQxlY5+eXsgok6Krz2Vauq6B7HGzs8wOlDLrbbJ+zRHcyH994kIKJoCjMSFwKBN0ow8/8IIA8=; path=/; expires=Sun, 21-Jan-24 03:37:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=_bnaSTamA9npLqmsL9ywGSwCwQPqy6XKBIZ2zLLo4fk-1705806441880-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848c58b43f2c4503-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:07:21,895 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 21:07:21,896 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:07:21,896 - DEBUG - receive_response_body.complete
2024-01-20 21:07:21,897 - DEBUG - response_closed.started
2024-01-20 21:07:21,897 - DEBUG - response_closed.complete
2024-01-20 21:07:21,897 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 21:07:21,902 - ERROR - Error during UML generation: 'Completion' object has no attribute 'data'
2024-01-20 21:07:21,902 - INFO - Cleaning up temporary directory
2024-01-20 21:07:22,072 - INFO - 127.0.0.1 - - [20/Jan/2024 21:07:22] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 21:15:48,588 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/app.py', reloading
2024-01-20 21:15:48,643 - INFO -  * Restarting with stat
2024-01-20 21:15:48,923 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:15:48,924 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 21:15:48,933 - WARNING -  * Debugger is active!
2024-01-20 21:15:48,938 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 21:15:56,479 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:15:56,480 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 21:15:56,490 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 21:15:56,490 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 21:15:56,490 - INFO -  * Restarting with stat
2024-01-20 21:15:56,743 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:15:56,744 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 21:15:56,752 - WARNING -  * Debugger is active!
2024-01-20 21:15:56,757 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 21:16:04,929 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 21:16:04,929 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 21:16:04,929 - INFO - Received local_dir: ./output
2024-01-20 21:16:04,929 - INFO - Received gitHubAccessToken: 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
2024-01-20 21:16:04,930 - INFO - Cleaning up temporary directory
2024-01-20 21:16:04,930 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 21:16:04,933 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 21:16:04,933 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpa8_u0zmr'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 21:16:11,009 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpa8_u0zmr'])'s unused stdout: 
2024-01-20 21:16:11,011 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 21:16:11,011 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpa8_u0zmr, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 21:16:11,017 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpa8_u0zmr, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 21:16:11,041 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 21:16:11,041 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n# code_to_uml.py\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-20 21:16:11,041 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 21:16:11,041 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n# code_to_uml.py\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-20 21:16:11,042 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-20 21:16:11,042 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-20 21:16:11,042 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

# code_to_uml.py
def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        logging.in
2024-01-20 21:16:11,043 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n# code_to_uml.py\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        logging.in', 'max_tokens': 1024}}
2024-01-20 21:16:11,056 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:16:11,128 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107984ad0>
2024-01-20 21:16:11,128 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1077a1b50> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:16:11,158 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107a1a250>
2024-01-20 21:16:11,158 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:16:11,159 - DEBUG - send_request_headers.complete
2024-01-20 21:16:11,159 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 21:16:11,159 - DEBUG - send_request_body.complete
2024-01-20 21:16:11,159 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:16:16,115 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 03:16:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4759'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'dfaf8edaa1de0afc4cd6f0338d397261'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9aoR2bNqPb6DOO4dUfagkT49jetl5rl5__QrM1YXiec-1705806976-1-AT9ozzNbTjQD5kkUUFgDzTzTWWcT+6nCza+7HtHRICKEfxQR3M/OKAvSQH3ydaO+1GzKcZ39ONR2Kjppx9fKcFo=; path=/; expires=Sun, 21-Jan-24 03:46:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=pyR4j62y5WYbHND88rmb0FnWmYr34LP43r20P5WUTRw-1705806976122-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848c65a25fad4578-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:16:16,116 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 21:16:16,117 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:16:16,117 - DEBUG - receive_response_body.complete
2024-01-20 21:16:16,117 - DEBUG - response_closed.started
2024-01-20 21:16:16,117 - DEBUG - response_closed.complete
2024-01-20 21:16:16,117 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 21:16:16,119 - ERROR - Error during UML generation: 'Completion' object has no attribute 'data'
2024-01-20 21:16:16,119 - INFO - Cleaning up temporary directory
2024-01-20 21:16:16,290 - INFO - 127.0.0.1 - - [20/Jan/2024 21:16:16] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 21:25:40,658 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/openai_api.py', reloading
2024-01-20 21:25:40,726 - INFO -  * Restarting with stat
2024-01-20 21:25:41,014 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:25:41,015 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 21:25:41,024 - WARNING -  * Debugger is active!
2024-01-20 21:25:41,029 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 21:25:50,352 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:25:50,353 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 21:25:50,363 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 21:25:50,363 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 21:25:50,363 - INFO -  * Restarting with stat
2024-01-20 21:25:50,616 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:25:50,617 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 21:25:50,625 - WARNING -  * Debugger is active!
2024-01-20 21:25:50,630 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 21:25:54,387 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 21:25:54,388 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 21:25:54,388 - INFO - Received local_dir: ./output
2024-01-20 21:25:54,388 - INFO - Received gitHubAccessToken: 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
2024-01-20 21:25:54,389 - INFO - Cleaning up temporary directory
2024-01-20 21:25:54,389 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 21:25:54,392 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 21:25:54,392 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpazbjj28b'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 21:25:58,834 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpazbjj28b'])'s unused stdout: 
2024-01-20 21:25:58,836 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 21:25:58,836 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpazbjj28b, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 21:25:58,842 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpazbjj28b, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 21:25:58,865 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 21:25:58,865 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n# code_to_uml.py\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-20 21:25:58,865 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 21:25:58,865 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n# code_to_uml.py\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-20 21:25:58,866 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-20 21:25:58,866 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-20 21:25:58,866 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

# code_to_uml.py
def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        logging.in
2024-01-20 21:25:58,867 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n# code_to_uml.py\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        logging.in', 'max_tokens': 1024}}
2024-01-20 21:25:58,879 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:25:58,936 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106691250>
2024-01-20 21:25:58,936 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106095b50> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:25:59,203 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10668fb90>
2024-01-20 21:25:59,203 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:25:59,204 - DEBUG - send_request_headers.complete
2024-01-20 21:25:59,204 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 21:25:59,205 - DEBUG - send_request_body.complete
2024-01-20 21:25:59,205 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:26:03,312 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 03:26:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4027'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'faf4322a8b0f2c03646626fd67884f82'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=uM3PjtmaJA.jlLngKrqkqWaAsVZEHOmo.YR172IfaKw-1705807563-1-AbZNwM4Cwz1BQgCBbCTffHAGwMGRvTcVXwtL69qJ4KbdHKM5if4N5B7PGVspSVmRXHmo44xTV53VlY7AdED3nyU=; path=/; expires=Sun, 21-Jan-24 03:56:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=84PxZO7lebHE.qTA_kyjTFRmq6N65RS5PNysjWxc0Uk-1705807563363-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848c73fd98f469ed-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:26:03,315 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 21:26:03,315 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:26:03,316 - DEBUG - receive_response_body.complete
2024-01-20 21:26:03,316 - DEBUG - response_closed.started
2024-01-20 21:26:03,316 - DEBUG - response_closed.complete
2024-01-20 21:26:03,316 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 21:26:03,319 - INFO - Received response from OpenAI: fo(f"Generating UML diagram for {file_path}")  # Log the file path
        file_paths.append(file_path)  # Store the file path in the list
        generated_code += api.generate(code)  # Generate code for the files and concatenate the results
    logging.info(f"Generated code: {generated_code}")  # Log the generated code
    api.create_diagram(generated_code, output_directory)  # Create a UML diagram using the API and the generated code

# main function
if __name__ == '__main__':
    # Define input files and output directory
    files = {
        'main.py': 'Code for the main function',
        'helper.py': 'Code for helper functions'
    }
    output_directory = 'diagrams'
    # Generate UML diagram for the files and save to output directory
    generate_content(files, output_directory)

@startuml

[*] --> code_to_uml

class code_to_uml.py {
+ api: OpenAIAPI
+ log_directory: String
+ log_filename: String
+ log_handler: RotatingFileHandler
+ log_formatter: Formatter
+ logger: logging
+ generate_content(): void
+ main(): void
}

code_to_uml.py --> OpenAIAPI
code_to_uml.py --> logging

class OpenAIAPI {
+ generate(): String
+ create_diagram(): void
}

class logging {
+ handlers: handlers
+ formatter: Formatter
logger: debug
info
}

code_to_uml.py --> main.py
code_to_uml.py --> helper.py

class main.py {
}

class helper.py {
}

main.py --> generate_content()
helper.py --> generate_content()

generate_content() --> logging
logging --> log_directory
logging --> log_filename
logging --> log_handler
logging --> log_formatter
logging --> logger
logger --> logging: debug, info
logging --> file_paths
logging --> generated_code
generate_content() --> api: create_diagram()
api --> generate()
generate() --> api: generate()
generate() --> code
generate() --> output
api --> create_diagram()
create_diagram() --> generated_code
create_diagram() --> output_directory

@enduml
2024-01-20 21:26:03,320 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

fo(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-20 21:26:03,322 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nfo(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-20 21:26:03,323 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:26:03,324 - DEBUG - send_request_headers.complete
2024-01-20 21:26:03,324 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 21:26:03,324 - DEBUG - send_request_body.complete
2024-01-20 21:26:03,324 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:26:06,271 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 03:26:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2831'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'd4b5037ca3fb3c42e0eb40ce998dfd10'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848c74178e1269ed-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:26:06,271 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 21:26:06,271 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:26:06,272 - DEBUG - receive_response_body.complete
2024-01-20 21:26:06,272 - DEBUG - response_closed.started
2024-01-20 21:26:06,272 - DEBUG - response_closed.complete
2024-01-20 21:26:06,272 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 21:26:06,273 - INFO - Received response from OpenAI: 

@startuml

class UMLGenerator {
    -generated_code: str
    -file_paths: list
    +fo(): void
    +generate_from_code(): str
    +save_generated_output(): str
    +file_name: str
    +final_output_path: str
    +logging: Logger
    +api: API
    +output_directory: str
    +file_path: str
    +generated_code_for_file: str
    +file_paths: list
}

UMLGenerator o-- Logger
UMLGenerator o-- API

class Logger {
    +info(): void
    +error(): void
}

class API {
    +generate_from_code(): str
    +save_generated_output(): str
}

class API {
    +file_path: str
}

class API {
    +generated_code_for_file: str
}

class API {
    +output_directory: str
}

class API {
    +final_output_path: str
}

class os {
    +basename(): str
}

UMLGenerator --> Logger: uses
UMLGenerator --> API: uses
UMLGenerator --> generated_code_for_file: aggregates
UMLGenerator --> file_paths: aggregates
UMLGenerator --> logging: uses
UMLGenerator --> output_directory: contains
UMLGenerator --> file_path: contains
UMLGenerator --> generated_code: aggregates

@enduml
2024-01-20 21:26:06,273 - INFO - UML code generated for src/routes/code_to_uml.py: fo(f"Generating UML diagram for {file_path}")  # Log the file path
        file_paths.append(file_path)  # Store the file path in the list
        generated_code += api.generate(code)  # Generate code for the files and concatenate the results
    logging.info(f"Generated code: {generated_code}")  # Log the generated code
    api.create_diagram(generated_code, output_directory)  # Create a UML diagram using the API and the generated code

# main function
if __name__ == '__main__':
    # Define input files and output directory
    files = {
        'main.py': 'Code for the main function',
        'helper.py': 'Code for helper functions'
    }
    output_directory = 'diagrams'
    # Generate UML diagram for the files and save to output directory
    generate_content(files, output_directory)

@startuml

[*] --> code_to_uml

class code_to_uml.py {
+ api: OpenAIAPI
+ log_directory: String
+ log_filename: String
+ log_handler: RotatingFileHandler
+ log_formatter: Formatter
+ logger: logging
+ generate_content(): void
+ main(): void
}

code_to_uml.py --> OpenAIAPI
code_to_uml.py --> logging

class OpenAIAPI {
+ generate(): String
+ create_diagram(): void
}

class logging {
+ handlers: handlers
+ formatter: Formatter
logger: debug
info
}

code_to_uml.py --> main.py
code_to_uml.py --> helper.py

class main.py {
}

class helper.py {
}

main.py --> generate_content()
helper.py --> generate_content()

generate_content() --> logging
logging --> log_directory
logging --> log_filename
logging --> log_handler
logging --> log_formatter
logging --> logger
logger --> logging: debug, info
logging --> file_paths
logging --> generated_code
generate_content() --> api: create_diagram()
api --> generate()
generate() --> api: generate()
generate() --> code
generate() --> output
api --> create_diagram()
create_diagram() --> generated_code
create_diagram() --> output_directory

@enduml@startuml

class UMLGenerator {
    -generated_code: str
    -file_paths: list
    +fo(): void
    +generate_from_code(): str
    +save_generated_output(): str
    +file_name: str
    +final_output_path: str
    +logging: Logger
    +api: API
    +output_directory: str
    +file_path: str
    +generated_code_for_file: str
    +file_paths: list
}

UMLGenerator o-- Logger
UMLGenerator o-- API

class Logger {
    +info(): void
    +error(): void
}

class API {
    +generate_from_code(): str
    +save_generated_output(): str
}

class API {
    +file_path: str
}

class API {
    +generated_code_for_file: str
}

class API {
    +output_directory: str
}

class API {
    +final_output_path: str
}

class os {
    +basename(): str
}

UMLGenerator --> Logger: uses
UMLGenerator --> API: uses
UMLGenerator --> generated_code_for_file: aggregates
UMLGenerator --> file_paths: aggregates
UMLGenerator --> logging: uses
UMLGenerator --> output_directory: contains
UMLGenerator --> file_path: contains
UMLGenerator --> generated_code: aggregates

@enduml
2024-01-20 21:26:06,273 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-20 21:26:06,273 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-20 21:26:06,274 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-20 21:26:06,274 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-20 21:26:06,275 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-20 21:26:06,275 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:26:06,276 - DEBUG - send_request_headers.complete
2024-01-20 21:26:06,276 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 21:26:06,276 - DEBUG - send_request_body.complete
2024-01-20 21:26:06,276 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:26:09,126 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 03:26:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2777'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'f58c491e08de8cd73076acdae27ad6e9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848c7429ce4769ed-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:26:09,128 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 21:26:09,129 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:26:09,130 - DEBUG - receive_response_body.complete
2024-01-20 21:26:09,130 - DEBUG - response_closed.started
2024-01-20 21:26:09,131 - DEBUG - response_closed.complete
2024-01-20 21:26:09,131 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 21:26:09,132 - INFO - Received response from OpenAI: 
        return True
    except Exception as e:
        logger.error(f"Error cloning repository: {repo_url} - {e}")
        return False


def retrieve_code(repo_url, temp_dir, access_token, dest_dir, branch='master'):
    # Clone the repository to a temporary directory
    cloned = clone_repo(repo_url, temp_dir, access_token)
    
    if cloned:
        try:
            repo = git.Repo(temp_dir)
            # Checkout the specified branch
            repo.git.checkout(branch)
            # Copy the files to the destination directory
            os.system(f'cp -r {temp_dir}/* {dest_dir}')
            logger.info(f"Successfully retrieved code from {repo_url}")
            return True
        except Exception as e:
            logger.error(f"Error retrieving code from {repo_url} - {e}")
            return False


@startuml

class GitManager {
    - repo_url : string
    - temp_dir : string
    - access_token : string
    - dest_dir : string
    - branch : string
    + clone_repo(repo_url, temp_dir, access_token) : boolean
    + retrieve_code(repo_url, temp_dir, access_token, dest_dir, branch='master') : boolean
}

note left of GitManager: Uses git\nlibrary

class git.Repo {
    + clone_from(repo_url, temp_dir) : git.Repo
    + git : GitCommandType
}

class os {
    + makedirs(directory, exist_ok=False) : None
    + system(command) : int
}

GitManager .. git.Repo : uses
GitManager .. os : uses

@enduml
2024-01-20 21:26:09,133 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-20 21:26:09,135 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-20 21:26:09,136 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:26:09,137 - DEBUG - send_request_headers.complete
2024-01-20 21:26:09,137 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 21:26:09,137 - DEBUG - send_request_body.complete
2024-01-20 21:26:09,137 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:26:13,271 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 03:26:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4012'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'cc8d66ea0ada852b07d03e32082760ed'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848c743baf6769ed-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:26:13,274 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 21:26:13,275 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:26:13,276 - DEBUG - receive_response_body.complete
2024-01-20 21:26:13,277 - DEBUG - response_closed.started
2024-01-20 21:26:13,277 - DEBUG - response_closed.complete
2024-01-20 21:26:13,278 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 21:26:13,281 - INFO - Received response from OpenAI:  if file.path.endswith('.py') and file.path not in ignore_list:  # Only include files that match the .py extension and are not in the ignore list
                included_files[file.path] = file.data_stream.read().decode("utf-8")  # Store the file path as the key and the code as the value
                
        return included_files  # Return the dictionary of included files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")



@startuml

class Repo {
    -path : str
    -tree : list
    -remote : str
    -branches : list
    +git : Repository
    +clone() : Repository
    +fetch() : Repository
    +checkout(branch_name : str) : void
    +tree() : list
}

class Logger {
    +error(message : str) : void
    +info(message : str) : void
}

class File {
    -path : str
    -data_stream : Stream
    +read() : str
}

class Config {
    -file_path : str
    -ignore_list : list
    -include_list : list
    +load() : dict
    +get_ignore_list() : list
    +get_include_list() : list
}

class CodeRetriever {
    -repo : Repo
    -branch_name : str
    +retrieve_code(repo : Repo, branch_name : str) : dict
}

CodeRetriever --> Repo : dependency
CodeRetriever --> Logger : dependency
CodeRetriever --> Config : dependency
Repo --> File : contains
Config --> File : contains

code {

CodeRetriever --> Logger : usage
CodeRetriever --> Repo : method call
Repo --> Logger : usage
Repo --> Config : method call
Repo --> File : method call
Repo --> Stream : method call

}

exception {
CodeRetriever --> ValueError : raise
CodeRetriever --> Exception : catch
Repo --> Exception : catch
}


@enduml
2024-01-20 21:26:13,283 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-20 21:26:13,284 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-20 21:26:13,285 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:26:13,286 - DEBUG - send_request_headers.complete
2024-01-20 21:26:13,286 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 21:26:13,286 - DEBUG - send_request_body.complete
2024-01-20 21:26:13,287 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:26:18,554 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 03:26:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5173'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'4d5a4449149089f9e27151ed5d2ce7e1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848c7455a8f169ed-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:26:18,557 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 21:26:18,557 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:26:18,558 - DEBUG - receive_response_body.complete
2024-01-20 21:26:18,558 - DEBUG - response_closed.started
2024-01-20 21:26:18,559 - DEBUG - response_closed.complete
2024-01-20 21:26:18,559 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 21:26:18,561 - INFO - Received response from OpenAI: 


@startuml
class FileUtils{
    -include_list: str[]
    -ignore_list: str[]
    -included_files: dict
    -logger: Logger
    
    +__init__(include_list: str[], ignore_list: str[])
    +retrieve_code(files: str[]): dict
}

class Logger{
    +info(msg: str)
    +warning(msg: str)
    +error(msg: str)
}

class File{
    -path: str
    -abspath: str
    
    +endswith(ext: str)
}

File <|-- FileUtils
Logger <|-- FileUtils

note top: "Main control flow" as MainControlFlow
MainControlFlow ..> FileUtils

MainControlFlow --> if any(file.path.endswith(ext) for ext in include_list)
MainControlFlow --> not any(ignored_file in file.path for ignored_file in ignore_list)

if any(file.path.endswith(ext) for ext in include_list) ..> File
not any(ignored_file in file.path for ignored_file in ignore_list) ..> File

if any(file.path.endswith(ext) for ext in include_list) ==> open
not any(ignored_file in file.path for ignored_file in ignore_list) ==> open

open --> with open(file.abspath, 'r') as f
open --> try..except

with open(file.abspath, 'r') as f --> included_files[file.path] = f.read()
try..except --> print
try..except --> logger.warning
try..except --> FileNotFoundError

print --> "Diagnostic print statement"

Logger <--: logger
logger ..> MainControlFlow

included_files[file.path] = f.read() ==> logger.info(f"Included file: {file.path}")

FileNotFoundError ..> print
FileNotFoundError ..> logger.warning

Logger <--: logger
logger ..> MainControlFlow

print --> "Ignoring missing file: {file.path}"
logger.warning(f"Ignoring missing file: {file.path}") ==> print

MainControlFlow --> return included_files

MainControlFlow --> Logger.error

Logger ..> MainControlFlow

note bottom: Catch all exceptions\nand raise ValueError as needed

Logger.error ==> raise ValueError(f"Failed to retrieve code: {str(e)}")
raise ValueError(f"Failed to retrieve code: {str(e)}") --> return included_files

MainControlFlow ..> Logger
Logger ..> raise: ValueError
Logger ..> except: Exception

note left: Calling code as follows:\ninclude_list = ['.py', '.txt']\nignore_list = ['tests', 'temp']\nfiles = ['test.py', 'index.txt', 'app.py', 'tests/utils.py', 'temp/index.txt']\n
note left: Include list: ['.py', '.txt']\nIgnore list: ['tests', 'temp']\nFiles: ['test.py', 'index.txt', 'app.py', 'tests/utils.py', 'temp/index.txt']
@enduml
2024-01-20 21:26:18,562 - INFO - UML code generated for src/routes/retrieve_code.py: return True
    except Exception as e:
        logger.error(f"Error cloning repository: {repo_url} - {e}")
        return False


def retrieve_code(repo_url, temp_dir, access_token, dest_dir, branch='master'):
    # Clone the repository to a temporary directory
    cloned = clone_repo(repo_url, temp_dir, access_token)
    
    if cloned:
        try:
            repo = git.Repo(temp_dir)
            # Checkout the specified branch
            repo.git.checkout(branch)
            # Copy the files to the destination directory
            os.system(f'cp -r {temp_dir}/* {dest_dir}')
            logger.info(f"Successfully retrieved code from {repo_url}")
            return True
        except Exception as e:
            logger.error(f"Error retrieving code from {repo_url} - {e}")
            return False


@startuml

class GitManager {
    - repo_url : string
    - temp_dir : string
    - access_token : string
    - dest_dir : string
    - branch : string
    + clone_repo(repo_url, temp_dir, access_token) : boolean
    + retrieve_code(repo_url, temp_dir, access_token, dest_dir, branch='master') : boolean
}

note left of GitManager: Uses git\nlibrary

class git.Repo {
    + clone_from(repo_url, temp_dir) : git.Repo
    + git : GitCommandType
}

class os {
    + makedirs(directory, exist_ok=False) : None
    + system(command) : int
}

GitManager .. git.Repo : uses
GitManager .. os : uses

@endumlif file.path.endswith('.py') and file.path not in ignore_list:  # Only include files that match the .py extension and are not in the ignore list
                included_files[file.path] = file.data_stream.read().decode("utf-8")  # Store the file path as the key and the code as the value
                
        return included_files  # Return the dictionary of included files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")



@startuml

class Repo {
    -path : str
    -tree : list
    -remote : str
    -branches : list
    +git : Repository
    +clone() : Repository
    +fetch() : Repository
    +checkout(branch_name : str) : void
    +tree() : list
}

class Logger {
    +error(message : str) : void
    +info(message : str) : void
}

class File {
    -path : str
    -data_stream : Stream
    +read() : str
}

class Config {
    -file_path : str
    -ignore_list : list
    -include_list : list
    +load() : dict
    +get_ignore_list() : list
    +get_include_list() : list
}

class CodeRetriever {
    -repo : Repo
    -branch_name : str
    +retrieve_code(repo : Repo, branch_name : str) : dict
}

CodeRetriever --> Repo : dependency
CodeRetriever --> Logger : dependency
CodeRetriever --> Config : dependency
Repo --> File : contains
Config --> File : contains

code {

CodeRetriever --> Logger : usage
CodeRetriever --> Repo : method call
Repo --> Logger : usage
Repo --> Config : method call
Repo --> File : method call
Repo --> Stream : method call

}

exception {
CodeRetriever --> ValueError : raise
CodeRetriever --> Exception : catch
Repo --> Exception : catch
}


@enduml@startuml
class FileUtils{
    -include_list: str[]
    -ignore_list: str[]
    -included_files: dict
    -logger: Logger
    
    +__init__(include_list: str[], ignore_list: str[])
    +retrieve_code(files: str[]): dict
}

class Logger{
    +info(msg: str)
    +warning(msg: str)
    +error(msg: str)
}

class File{
    -path: str
    -abspath: str
    
    +endswith(ext: str)
}

File <|-- FileUtils
Logger <|-- FileUtils

note top: "Main control flow" as MainControlFlow
MainControlFlow ..> FileUtils

MainControlFlow --> if any(file.path.endswith(ext) for ext in include_list)
MainControlFlow --> not any(ignored_file in file.path for ignored_file in ignore_list)

if any(file.path.endswith(ext) for ext in include_list) ..> File
not any(ignored_file in file.path for ignored_file in ignore_list) ..> File

if any(file.path.endswith(ext) for ext in include_list) ==> open
not any(ignored_file in file.path for ignored_file in ignore_list) ==> open

open --> with open(file.abspath, 'r') as f
open --> try..except

with open(file.abspath, 'r') as f --> included_files[file.path] = f.read()
try..except --> print
try..except --> logger.warning
try..except --> FileNotFoundError

print --> "Diagnostic print statement"

Logger <--: logger
logger ..> MainControlFlow

included_files[file.path] = f.read() ==> logger.info(f"Included file: {file.path}")

FileNotFoundError ..> print
FileNotFoundError ..> logger.warning

Logger <--: logger
logger ..> MainControlFlow

print --> "Ignoring missing file: {file.path}"
logger.warning(f"Ignoring missing file: {file.path}") ==> print

MainControlFlow --> return included_files

MainControlFlow --> Logger.error

Logger ..> MainControlFlow

note bottom: Catch all exceptions\nand raise ValueError as needed

Logger.error ==> raise ValueError(f"Failed to retrieve code: {str(e)}")
raise ValueError(f"Failed to retrieve code: {str(e)}") --> return included_files

MainControlFlow ..> Logger
Logger ..> raise: ValueError
Logger ..> except: Exception

note left: Calling code as follows:\ninclude_list = ['.py', '.txt']\nignore_list = ['tests', 'temp']\nfiles = ['test.py', 'index.txt', 'app.py', 'tests/utils.py', 'temp/index.txt']\n
note left: Include list: ['.py', '.txt']\nIgnore list: ['tests', 'temp']\nFiles: ['test.py', 'index.txt', 'app.py', 'tests/utils.py', 'temp/index.txt']
@enduml
2024-01-20 21:26:18,563 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-20 21:26:18,564 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-20 21:26:18,564 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-20 21:26:18,565 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-20 21:26:18,566 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-20 21:26:18,567 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:26:18,568 - DEBUG - send_request_headers.complete
2024-01-20 21:26:18,568 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 21:26:18,568 - DEBUG - send_request_body.complete
2024-01-20 21:26:18,569 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:26:18,748 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 03:26:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'44'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'5f5b96ebe0aa1866a428797a7080e4a5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848c7476eb6069ed-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:26:18,749 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 21:26:18,749 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:26:18,749 - DEBUG - receive_response_body.complete
2024-01-20 21:26:18,750 - DEBUG - response_closed.started
2024-01-20 21:26:18,750 - DEBUG - response_closed.complete
2024-01-20 21:26:18,750 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 21:26:18,751 - INFO - Received response from OpenAI: 
2024-01-20 21:26:18,752 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-20 21:26:18,753 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-20 21:26:18,754 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:26:18,755 - DEBUG - send_request_headers.complete
2024-01-20 21:26:18,755 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 21:26:18,755 - DEBUG - send_request_body.complete
2024-01-20 21:26:18,755 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:26:23,010 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 03:26:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4191'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'731dec0892a047c170690c4ca66f3e64'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848c7477cca169ed-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:26:23,012 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 21:26:23,013 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:26:23,014 - DEBUG - receive_response_body.complete
2024-01-20 21:26:23,014 - DEBUG - response_closed.started
2024-01-20 21:26:23,014 - DEBUG - response_closed.complete
2024-01-20 21:26:23,015 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 21:26:23,017 - INFO - Received response from OpenAI: )

        # Generate UML diagrams
        for diagram in config['diagrams']:
            plantuml = PlantUML()
            for file in diagram['files']:
                plantuml.process_file(file)
            plantuml.run(output_directory)

Class Diagram:
@startuml
class MainController
Entity thub_access_token
Entity branch_name
Entity git_repo_url
Entity output_directory

MainController -- thub_access_token : has
MainController -- branch_name : has
MainController -- git_repo_url : has
MainController -- output_directory : has

MainController : -logger
MainController : -temp_dir

note top of MainController
main controller
end note
@enduml

Sequence Diagram:
@startuml
hide footbox
title UML Generation

autonumber

actor User
boundary Controller
control MainController
database Database
participant TryCatch
participant config
participant clone_repo
participant PlantUML

User -> Controller: Submit request
activate Controller
Controller -> MainController: Get parameters
activate MainController
MainController -> MainController: Set default branch name
MainController -> MainController: Check for missing parameters
deactivate MainController
alt Parameters missing
MainController -> TryCatch: Log error
activate TryCatch
TryCatch --> Controller: Return error message
deactivate TryCatch
else Parameters valid
MainController -> TryCatch: Create temporary directory
activate TryCatch
alt Error creating directory
TryCatch --> MainController: Return error message
else Directory created successfully
TryCatch -> MainController: Clone repository
activate MainController
MainController -> Database: Get config file
activate Database
alt Config file not found
Database --> MainController: Return error message
else Config file found
Database -> MainController: Load config
MainController -> MainController: Generate UML diagrams
MainController -> MainController: Process each file in config
MainController -> PlantUML: Generate UML for each file
activate PlantUML
PlantUML -> output_directory: Save UML diagrams
plantuml run
deactivate PlantUML
MainController --> MainController: Return success message
end
deactivate MainController
@enduml
2024-01-20 21:26:23,017 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-20 21:26:23,019 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-20 21:26:23,021 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:26:23,021 - DEBUG - send_request_headers.complete
2024-01-20 21:26:23,021 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 21:26:23,022 - DEBUG - send_request_body.complete
2024-01-20 21:26:23,022 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:26:25,331 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 03:26:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2060'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'aa94e297d0ebc0e9a842975e87d4dc6e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848c74928d0169ed-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:26:25,334 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 21:26:25,335 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:26:25,337 - DEBUG - receive_response_body.complete
2024-01-20 21:26:25,338 - DEBUG - response_closed.started
2024-01-20 21:26:25,338 - DEBUG - response_closed.complete
2024-01-20 21:26:25,339 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 21:26:25,340 - INFO - Received response from OpenAI: t_from_files(included_files)
        
        
@startuml

class TraverseDirectories {
    -repo: Repository
    -temp_dir: String
    -config: Config
    +included_files: Map<String, String>
    +traverse_directories(Repo, String, Config): Map<String, String>
}

class Repository {
    +tree(): Tree
}

class Tree {
    +traverse(): Iterable<TreeItem>
}

class TreeItem {
    -type: String
    -path: String
}

class Config {
    -include: List<String>
}

class Logger {
    +debug(message: String): void
    +info(message: String): void
}

class GenerateContent {
    +generate_content_from_files(files: Map<String, String>): List<String>
}

TraverseDirectories --> Repository
TraverseDirectories --> Config
TraverseDirectories --> Logger
TraverseDirectories --> GenerateContent
TraverseDirectories o-- Map

Repository --> Tree

Tree --> TreeItem

GenerateContent <-- TraverseDirectories

GenerateContent --> Logger
GenerateContent o-- Map

Logger <-- TraverseDirectories
Logger <-- GenerateContent


Config <.. TraverseDirectories
Config <.. GenerateContent

@enduml
2024-01-20 21:26:25,341 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-20 21:26:25,343 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-20 21:26:25,345 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:26:25,345 - DEBUG - send_request_headers.complete
2024-01-20 21:26:25,345 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 21:26:25,346 - DEBUG - send_request_body.complete
2024-01-20 21:26:25,346 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:26:28,056 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 03:26:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2608'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'13cf384c947cad44e3e979d98d6de375'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848c74a10b2969ed-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:26:28,058 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 21:26:28,059 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:26:28,060 - DEBUG - receive_response_body.complete
2024-01-20 21:26:28,060 - DEBUG - response_closed.started
2024-01-20 21:26:28,061 - DEBUG - response_closed.complete
2024-01-20 21:26:28,061 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 21:26:28,064 - INFO - Received response from OpenAI:  @enduml

@startuml

class t {
  - included_files
  - output_directory
  + logger
  + final_output_paths
  + git_repo_url
  + temp_dir
  + e
  + t(included_files, output_directory)
  + generate_UML()
}

t..>logger: uses
t-->"output_paths": contains
t-->output_paths: "is a list"
t-->git_repo_url
t-->temp_dir: "contains"
t-->e: "contains"
t-->generate_UML: "calls"
output_paths..>"output_directory": in
git_repo_url-->"Repository": in
e-->500: "returns"
t-->500: "returns"
temp_dir-->"Cleaning up temporary directory": logs
e-->"Error during UML generation:": logs
output_paths-->"Log the path where each UML diagram was saved": logs

generate_UML-->"UML diagram saved at": logs
output_paths..>"Final output paths": in
t-->t(included_files, output_directory): "calls"
t-->{json}: returns
{json}-->"message": in
{json}-->"details": in
{json}-->"Repository": in
{json}-->"Output Paths": in
{json}-->t: returns

@enduml
2024-01-20 21:26:28,064 - INFO - UML code generated for src/routes/uml_from_repo.py: )

        # Generate UML diagrams
        for diagram in config['diagrams']:
            plantuml = PlantUML()
            for file in diagram['files']:
                plantuml.process_file(file)
            plantuml.run(output_directory)

Class Diagram:
@startuml
class MainController
Entity thub_access_token
Entity branch_name
Entity git_repo_url
Entity output_directory

MainController -- thub_access_token : has
MainController -- branch_name : has
MainController -- git_repo_url : has
MainController -- output_directory : has

MainController : -logger
MainController : -temp_dir

note top of MainController
main controller
end note
@enduml

Sequence Diagram:
@startuml
hide footbox
title UML Generation

autonumber

actor User
boundary Controller
control MainController
database Database
participant TryCatch
participant config
participant clone_repo
participant PlantUML

User -> Controller: Submit request
activate Controller
Controller -> MainController: Get parameters
activate MainController
MainController -> MainController: Set default branch name
MainController -> MainController: Check for missing parameters
deactivate MainController
alt Parameters missing
MainController -> TryCatch: Log error
activate TryCatch
TryCatch --> Controller: Return error message
deactivate TryCatch
else Parameters valid
MainController -> TryCatch: Create temporary directory
activate TryCatch
alt Error creating directory
TryCatch --> MainController: Return error message
else Directory created successfully
TryCatch -> MainController: Clone repository
activate MainController
MainController -> Database: Get config file
activate Database
alt Config file not found
Database --> MainController: Return error message
else Config file found
Database -> MainController: Load config
MainController -> MainController: Generate UML diagrams
MainController -> MainController: Process each file in config
MainController -> PlantUML: Generate UML for each file
activate PlantUML
PlantUML -> output_directory: Save UML diagrams
plantuml run
deactivate PlantUML
MainController --> MainController: Return success message
end
deactivate MainController
@endumlt_from_files(included_files)
        
        
@startuml

class TraverseDirectories {
    -repo: Repository
    -temp_dir: String
    -config: Config
    +included_files: Map<String, String>
    +traverse_directories(Repo, String, Config): Map<String, String>
}

class Repository {
    +tree(): Tree
}

class Tree {
    +traverse(): Iterable<TreeItem>
}

class TreeItem {
    -type: String
    -path: String
}

class Config {
    -include: List<String>
}

class Logger {
    +debug(message: String): void
    +info(message: String): void
}

class GenerateContent {
    +generate_content_from_files(files: Map<String, String>): List<String>
}

TraverseDirectories --> Repository
TraverseDirectories --> Config
TraverseDirectories --> Logger
TraverseDirectories --> GenerateContent
TraverseDirectories o-- Map

Repository --> Tree

Tree --> TreeItem

GenerateContent <-- TraverseDirectories

GenerateContent --> Logger
GenerateContent o-- Map

Logger <-- TraverseDirectories
Logger <-- GenerateContent


Config <.. TraverseDirectories
Config <.. GenerateContent

@enduml@enduml

@startuml

class t {
  - included_files
  - output_directory
  + logger
  + final_output_paths
  + git_repo_url
  + temp_dir
  + e
  + t(included_files, output_directory)
  + generate_UML()
}

t..>logger: uses
t-->"output_paths": contains
t-->output_paths: "is a list"
t-->git_repo_url
t-->temp_dir: "contains"
t-->e: "contains"
t-->generate_UML: "calls"
output_paths..>"output_directory": in
git_repo_url-->"Repository": in
e-->500: "returns"
t-->500: "returns"
temp_dir-->"Cleaning up temporary directory": logs
e-->"Error during UML generation:": logs
output_paths-->"Log the path where each UML diagram was saved": logs

generate_UML-->"UML diagram saved at": logs
output_paths..>"Final output paths": in
t-->t(included_files, output_directory): "calls"
t-->{json}: returns
{json}-->"message": in
{json}-->"details": in
{json}-->"Repository": in
{json}-->"Output Paths": in
{json}-->t: returns

@enduml
2024-01-20 21:26:28,065 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-20 21:26:28,066 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-20 21:26:28,066 - INFO - Skipping empty file: src/scripts/__init__.py
2024-01-20 21:26:28,066 - INFO - Processing file: src/scripts/execute_generate_uml.py
2024-01-20 21:26:28,067 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import json
import os
import requests
import logging
from logging import handlers
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure logging to write to a file
log_directory = '../../logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'execute_generate_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


# Configure logging
logging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))
# Configuration file path
config_file_path = os.path.join(cu
2024-01-20 21:26:28,068 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nimport json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(cu", 'max_tokens': 1024}}
2024-01-20 21:26:28,069 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:26:28,070 - DEBUG - send_request_headers.complete
2024-01-20 21:26:28,070 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 21:26:28,070 - DEBUG - send_request_body.complete
2024-01-20 21:26:28,070 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:26:32,761 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 03:26:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4595'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'dcdefdbe44fe7dab3efcf5212eaae406'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848c74b20f7969ed-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:26:32,763 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 21:26:32,765 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:26:32,766 - DEBUG - receive_response_body.complete
2024-01-20 21:26:32,766 - DEBUG - response_closed.started
2024-01-20 21:26:32,766 - DEBUG - response_closed.complete
2024-01-20 21:26:32,767 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 21:26:32,769 - INFO - Received response from OpenAI: rrent_dir, 'config.json')

@startuml

class Config
    Current_dir : string
    Config_file_path : string
    + get_config() : dict
    + update_config(config) : void

Config --> Current_dir
Config --> Config_file_path
Config --o logger


class Logger
    + log_handler : RotatingFileHandler
    + log_formatter : Formatter
    + logger : Logger
    + set_handler(handler) : void
    + set_formatter(formatter) : void
    + add_handler(handler) : void
    + set_level(level) : void
    + log(msg, level) : void

Logger --o log_handler
Logger --o log_formatter
Logger --o logger


class UmlGenerator
    + config : Config
    + logger : Logger
    + execute() : void
    + generate_uml() : void
    + save_file(content) : void

UmlGenerator --o config
UmlGenerator --o logger

class RequestManager
    + api_url : string
    + config : Config
    + logger : Logger
    + get_umls(concepts) : list
    + process_request(response) : dict
    + send_request(params) : json

RequestManager --o config
RequestManager --o logger

class DOTEnv
    + load_dotenv() : void

DOTEnv --o UmlGenerator

class JsonManager
    + config_file_path : string
    + get_data() : dict
    + update_data(new_data) : void

JsonManager --o Config
JsonManager --o Config_file_path

class OS
    + get_current_dir() : string

OS --o Config
OS --o Current_dir

class Requests
    + get(url) : json

Requests --o RequestManager


@enduml

The diagram shows the classes and their relationships within the code. The JSON and OS classes have been added based on their usage in the code. The DOTEnv class is dependent on the UmlGenerator class as it is used within its code. The Config class is also dependent on the Logger class for handling logging. The UmlGenerator class uses the Config and Logger classes for its functionality, while also using the RequestManager class to handle API requests. All of these classes are used within the main program. 
2024-01-20 21:26:32,769 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

rrent_dir, 'config.json')

# Read configuration from the JSON file
with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

# Retrieve the GitHub access token from environment variables
github_token = os.getenv('GITHUB_PAT')

# Endpoint URL
url = 'http://127.0.0.1:5000/generate-uml'

# Headers
headers = {
    'Content-Type': 'application/json'
}

# Update the GitHub access token and local directory in the config data
config_data['gitHubAccessToken'] = github_token
config_data['local_dir'] = os.path.join(current_dir, '../..', 'output')

# Log the JSON data being sent in the request
logging.info(f'Sending JSON data to {url}:')
logging.info(json.dumps(config_data, indent=2))

try:
    # Make the POST request
    response = requests.post(url, headers=headers, json=config_data)

    # Log the response from the server
    logging.info(f'Response from server ({url}):')
    logging.info(f'Status Code: {response.status_code}')
    logging.info(f'Response Text: {response.text}')

    #
2024-01-20 21:26:32,771 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nrrent_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    #", 'max_tokens': 1024}}
2024-01-20 21:26:32,772 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:26:32,773 - DEBUG - send_request_headers.complete
2024-01-20 21:26:32,773 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 21:26:32,773 - DEBUG - send_request_body.complete
2024-01-20 21:26:32,773 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:26:34,252 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 03:26:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'c832ec875efe36673b72b93ee90459ce'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848c74cf9cab69ed-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:26:34,253 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 21:26:34,253 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:26:34,253 - DEBUG - receive_response_body.complete
2024-01-20 21:26:34,253 - DEBUG - response_closed.started
2024-01-20 21:26:34,254 - DEBUG - response_closed.complete
2024-01-20 21:26:34,254 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 21:26:34,255 - INFO - Received response from OpenAI:  Check if the response was successful
    if response.status_code == 200:
        # Save the UML diagram to a file
        with open('diagram.png', 'wb') as f:
            f.write(response.content)
exc

@startuml
class ConfigData {
    - String gitHubAccessToken
    - String local_dir
}
class RequestSender {
    - String url
    - Map headers
    + json_data
    + response
}
note right of ConfigData: read from JSON file
ConfigData -- RequestSender : <m>
RequestSender --|> ConfigData : has-a
note bottom of RequestSender: uses url and headers
@enduml
2024-01-20 21:26:34,255 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

 Print the response from the server
    print(response.text)

    # Save the response to a file in the output directory
    output_dir = os.path.join(current_dir, '../..', 'output')
    os.makedirs(output_dir, exist_ok=True)
    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:
        json.dump(response.json(), output_file, indent=2)

except Exception as e:
    # Log any exceptions that occur
    logging.error(f'Error occurred: {str(e)}')
2024-01-20 21:26:34,257 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')", 'max_tokens': 1024}}
2024-01-20 21:26:34,257 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:26:34,258 - DEBUG - send_request_headers.complete
2024-01-20 21:26:34,258 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 21:26:34,258 - DEBUG - send_request_body.complete
2024-01-20 21:26:34,258 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:26:35,384 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 03:26:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1038'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'02c9654cb4c38a72e72113b254485424'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848c74d8af1a69ed-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:26:35,386 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 21:26:35,386 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:26:35,387 - DEBUG - receive_response_body.complete
2024-01-20 21:26:35,387 - DEBUG - response_closed.started
2024-01-20 21:26:35,387 - DEBUG - response_closed.complete
2024-01-20 21:26:35,387 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 21:26:35,389 - INFO - Received response from OpenAI: 

@startuml

class Client {
    - output_dir : String
    + main() : void
}

class Server {
    - response : String
    + getResponse() : String
}

Client o-- Server : makeRequest()
Client o-- Logger : Log exception
Client o-- os : outputDirExist()
Client o-- json : saveResponse()

class Logger {
    - ERROR : String
    + logError(e: Exception) : void
}

Client --> output_dir

@enduml
2024-01-20 21:26:35,389 - INFO - UML code generated for src/scripts/execute_generate_uml.py: rrent_dir, 'config.json')

@startuml

class Config
    Current_dir : string
    Config_file_path : string
    + get_config() : dict
    + update_config(config) : void

Config --> Current_dir
Config --> Config_file_path
Config --o logger


class Logger
    + log_handler : RotatingFileHandler
    + log_formatter : Formatter
    + logger : Logger
    + set_handler(handler) : void
    + set_formatter(formatter) : void
    + add_handler(handler) : void
    + set_level(level) : void
    + log(msg, level) : void

Logger --o log_handler
Logger --o log_formatter
Logger --o logger


class UmlGenerator
    + config : Config
    + logger : Logger
    + execute() : void
    + generate_uml() : void
    + save_file(content) : void

UmlGenerator --o config
UmlGenerator --o logger

class RequestManager
    + api_url : string
    + config : Config
    + logger : Logger
    + get_umls(concepts) : list
    + process_request(response) : dict
    + send_request(params) : json

RequestManager --o config
RequestManager --o logger

class DOTEnv
    + load_dotenv() : void

DOTEnv --o UmlGenerator

class JsonManager
    + config_file_path : string
    + get_data() : dict
    + update_data(new_data) : void

JsonManager --o Config
JsonManager --o Config_file_path

class OS
    + get_current_dir() : string

OS --o Config
OS --o Current_dir

class Requests
    + get(url) : json

Requests --o RequestManager


@enduml

The diagram shows the classes and their relationships within the code. The JSON and OS classes have been added based on their usage in the code. The DOTEnv class is dependent on the UmlGenerator class as it is used within its code. The Config class is also dependent on the Logger class for handling logging. The UmlGenerator class uses the Config and Logger classes for its functionality, while also using the RequestManager class to handle API requests. All of these classes are used within the main program.Check if the response was successful
    if response.status_code == 200:
        # Save the UML diagram to a file
        with open('diagram.png', 'wb') as f:
            f.write(response.content)
exc

@startuml
class ConfigData {
    - String gitHubAccessToken
    - String local_dir
}
class RequestSender {
    - String url
    - Map headers
    + json_data
    + response
}
note right of ConfigData: read from JSON file
ConfigData -- RequestSender : <m>
RequestSender --|> ConfigData : has-a
note bottom of RequestSender: uses url and headers
@enduml@startuml

class Client {
    - output_dir : String
    + main() : void
}

class Server {
    - response : String
    + getResponse() : String
}

Client o-- Server : makeRequest()
Client o-- Logger : Log exception
Client o-- os : outputDirExist()
Client o-- json : saveResponse()

class Logger {
    - ERROR : String
    + logError(e: Exception) : void
}

Client --> output_dir

@enduml
2024-01-20 21:26:35,389 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-20 21:26:35,390 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-20 21:26:35,390 - INFO - Generated file paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-20 21:26:35,390 - INFO - Final output paths: (['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml'], 'fo(f"Generating UML diagram for {file_path}")  # Log the file path\n        file_paths.append(file_path)  # Store the file path in the list\n        generated_code += api.generate(code)  # Generate code for the files and concatenate the results\n    logging.info(f"Generated code: {generated_code}")  # Log the generated code\n    api.create_diagram(generated_code, output_directory)  # Create a UML diagram using the API and the generated code\n\n# main function\nif __name__ == \'__main__\':\n    # Define input files and output directory\n    files = {\n        \'main.py\': \'Code for the main function\',\n        \'helper.py\': \'Code for helper functions\'\n    }\n    output_directory = \'diagrams\'\n    # Generate UML diagram for the files and save to output directory\n    generate_content(files, output_directory)\n\n@startuml\n\n[*] --> code_to_uml\n\nclass code_to_uml.py {\n+ api: OpenAIAPI\n+ log_directory: String\n+ log_filename: String\n+ log_handler: RotatingFileHandler\n+ log_formatter: Formatter\n+ logger: logging\n+ generate_content(): void\n+ main(): void\n}\n\ncode_to_uml.py --> OpenAIAPI\ncode_to_uml.py --> logging\n\nclass OpenAIAPI {\n+ generate(): String\n+ create_diagram(): void\n}\n\nclass logging {\n+ handlers: handlers\n+ formatter: Formatter\nlogger: debug\ninfo\n}\n\ncode_to_uml.py --> main.py\ncode_to_uml.py --> helper.py\n\nclass main.py {\n}\n\nclass helper.py {\n}\n\nmain.py --> generate_content()\nhelper.py --> generate_content()\n\ngenerate_content() --> logging\nlogging --> log_directory\nlogging --> log_filename\nlogging --> log_handler\nlogging --> log_formatter\nlogging --> logger\nlogger --> logging: debug, info\nlogging --> file_paths\nlogging --> generated_code\ngenerate_content() --> api: create_diagram()\napi --> generate()\ngenerate() --> api: generate()\ngenerate() --> code\ngenerate() --> output\napi --> create_diagram()\ncreate_diagram() --> generated_code\ncreate_diagram() --> output_directory\n\n@enduml@startuml\n\nclass UMLGenerator {\n    -generated_code: str\n    -file_paths: list\n    +fo(): void\n    +generate_from_code(): str\n    +save_generated_output(): str\n    +file_name: str\n    +final_output_path: str\n    +logging: Logger\n    +api: API\n    +output_directory: str\n    +file_path: str\n    +generated_code_for_file: str\n    +file_paths: list\n}\n\nUMLGenerator o-- Logger\nUMLGenerator o-- API\n\nclass Logger {\n    +info(): void\n    +error(): void\n}\n\nclass API {\n    +generate_from_code(): str\n    +save_generated_output(): str\n}\n\nclass API {\n    +file_path: str\n}\n\nclass API {\n    +generated_code_for_file: str\n}\n\nclass API {\n    +output_directory: str\n}\n\nclass API {\n    +final_output_path: str\n}\n\nclass os {\n    +basename(): str\n}\n\nUMLGenerator --> Logger: uses\nUMLGenerator --> API: uses\nUMLGenerator --> generated_code_for_file: aggregates\nUMLGenerator --> file_paths: aggregates\nUMLGenerator --> logging: uses\nUMLGenerator --> output_directory: contains\nUMLGenerator --> file_path: contains\nUMLGenerator --> generated_code: aggregates\n\n@endumlreturn True\n    except Exception as e:\n        logger.error(f"Error cloning repository: {repo_url} - {e}")\n        return False\n\n\ndef retrieve_code(repo_url, temp_dir, access_token, dest_dir, branch=\'master\'):\n    # Clone the repository to a temporary directory\n    cloned = clone_repo(repo_url, temp_dir, access_token)\n    \n    if cloned:\n        try:\n            repo = git.Repo(temp_dir)\n            # Checkout the specified branch\n            repo.git.checkout(branch)\n            # Copy the files to the destination directory\n            os.system(f\'cp -r {temp_dir}/* {dest_dir}\')\n            logger.info(f"Successfully retrieved code from {repo_url}")\n            return True\n        except Exception as e:\n            logger.error(f"Error retrieving code from {repo_url} - {e}")\n            return False\n\n\n@startuml\n\nclass GitManager {\n    - repo_url : string\n    - temp_dir : string\n    - access_token : string\n    - dest_dir : string\n    - branch : string\n    + clone_repo(repo_url, temp_dir, access_token) : boolean\n    + retrieve_code(repo_url, temp_dir, access_token, dest_dir, branch=\'master\') : boolean\n}\n\nnote left of GitManager: Uses git\\nlibrary\n\nclass git.Repo {\n    + clone_from(repo_url, temp_dir) : git.Repo\n    + git : GitCommandType\n}\n\nclass os {\n    + makedirs(directory, exist_ok=False) : None\n    + system(command) : int\n}\n\nGitManager .. git.Repo : uses\nGitManager .. os : uses\n\n@endumlif file.path.endswith(\'.py\') and file.path not in ignore_list:  # Only include files that match the .py extension and are not in the ignore list\n                included_files[file.path] = file.data_stream.read().decode("utf-8")  # Store the file path as the key and the code as the value\n                \n        return included_files  # Return the dictionary of included files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")\n\n\n\n@startuml\n\nclass Repo {\n    -path : str\n    -tree : list\n    -remote : str\n    -branches : list\n    +git : Repository\n    +clone() : Repository\n    +fetch() : Repository\n    +checkout(branch_name : str) : void\n    +tree() : list\n}\n\nclass Logger {\n    +error(message : str) : void\n    +info(message : str) : void\n}\n\nclass File {\n    -path : str\n    -data_stream : Stream\n    +read() : str\n}\n\nclass Config {\n    -file_path : str\n    -ignore_list : list\n    -include_list : list\n    +load() : dict\n    +get_ignore_list() : list\n    +get_include_list() : list\n}\n\nclass CodeRetriever {\n    -repo : Repo\n    -branch_name : str\n    +retrieve_code(repo : Repo, branch_name : str) : dict\n}\n\nCodeRetriever --> Repo : dependency\nCodeRetriever --> Logger : dependency\nCodeRetriever --> Config : dependency\nRepo --> File : contains\nConfig --> File : contains\n\ncode {\n\nCodeRetriever --> Logger : usage\nCodeRetriever --> Repo : method call\nRepo --> Logger : usage\nRepo --> Config : method call\nRepo --> File : method call\nRepo --> Stream : method call\n\n}\n\nexception {\nCodeRetriever --> ValueError : raise\nCodeRetriever --> Exception : catch\nRepo --> Exception : catch\n}\n\n\n@enduml@startuml\nclass FileUtils{\n    -include_list: str[]\n    -ignore_list: str[]\n    -included_files: dict\n    -logger: Logger\n    \n    +__init__(include_list: str[], ignore_list: str[])\n    +retrieve_code(files: str[]): dict\n}\n\nclass Logger{\n    +info(msg: str)\n    +warning(msg: str)\n    +error(msg: str)\n}\n\nclass File{\n    -path: str\n    -abspath: str\n    \n    +endswith(ext: str)\n}\n\nFile <|-- FileUtils\nLogger <|-- FileUtils\n\nnote top: "Main control flow" as MainControlFlow\nMainControlFlow ..> FileUtils\n\nMainControlFlow --> if any(file.path.endswith(ext) for ext in include_list)\nMainControlFlow --> not any(ignored_file in file.path for ignored_file in ignore_list)\n\nif any(file.path.endswith(ext) for ext in include_list) ..> File\nnot any(ignored_file in file.path for ignored_file in ignore_list) ..> File\n\nif any(file.path.endswith(ext) for ext in include_list) ==> open\nnot any(ignored_file in file.path for ignored_file in ignore_list) ==> open\n\nopen --> with open(file.abspath, \'r\') as f\nopen --> try..except\n\nwith open(file.abspath, \'r\') as f --> included_files[file.path] = f.read()\ntry..except --> print\ntry..except --> logger.warning\ntry..except --> FileNotFoundError\n\nprint --> "Diagnostic print statement"\n\nLogger <--: logger\nlogger ..> MainControlFlow\n\nincluded_files[file.path] = f.read() ==> logger.info(f"Included file: {file.path}")\n\nFileNotFoundError ..> print\nFileNotFoundError ..> logger.warning\n\nLogger <--: logger\nlogger ..> MainControlFlow\n\nprint --> "Ignoring missing file: {file.path}"\nlogger.warning(f"Ignoring missing file: {file.path}") ==> print\n\nMainControlFlow --> return included_files\n\nMainControlFlow --> Logger.error\n\nLogger ..> MainControlFlow\n\nnote bottom: Catch all exceptions\\nand raise ValueError as needed\n\nLogger.error ==> raise ValueError(f"Failed to retrieve code: {str(e)}")\nraise ValueError(f"Failed to retrieve code: {str(e)}") --> return included_files\n\nMainControlFlow ..> Logger\nLogger ..> raise: ValueError\nLogger ..> except: Exception\n\nnote left: Calling code as follows:\\ninclude_list = [\'.py\', \'.txt\']\\nignore_list = [\'tests\', \'temp\']\\nfiles = [\'test.py\', \'index.txt\', \'app.py\', \'tests/utils.py\', \'temp/index.txt\']\\n\nnote left: Include list: [\'.py\', \'.txt\']\\nIgnore list: [\'tests\', \'temp\']\\nFiles: [\'test.py\', \'index.txt\', \'app.py\', \'tests/utils.py\', \'temp/index.txt\']\n@enduml)\n\n        # Generate UML diagrams\n        for diagram in config[\'diagrams\']:\n            plantuml = PlantUML()\n            for file in diagram[\'files\']:\n                plantuml.process_file(file)\n            plantuml.run(output_directory)\n\nClass Diagram:\n@startuml\nclass MainController\nEntity thub_access_token\nEntity branch_name\nEntity git_repo_url\nEntity output_directory\n\nMainController -- thub_access_token : has\nMainController -- branch_name : has\nMainController -- git_repo_url : has\nMainController -- output_directory : has\n\nMainController : -logger\nMainController : -temp_dir\n\nnote top of MainController\nmain controller\nend note\n@enduml\n\nSequence Diagram:\n@startuml\nhide footbox\ntitle UML Generation\n\nautonumber\n\nactor User\nboundary Controller\ncontrol MainController\ndatabase Database\nparticipant TryCatch\nparticipant config\nparticipant clone_repo\nparticipant PlantUML\n\nUser -> Controller: Submit request\nactivate Controller\nController -> MainController: Get parameters\nactivate MainController\nMainController -> MainController: Set default branch name\nMainController -> MainController: Check for missing parameters\ndeactivate MainController\nalt Parameters missing\nMainController -> TryCatch: Log error\nactivate TryCatch\nTryCatch --> Controller: Return error message\ndeactivate TryCatch\nelse Parameters valid\nMainController -> TryCatch: Create temporary directory\nactivate TryCatch\nalt Error creating directory\nTryCatch --> MainController: Return error message\nelse Directory created successfully\nTryCatch -> MainController: Clone repository\nactivate MainController\nMainController -> Database: Get config file\nactivate Database\nalt Config file not found\nDatabase --> MainController: Return error message\nelse Config file found\nDatabase -> MainController: Load config\nMainController -> MainController: Generate UML diagrams\nMainController -> MainController: Process each file in config\nMainController -> PlantUML: Generate UML for each file\nactivate PlantUML\nPlantUML -> output_directory: Save UML diagrams\nplantuml run\ndeactivate PlantUML\nMainController --> MainController: Return success message\nend\ndeactivate MainController\n@endumlt_from_files(included_files)\n        \n        \n@startuml\n\nclass TraverseDirectories {\n    -repo: Repository\n    -temp_dir: String\n    -config: Config\n    +included_files: Map<String, String>\n    +traverse_directories(Repo, String, Config): Map<String, String>\n}\n\nclass Repository {\n    +tree(): Tree\n}\n\nclass Tree {\n    +traverse(): Iterable<TreeItem>\n}\n\nclass TreeItem {\n    -type: String\n    -path: String\n}\n\nclass Config {\n    -include: List<String>\n}\n\nclass Logger {\n    +debug(message: String): void\n    +info(message: String): void\n}\n\nclass GenerateContent {\n    +generate_content_from_files(files: Map<String, String>): List<String>\n}\n\nTraverseDirectories --> Repository\nTraverseDirectories --> Config\nTraverseDirectories --> Logger\nTraverseDirectories --> GenerateContent\nTraverseDirectories o-- Map\n\nRepository --> Tree\n\nTree --> TreeItem\n\nGenerateContent <-- TraverseDirectories\n\nGenerateContent --> Logger\nGenerateContent o-- Map\n\nLogger <-- TraverseDirectories\nLogger <-- GenerateContent\n\n\nConfig <.. TraverseDirectories\nConfig <.. GenerateContent\n\n@enduml@enduml\n\n@startuml\n\nclass t {\n  - included_files\n  - output_directory\n  + logger\n  + final_output_paths\n  + git_repo_url\n  + temp_dir\n  + e\n  + t(included_files, output_directory)\n  + generate_UML()\n}\n\nt..>logger: uses\nt-->"output_paths": contains\nt-->output_paths: "is a list"\nt-->git_repo_url\nt-->temp_dir: "contains"\nt-->e: "contains"\nt-->generate_UML: "calls"\noutput_paths..>"output_directory": in\ngit_repo_url-->"Repository": in\ne-->500: "returns"\nt-->500: "returns"\ntemp_dir-->"Cleaning up temporary directory": logs\ne-->"Error during UML generation:": logs\noutput_paths-->"Log the path where each UML diagram was saved": logs\n\ngenerate_UML-->"UML diagram saved at": logs\noutput_paths..>"Final output paths": in\nt-->t(included_files, output_directory): "calls"\nt-->{json}: returns\n{json}-->"message": in\n{json}-->"details": in\n{json}-->"Repository": in\n{json}-->"Output Paths": in\n{json}-->t: returns\n\n@endumlrrent_dir, \'config.json\')\n\n@startuml\n\nclass Config\n    Current_dir : string\n    Config_file_path : string\n    + get_config() : dict\n    + update_config(config) : void\n\nConfig --> Current_dir\nConfig --> Config_file_path\nConfig --o logger\n\n\nclass Logger\n    + log_handler : RotatingFileHandler\n    + log_formatter : Formatter\n    + logger : Logger\n    + set_handler(handler) : void\n    + set_formatter(formatter) : void\n    + add_handler(handler) : void\n    + set_level(level) : void\n    + log(msg, level) : void\n\nLogger --o log_handler\nLogger --o log_formatter\nLogger --o logger\n\n\nclass UmlGenerator\n    + config : Config\n    + logger : Logger\n    + execute() : void\n    + generate_uml() : void\n    + save_file(content) : void\n\nUmlGenerator --o config\nUmlGenerator --o logger\n\nclass RequestManager\n    + api_url : string\n    + config : Config\n    + logger : Logger\n    + get_umls(concepts) : list\n    + process_request(response) : dict\n    + send_request(params) : json\n\nRequestManager --o config\nRequestManager --o logger\n\nclass DOTEnv\n    + load_dotenv() : void\n\nDOTEnv --o UmlGenerator\n\nclass JsonManager\n    + config_file_path : string\n    + get_data() : dict\n    + update_data(new_data) : void\n\nJsonManager --o Config\nJsonManager --o Config_file_path\n\nclass OS\n    + get_current_dir() : string\n\nOS --o Config\nOS --o Current_dir\n\nclass Requests\n    + get(url) : json\n\nRequests --o RequestManager\n\n\n@enduml\n\nThe diagram shows the classes and their relationships within the code. The JSON and OS classes have been added based on their usage in the code. The DOTEnv class is dependent on the UmlGenerator class as it is used within its code. The Config class is also dependent on the Logger class for handling logging. The UmlGenerator class uses the Config and Logger classes for its functionality, while also using the RequestManager class to handle API requests. All of these classes are used within the main program.Check if the response was successful\n    if response.status_code == 200:\n        # Save the UML diagram to a file\n        with open(\'diagram.png\', \'wb\') as f:\n            f.write(response.content)\nexc\n\n@startuml\nclass ConfigData {\n    - String gitHubAccessToken\n    - String local_dir\n}\nclass RequestSender {\n    - String url\n    - Map headers\n    + json_data\n    + response\n}\nnote right of ConfigData: read from JSON file\nConfigData -- RequestSender : <m>\nRequestSender --|> ConfigData : has-a\nnote bottom of RequestSender: uses url and headers\n@enduml@startuml\n\nclass Client {\n    - output_dir : String\n    + main() : void\n}\n\nclass Server {\n    - response : String\n    + getResponse() : String\n}\n\nClient o-- Server : makeRequest()\nClient o-- Logger : Log exception\nClient o-- os : outputDirExist()\nClient o-- json : saveResponse()\n\nclass Logger {\n    - ERROR : String\n    + logError(e: Exception) : void\n}\n\nClient --> output_dir\n\n@enduml')
2024-01-20 21:26:35,392 - INFO - UML diagram saved at: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-20 21:26:35,393 - INFO - UML diagram saved at: fo(f"Generating UML diagram for {file_path}")  # Log the file path
        file_paths.append(file_path)  # Store the file path in the list
        generated_code += api.generate(code)  # Generate code for the files and concatenate the results
    logging.info(f"Generated code: {generated_code}")  # Log the generated code
    api.create_diagram(generated_code, output_directory)  # Create a UML diagram using the API and the generated code

# main function
if __name__ == '__main__':
    # Define input files and output directory
    files = {
        'main.py': 'Code for the main function',
        'helper.py': 'Code for helper functions'
    }
    output_directory = 'diagrams'
    # Generate UML diagram for the files and save to output directory
    generate_content(files, output_directory)

@startuml

[*] --> code_to_uml

class code_to_uml.py {
+ api: OpenAIAPI
+ log_directory: String
+ log_filename: String
+ log_handler: RotatingFileHandler
+ log_formatter: Formatter
+ logger: logging
+ generate_content(): void
+ main(): void
}

code_to_uml.py --> OpenAIAPI
code_to_uml.py --> logging

class OpenAIAPI {
+ generate(): String
+ create_diagram(): void
}

class logging {
+ handlers: handlers
+ formatter: Formatter
logger: debug
info
}

code_to_uml.py --> main.py
code_to_uml.py --> helper.py

class main.py {
}

class helper.py {
}

main.py --> generate_content()
helper.py --> generate_content()

generate_content() --> logging
logging --> log_directory
logging --> log_filename
logging --> log_handler
logging --> log_formatter
logging --> logger
logger --> logging: debug, info
logging --> file_paths
logging --> generated_code
generate_content() --> api: create_diagram()
api --> generate()
generate() --> api: generate()
generate() --> code
generate() --> output
api --> create_diagram()
create_diagram() --> generated_code
create_diagram() --> output_directory

@enduml@startuml

class UMLGenerator {
    -generated_code: str
    -file_paths: list
    +fo(): void
    +generate_from_code(): str
    +save_generated_output(): str
    +file_name: str
    +final_output_path: str
    +logging: Logger
    +api: API
    +output_directory: str
    +file_path: str
    +generated_code_for_file: str
    +file_paths: list
}

UMLGenerator o-- Logger
UMLGenerator o-- API

class Logger {
    +info(): void
    +error(): void
}

class API {
    +generate_from_code(): str
    +save_generated_output(): str
}

class API {
    +file_path: str
}

class API {
    +generated_code_for_file: str
}

class API {
    +output_directory: str
}

class API {
    +final_output_path: str
}

class os {
    +basename(): str
}

UMLGenerator --> Logger: uses
UMLGenerator --> API: uses
UMLGenerator --> generated_code_for_file: aggregates
UMLGenerator --> file_paths: aggregates
UMLGenerator --> logging: uses
UMLGenerator --> output_directory: contains
UMLGenerator --> file_path: contains
UMLGenerator --> generated_code: aggregates

@endumlreturn True
    except Exception as e:
        logger.error(f"Error cloning repository: {repo_url} - {e}")
        return False


def retrieve_code(repo_url, temp_dir, access_token, dest_dir, branch='master'):
    # Clone the repository to a temporary directory
    cloned = clone_repo(repo_url, temp_dir, access_token)
    
    if cloned:
        try:
            repo = git.Repo(temp_dir)
            # Checkout the specified branch
            repo.git.checkout(branch)
            # Copy the files to the destination directory
            os.system(f'cp -r {temp_dir}/* {dest_dir}')
            logger.info(f"Successfully retrieved code from {repo_url}")
            return True
        except Exception as e:
            logger.error(f"Error retrieving code from {repo_url} - {e}")
            return False


@startuml

class GitManager {
    - repo_url : string
    - temp_dir : string
    - access_token : string
    - dest_dir : string
    - branch : string
    + clone_repo(repo_url, temp_dir, access_token) : boolean
    + retrieve_code(repo_url, temp_dir, access_token, dest_dir, branch='master') : boolean
}

note left of GitManager: Uses git\nlibrary

class git.Repo {
    + clone_from(repo_url, temp_dir) : git.Repo
    + git : GitCommandType
}

class os {
    + makedirs(directory, exist_ok=False) : None
    + system(command) : int
}

GitManager .. git.Repo : uses
GitManager .. os : uses

@endumlif file.path.endswith('.py') and file.path not in ignore_list:  # Only include files that match the .py extension and are not in the ignore list
                included_files[file.path] = file.data_stream.read().decode("utf-8")  # Store the file path as the key and the code as the value
                
        return included_files  # Return the dictionary of included files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")



@startuml

class Repo {
    -path : str
    -tree : list
    -remote : str
    -branches : list
    +git : Repository
    +clone() : Repository
    +fetch() : Repository
    +checkout(branch_name : str) : void
    +tree() : list
}

class Logger {
    +error(message : str) : void
    +info(message : str) : void
}

class File {
    -path : str
    -data_stream : Stream
    +read() : str
}

class Config {
    -file_path : str
    -ignore_list : list
    -include_list : list
    +load() : dict
    +get_ignore_list() : list
    +get_include_list() : list
}

class CodeRetriever {
    -repo : Repo
    -branch_name : str
    +retrieve_code(repo : Repo, branch_name : str) : dict
}

CodeRetriever --> Repo : dependency
CodeRetriever --> Logger : dependency
CodeRetriever --> Config : dependency
Repo --> File : contains
Config --> File : contains

code {

CodeRetriever --> Logger : usage
CodeRetriever --> Repo : method call
Repo --> Logger : usage
Repo --> Config : method call
Repo --> File : method call
Repo --> Stream : method call

}

exception {
CodeRetriever --> ValueError : raise
CodeRetriever --> Exception : catch
Repo --> Exception : catch
}


@enduml@startuml
class FileUtils{
    -include_list: str[]
    -ignore_list: str[]
    -included_files: dict
    -logger: Logger
    
    +__init__(include_list: str[], ignore_list: str[])
    +retrieve_code(files: str[]): dict
}

class Logger{
    +info(msg: str)
    +warning(msg: str)
    +error(msg: str)
}

class File{
    -path: str
    -abspath: str
    
    +endswith(ext: str)
}

File <|-- FileUtils
Logger <|-- FileUtils

note top: "Main control flow" as MainControlFlow
MainControlFlow ..> FileUtils

MainControlFlow --> if any(file.path.endswith(ext) for ext in include_list)
MainControlFlow --> not any(ignored_file in file.path for ignored_file in ignore_list)

if any(file.path.endswith(ext) for ext in include_list) ..> File
not any(ignored_file in file.path for ignored_file in ignore_list) ..> File

if any(file.path.endswith(ext) for ext in include_list) ==> open
not any(ignored_file in file.path for ignored_file in ignore_list) ==> open

open --> with open(file.abspath, 'r') as f
open --> try..except

with open(file.abspath, 'r') as f --> included_files[file.path] = f.read()
try..except --> print
try..except --> logger.warning
try..except --> FileNotFoundError

print --> "Diagnostic print statement"

Logger <--: logger
logger ..> MainControlFlow

included_files[file.path] = f.read() ==> logger.info(f"Included file: {file.path}")

FileNotFoundError ..> print
FileNotFoundError ..> logger.warning

Logger <--: logger
logger ..> MainControlFlow

print --> "Ignoring missing file: {file.path}"
logger.warning(f"Ignoring missing file: {file.path}") ==> print

MainControlFlow --> return included_files

MainControlFlow --> Logger.error

Logger ..> MainControlFlow

note bottom: Catch all exceptions\nand raise ValueError as needed

Logger.error ==> raise ValueError(f"Failed to retrieve code: {str(e)}")
raise ValueError(f"Failed to retrieve code: {str(e)}") --> return included_files

MainControlFlow ..> Logger
Logger ..> raise: ValueError
Logger ..> except: Exception

note left: Calling code as follows:\ninclude_list = ['.py', '.txt']\nignore_list = ['tests', 'temp']\nfiles = ['test.py', 'index.txt', 'app.py', 'tests/utils.py', 'temp/index.txt']\n
note left: Include list: ['.py', '.txt']\nIgnore list: ['tests', 'temp']\nFiles: ['test.py', 'index.txt', 'app.py', 'tests/utils.py', 'temp/index.txt']
@enduml)

        # Generate UML diagrams
        for diagram in config['diagrams']:
            plantuml = PlantUML()
            for file in diagram['files']:
                plantuml.process_file(file)
            plantuml.run(output_directory)

Class Diagram:
@startuml
class MainController
Entity thub_access_token
Entity branch_name
Entity git_repo_url
Entity output_directory

MainController -- thub_access_token : has
MainController -- branch_name : has
MainController -- git_repo_url : has
MainController -- output_directory : has

MainController : -logger
MainController : -temp_dir

note top of MainController
main controller
end note
@enduml

Sequence Diagram:
@startuml
hide footbox
title UML Generation

autonumber

actor User
boundary Controller
control MainController
database Database
participant TryCatch
participant config
participant clone_repo
participant PlantUML

User -> Controller: Submit request
activate Controller
Controller -> MainController: Get parameters
activate MainController
MainController -> MainController: Set default branch name
MainController -> MainController: Check for missing parameters
deactivate MainController
alt Parameters missing
MainController -> TryCatch: Log error
activate TryCatch
TryCatch --> Controller: Return error message
deactivate TryCatch
else Parameters valid
MainController -> TryCatch: Create temporary directory
activate TryCatch
alt Error creating directory
TryCatch --> MainController: Return error message
else Directory created successfully
TryCatch -> MainController: Clone repository
activate MainController
MainController -> Database: Get config file
activate Database
alt Config file not found
Database --> MainController: Return error message
else Config file found
Database -> MainController: Load config
MainController -> MainController: Generate UML diagrams
MainController -> MainController: Process each file in config
MainController -> PlantUML: Generate UML for each file
activate PlantUML
PlantUML -> output_directory: Save UML diagrams
plantuml run
deactivate PlantUML
MainController --> MainController: Return success message
end
deactivate MainController
@endumlt_from_files(included_files)
        
        
@startuml

class TraverseDirectories {
    -repo: Repository
    -temp_dir: String
    -config: Config
    +included_files: Map<String, String>
    +traverse_directories(Repo, String, Config): Map<String, String>
}

class Repository {
    +tree(): Tree
}

class Tree {
    +traverse(): Iterable<TreeItem>
}

class TreeItem {
    -type: String
    -path: String
}

class Config {
    -include: List<String>
}

class Logger {
    +debug(message: String): void
    +info(message: String): void
}

class GenerateContent {
    +generate_content_from_files(files: Map<String, String>): List<String>
}

TraverseDirectories --> Repository
TraverseDirectories --> Config
TraverseDirectories --> Logger
TraverseDirectories --> GenerateContent
TraverseDirectories o-- Map

Repository --> Tree

Tree --> TreeItem

GenerateContent <-- TraverseDirectories

GenerateContent --> Logger
GenerateContent o-- Map

Logger <-- TraverseDirectories
Logger <-- GenerateContent


Config <.. TraverseDirectories
Config <.. GenerateContent

@enduml@enduml

@startuml

class t {
  - included_files
  - output_directory
  + logger
  + final_output_paths
  + git_repo_url
  + temp_dir
  + e
  + t(included_files, output_directory)
  + generate_UML()
}

t..>logger: uses
t-->"output_paths": contains
t-->output_paths: "is a list"
t-->git_repo_url
t-->temp_dir: "contains"
t-->e: "contains"
t-->generate_UML: "calls"
output_paths..>"output_directory": in
git_repo_url-->"Repository": in
e-->500: "returns"
t-->500: "returns"
temp_dir-->"Cleaning up temporary directory": logs
e-->"Error during UML generation:": logs
output_paths-->"Log the path where each UML diagram was saved": logs

generate_UML-->"UML diagram saved at": logs
output_paths..>"Final output paths": in
t-->t(included_files, output_directory): "calls"
t-->{json}: returns
{json}-->"message": in
{json}-->"details": in
{json}-->"Repository": in
{json}-->"Output Paths": in
{json}-->t: returns

@endumlrrent_dir, 'config.json')

@startuml

class Config
    Current_dir : string
    Config_file_path : string
    + get_config() : dict
    + update_config(config) : void

Config --> Current_dir
Config --> Config_file_path
Config --o logger


class Logger
    + log_handler : RotatingFileHandler
    + log_formatter : Formatter
    + logger : Logger
    + set_handler(handler) : void
    + set_formatter(formatter) : void
    + add_handler(handler) : void
    + set_level(level) : void
    + log(msg, level) : void

Logger --o log_handler
Logger --o log_formatter
Logger --o logger


class UmlGenerator
    + config : Config
    + logger : Logger
    + execute() : void
    + generate_uml() : void
    + save_file(content) : void

UmlGenerator --o config
UmlGenerator --o logger

class RequestManager
    + api_url : string
    + config : Config
    + logger : Logger
    + get_umls(concepts) : list
    + process_request(response) : dict
    + send_request(params) : json

RequestManager --o config
RequestManager --o logger

class DOTEnv
    + load_dotenv() : void

DOTEnv --o UmlGenerator

class JsonManager
    + config_file_path : string
    + get_data() : dict
    + update_data(new_data) : void

JsonManager --o Config
JsonManager --o Config_file_path

class OS
    + get_current_dir() : string

OS --o Config
OS --o Current_dir

class Requests
    + get(url) : json

Requests --o RequestManager


@enduml

The diagram shows the classes and their relationships within the code. The JSON and OS classes have been added based on their usage in the code. The DOTEnv class is dependent on the UmlGenerator class as it is used within its code. The Config class is also dependent on the Logger class for handling logging. The UmlGenerator class uses the Config and Logger classes for its functionality, while also using the RequestManager class to handle API requests. All of these classes are used within the main program.Check if the response was successful
    if response.status_code == 200:
        # Save the UML diagram to a file
        with open('diagram.png', 'wb') as f:
            f.write(response.content)
exc

@startuml
class ConfigData {
    - String gitHubAccessToken
    - String local_dir
}
class RequestSender {
    - String url
    - Map headers
    + json_data
    + response
}
note right of ConfigData: read from JSON file
ConfigData -- RequestSender : <m>
RequestSender --|> ConfigData : has-a
note bottom of RequestSender: uses url and headers
@enduml@startuml

class Client {
    - output_dir : String
    + main() : void
}

class Server {
    - response : String
    + getResponse() : String
}

Client o-- Server : makeRequest()
Client o-- Logger : Log exception
Client o-- os : outputDirExist()
Client o-- json : saveResponse()

class Logger {
    - ERROR : String
    + logError(e: Exception) : void
}

Client --> output_dir

@enduml
2024-01-20 21:26:35,394 - INFO - Cleaning up temporary directory
2024-01-20 21:26:35,570 - INFO - 127.0.0.1 - - [20/Jan/2024 21:26:35] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 22:17:20,829 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/code_to_uml.py', reloading
2024-01-20 22:17:20,899 - INFO -  * Restarting with stat
2024-01-20 22:17:21,196 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:17:21,197 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 22:17:21,207 - WARNING -  * Debugger is active!
2024-01-20 22:17:21,215 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 22:17:38,350 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:17:38,351 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 22:17:38,361 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 22:17:38,361 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 22:17:38,361 - INFO -  * Restarting with stat
2024-01-20 22:17:38,614 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:17:38,615 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 22:17:38,623 - WARNING -  * Debugger is active!
2024-01-20 22:17:38,627 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 22:17:44,478 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 22:17:44,478 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 22:17:44,479 - INFO - Received local_dir: ./output
2024-01-20 22:17:44,479 - INFO - Received gitHubAccessToken: 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
2024-01-20 22:17:44,479 - INFO - Cleaning up temporary directory
2024-01-20 22:17:44,480 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 22:17:44,483 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 22:17:44,484 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp_ig2_aro'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 22:17:49,372 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp_ig2_aro'])'s unused stdout: 
2024-01-20 22:17:49,373 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 22:17:49,373 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp_ig2_aro, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 22:17:49,380 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp_ig2_aro, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 22:17:49,402 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 22:17:49,402 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-20 22:17:49,402 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 22:17:49,402 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-20 22:17:49,402 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-20 22:17:49,403 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-20 22:17:49,403 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-20 22:17:49,404 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-20 22:17:49,419 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 22:17:49,508 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107662190>
2024-01-20 22:17:49,508 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107565b50> server_hostname='api.openai.com' timeout=5.0
2024-01-20 22:17:49,572 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10b911350>
2024-01-20 22:17:49,572 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:17:49,573 - DEBUG - send_request_headers.complete
2024-01-20 22:17:49,573 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:17:49,573 - DEBUG - send_request_body.complete
2024-01-20 22:17:49,573 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:17:55,688 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:17:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5909'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'cd4760d6d108ce3c341257e826d7dda1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=QB3.4pK.fsBRc2vzZSefvwgCOr_9huO_z3GtTavljuY-1705810675-1-AahiWcyU4xupFZHw+Lse06RWDQFsJszpVpUe9huYyMAoLInT/54rqwwsVqooj5vsFqgXDep44ubb0BHb8ZqZvbg=; path=/; expires=Sun, 21-Jan-24 04:47:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=jdSSxWAbr_V_6nzEaYAcRWxsaREam7u61CTBUbIJ.dc-1705810675694-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cbfed380c53c3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:17:55,692 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:17:55,693 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:17:55,693 - DEBUG - receive_response_body.complete
2024-01-20 22:17:55,694 - DEBUG - response_closed.started
2024-01-20 22:17:55,694 - DEBUG - response_closed.complete
2024-01-20 22:17:55,694 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:17:55,697 - INFO - Received response from OpenAI: 
        if code == "":
            logging.warning(f"File {file_path} is empty.")
            continue
        # Check if the file path already exists
        if file_path not in file_paths:
            file_paths.append(file_path)
            # Generate content based on the code using the OpenAI API
            content = api.generate(code)
            # Append the generated content to the overall generated code
            generated_code += content + "\n"

    # Write the generated code to a file in the specified output directory
    output_file = os.path.join(output_directory, "generated_code.py")
    with open(output_file, "w") as f:
        f.write(generated_code)

# Create a dictionary with file paths as keys and code as values
files = {
    "main.py": "print('Hello, world!')",
    "functions.py": "def add(x, y): return x + y"
}

# Generate content using the files dictionary and output it to the "output" directory
generate_content(files, "output")


@startuml

class OpenAIAPI

api

OpenAIAPI : +OpenAIAPI()

class logging

log_directory : string
log_filename : string
log_handler : RotatingFileHandler
log_formatter : Formatter
logger : Logger

logging : +info(message)
logging : +warning(message)
logging : +debug(message)

class handlers

RotatingFileHandler
maxBytes: int
backupCount: int

handlers : +RotatingFileHandler(filename, maxBytes, backupCount)

class os

os : +makedirs(path, exist_ok)
os : +path.join(path1, path2)

OpenAIAPI ..> os
logging ..> handlers
handlers ..> logging
generate_content ..> logging
generate_content ..> OpenAIAPI
generate_content ..> os


interface OpenAIAPI {
  +generate(code): string
}

class "code_to_uml.py"

"code_to_uml.py" ..> OpenAIAPI
"code_to_uml.py" ..> logging
"code_to_uml.py" ..> handlers
"code_to_uml.py" ..> os

class "generate_content"

generate_content : -generated_code : string
generate_content : -file_paths : list

"generate_content" ..> logging
"generate_content" ..> OpenAIAPI
"generate_content" ..> os

(generate_content, "code_to_uml.py") ..> files

class files {
  +main.py : string
  +functions.py : string
}

(generate_content, "code_to_uml.py") ..> output_directory
class output_directory

@generate_content
generate_content : +__init__()
generate_content : +generate_content(files, output_directory)
generate_content : -output_file : string
generate_content : -content : string

class "output_directory"
class "files" {
  +__init__()
  +append()
}
output_directory ..> os

code_to_uml.py ..> API : api
code_to_uml.py ..> files : files

@enduml
2024-01-20 22:17:55,698 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-20 22:17:55,700 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-20 22:17:55,701 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:17:55,702 - DEBUG - send_request_headers.complete
2024-01-20 22:17:55,702 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:17:55,702 - DEBUG - send_request_body.complete
2024-01-20 22:17:55,702 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:17:57,644 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:17:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1842'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'2263e317213813e443ce44ad21b94c68'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cc01399e853c3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:17:57,646 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:17:57,648 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:17:57,649 - DEBUG - receive_response_body.complete
2024-01-20 22:17:57,649 - DEBUG - response_closed.started
2024-01-20 22:17:57,650 - DEBUG - response_closed.complete
2024-01-20 22:17:57,650 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:17:57,652 - INFO - Received response from OpenAI: _paths})


@startuml

class CodeGeneration
- code : string
- file_path : string
- generated_code_for_file : string
- final_output_path : string
- file_paths : list

+ generate_from_code(code : string) : string
+ save_generated_output(generated_code_for_file : string, output_path : string) : string
	
@enduml

@startuml

class Logging
- empty_file : string
- file_path : string
- generated_code_for_file : string
- file_path : string
- final_output_path : string
- file_paths : list

+ info(message : string) : void
+ error(message : string) : void
	
@enduml

@startuml

class API
- code : string
- file_path : string
- generated_code_for_file : string
- final_output_path : string
- file_paths : list

+ generate_from_code(code : string) : string
+ save_generated_output(generated_code_for_file : string, output_path : string) : string
	
@enduml
2024-01-20 22:17:57,653 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-20 22:17:57,655 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-20 22:17:57,657 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:17:57,657 - DEBUG - send_request_headers.complete
2024-01-20 22:17:57,657 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:17:57,657 - DEBUG - send_request_body.complete
2024-01-20 22:17:57,658 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:17:58,619 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:17:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'884'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'0ccdd59ddfa99c62f95212f5b08de99d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cc01f882f53c3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:17:58,621 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:17:58,622 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:17:58,623 - DEBUG - receive_response_body.complete
2024-01-20 22:17:58,623 - DEBUG - response_closed.started
2024-01-20 22:17:58,623 - DEBUG - response_closed.complete
2024-01-20 22:17:58,624 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:17:58,626 - INFO - Received response from OpenAI: 

//Class: FileBuilder

//Attributes:
- file_paths: List<String>
- generated_code: String

//Methods:
+ add_file(path: String): void
+ generate_code(): String
---------------------------------------------
//Class: FilePathsGenerator

//Attributes:
- project_name: String
- language: String
- file_paths: List<String>
- generated_code: String

//Methods:
+ add_path(path: String): void
+ generate(): void
+ get_file_paths(): List<String>
+ get_generated_code(): String
2024-01-20 22:17:58,627 - INFO - UML code generated for src/routes/code_to_uml.py: if code == "":
            logging.warning(f"File {file_path} is empty.")
            continue
        # Check if the file path already exists
        if file_path not in file_paths:
            file_paths.append(file_path)
            # Generate content based on the code using the OpenAI API
            content = api.generate(code)
            # Append the generated content to the overall generated code
            generated_code += content + "\n"

    # Write the generated code to a file in the specified output directory
    output_file = os.path.join(output_directory, "generated_code.py")
    with open(output_file, "w") as f:
        f.write(generated_code)

# Create a dictionary with file paths as keys and code as values
files = {
    "main.py": "print('Hello, world!')",
    "functions.py": "def add(x, y): return x + y"
}

# Generate content using the files dictionary and output it to the "output" directory
generate_content(files, "output")


@startuml

class OpenAIAPI

api

OpenAIAPI : +OpenAIAPI()

class logging

log_directory : string
log_filename : string
log_handler : RotatingFileHandler
log_formatter : Formatter
logger : Logger

logging : +info(message)
logging : +warning(message)
logging : +debug(message)

class handlers

RotatingFileHandler
maxBytes: int
backupCount: int

handlers : +RotatingFileHandler(filename, maxBytes, backupCount)

class os

os : +makedirs(path, exist_ok)
os : +path.join(path1, path2)

OpenAIAPI ..> os
logging ..> handlers
handlers ..> logging
generate_content ..> logging
generate_content ..> OpenAIAPI
generate_content ..> os


interface OpenAIAPI {
  +generate(code): string
}

class "code_to_uml.py"

"code_to_uml.py" ..> OpenAIAPI
"code_to_uml.py" ..> logging
"code_to_uml.py" ..> handlers
"code_to_uml.py" ..> os

class "generate_content"

generate_content : -generated_code : string
generate_content : -file_paths : list

"generate_content" ..> logging
"generate_content" ..> OpenAIAPI
"generate_content" ..> os

(generate_content, "code_to_uml.py") ..> files

class files {
  +main.py : string
  +functions.py : string
}

(generate_content, "code_to_uml.py") ..> output_directory
class output_directory

@generate_content
generate_content : +__init__()
generate_content : +generate_content(files, output_directory)
generate_content : -output_file : string
generate_content : -content : string

class "output_directory"
class "files" {
  +__init__()
  +append()
}
output_directory ..> os

code_to_uml.py ..> API : api
code_to_uml.py ..> files : files

@enduml_paths})


@startuml

class CodeGeneration
- code : string
- file_path : string
- generated_code_for_file : string
- final_output_path : string
- file_paths : list

+ generate_from_code(code : string) : string
+ save_generated_output(generated_code_for_file : string, output_path : string) : string
	
@enduml

@startuml

class Logging
- empty_file : string
- file_path : string
- generated_code_for_file : string
- file_path : string
- final_output_path : string
- file_paths : list

+ info(message : string) : void
+ error(message : string) : void
	
@enduml

@startuml

class API
- code : string
- file_path : string
- generated_code_for_file : string
- final_output_path : string
- file_paths : list

+ generate_from_code(code : string) : string
+ save_generated_output(generated_code_for_file : string, output_path : string) : string
	
@enduml//Class: FileBuilder

//Attributes:
- file_paths: List<String>
- generated_code: String

//Methods:
+ add_file(path: String): void
+ generate_code(): String
---------------------------------------------
//Class: FilePathsGenerator

//Attributes:
- project_name: String
- language: String
- file_paths: List<String>
- generated_code: String

//Methods:
+ add_path(path: String): void
+ generate(): void
+ get_file_paths(): List<String>
+ get_generated_code(): String
2024-01-20 22:17:58,628 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-20 22:17:58,630 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-20 22:17:58,631 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-20 22:17:58,631 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-20 22:17:58,633 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-20 22:17:58,634 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:17:58,634 - DEBUG - send_request_headers.complete
2024-01-20 22:17:58,635 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:17:58,635 - DEBUG - send_request_body.complete
2024-01-20 22:17:58,635 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:18:00,899 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:18:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2184'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'dfdc81e3a7624c0ec1e4ea1f13458a8f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cc025cf2753c3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:18:00,901 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:18:00,901 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:18:00,902 - DEBUG - receive_response_body.complete
2024-01-20 22:18:00,902 - DEBUG - response_closed.started
2024-01-20 22:18:00,903 - DEBUG - response_closed.complete
2024-01-20 22:18:00,903 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:18:00,907 - INFO - Received response from OpenAI: 
        return repo
    
    except Exception as e:
        logger.error(f"Failed to clone repository: {repo_url}")
        logger.error(e)
        return None


def get_file_contents(file_path):
    try:
        with open(file_path, 'r') as file:
            return json.load(file)
    
    except Exception as e:
        logger.error(f"Failed to retrieve contents of file: {file_path}")
        logger.error(e)
        return None

### UML Diagram ###

@startuml

package gittools {
    
    class git {
        + clone_from(repo_url, temp_dir)
    }
    
}

package logger {
    
    class handlers {
        + RotatingFileHandler(log_filename, maxBytes, backupCount)
    }
    
    class logging {
        + Formatter()
        + getLogger()
    }
    
}

class os {
    + makedirs(log_directory, exist_ok)
    + path
}

class json {
    + load(file_path)
}

Main --> os
Main --> json
Main --> gittools
Main --> logger

gittools --> git
gittools --> os
    
FileHandler "1" --> handlers
Logging "1" --> handlers
handlers "1" --> Formatter
handlers "1" --> RotatingFileHandler

Main --> FileHandler
Main --> Logging

@enduml
2024-01-20 22:18:00,908 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-20 22:18:00,910 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-20 22:18:00,912 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:18:00,912 - DEBUG - send_request_headers.complete
2024-01-20 22:18:00,912 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:18:00,912 - DEBUG - send_request_body.complete
2024-01-20 22:18:00,913 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:18:04,013 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:18:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3036'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'9ffa106ce875b5ce9ac5da2356a30651'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cc033ee2a53c3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:18:04,015 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:18:04,015 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:18:04,016 - DEBUG - receive_response_body.complete
2024-01-20 22:18:04,017 - DEBUG - response_closed.started
2024-01-20 22:18:04,017 - DEBUG - response_closed.complete
2024-01-20 22:18:04,017 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:18:04,019 - INFO - Received response from OpenAI:  # Check if the file should be ignored or included based on the config
            if file.path in ignore_list:
                continue
            if include_list:
                if file.path not in include_list:
                    continue
            # If no ignore or include lists are provided, include all files available in the repository

            # Read the code from the file and store it in the dictionary
            code = file.data_stream.read().decode("utf-8")
            included_files[file.path] = code

        return included_files
    
    except Exception as e:
        logger.error(f"Failed to retrieve code from repository: {str(e)}")
        raise ValueError(f"Failed to retrieve code from repository: {str(e)}")

@startuml
class main:
    - repo: Repository
        
    + retrieve_code(repo: Repository, branch_name: string) : Dictionary
    
    - check_if_ignored(file_path: string, ignore_list: list) : boolean
    - check_if_included(file_path: string, include_list: list) : boolean
    
    + main() : void
@enduml

@startuml
class Repository
    + git: Git
    + tree() : File
    + fetch() : void
    + checkout(branch_name: string) : void
@enduml

@startuml
class File
    - path: string
    - data_stream: DataStream
    
    + read() : string
@enduml

@startuml
class DataStream
    + read() : string
@enduml

@startuml
class Config
    + ignore: list
    + include: list
@enduml
2024-01-20 22:18:04,019 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-20 22:18:04,021 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-20 22:18:04,022 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:18:04,023 - DEBUG - send_request_headers.complete
2024-01-20 22:18:04,023 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:18:04,023 - DEBUG - send_request_body.complete
2024-01-20 22:18:04,023 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:18:06,838 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:18:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2670'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'0f723b80c10cd081b88a317f3c8041e0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cc0475b8553c3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:18:06,839 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:18:06,839 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:18:06,839 - DEBUG - receive_response_body.complete
2024-01-20 22:18:06,839 - DEBUG - response_closed.started
2024-01-20 22:18:06,840 - DEBUG - response_closed.complete
2024-01-20 22:18:06,840 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:18:06,840 - INFO - Received response from OpenAI: 
@startuml

class "CodeRetriever" {
    - include_list: list
    - ignore_list: list
    + included_files: dict
    + logger: Logger
    + retrieve_code()
}

class "Logger" {
    + info(message: str)
    + warning(message: str)
    + error(message: str)
}

class "File" {
    - path: str
    - abspath: str
    + endswith(ext: str)
}

"CodeRetriever" --> "Logger"
"CodeRetriever" --> "File"
"Logger" -- "File"

note right of "CodeRetriever" #yellow
    Control flow for retrieving code
end note

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list) then (if condition holds)
    "CodeRetriever" -> "File"
    "File" -> end
else (if condition does not hold)
    "File" -> end
    note right #yellow
        Code retrieval failed
    end note
end if

group Try-Catch block
    try (try block)
        "File" -> "Logger"
        "Logger" -> "CodeRetriever"
    catch (catch block)
        "Logger" -> "File"
        "File" -> "Logger"
    end try
end group

@enduml
2024-01-20 22:18:06,841 - INFO - UML code generated for src/routes/retrieve_code.py: return repo
    
    except Exception as e:
        logger.error(f"Failed to clone repository: {repo_url}")
        logger.error(e)
        return None


def get_file_contents(file_path):
    try:
        with open(file_path, 'r') as file:
            return json.load(file)
    
    except Exception as e:
        logger.error(f"Failed to retrieve contents of file: {file_path}")
        logger.error(e)
        return None

### UML Diagram ###

@startuml

package gittools {
    
    class git {
        + clone_from(repo_url, temp_dir)
    }
    
}

package logger {
    
    class handlers {
        + RotatingFileHandler(log_filename, maxBytes, backupCount)
    }
    
    class logging {
        + Formatter()
        + getLogger()
    }
    
}

class os {
    + makedirs(log_directory, exist_ok)
    + path
}

class json {
    + load(file_path)
}

Main --> os
Main --> json
Main --> gittools
Main --> logger

gittools --> git
gittools --> os
    
FileHandler "1" --> handlers
Logging "1" --> handlers
handlers "1" --> Formatter
handlers "1" --> RotatingFileHandler

Main --> FileHandler
Main --> Logging

@enduml# Check if the file should be ignored or included based on the config
            if file.path in ignore_list:
                continue
            if include_list:
                if file.path not in include_list:
                    continue
            # If no ignore or include lists are provided, include all files available in the repository

            # Read the code from the file and store it in the dictionary
            code = file.data_stream.read().decode("utf-8")
            included_files[file.path] = code

        return included_files
    
    except Exception as e:
        logger.error(f"Failed to retrieve code from repository: {str(e)}")
        raise ValueError(f"Failed to retrieve code from repository: {str(e)}")

@startuml
class main:
    - repo: Repository
        
    + retrieve_code(repo: Repository, branch_name: string) : Dictionary
    
    - check_if_ignored(file_path: string, ignore_list: list) : boolean
    - check_if_included(file_path: string, include_list: list) : boolean
    
    + main() : void
@enduml

@startuml
class Repository
    + git: Git
    + tree() : File
    + fetch() : void
    + checkout(branch_name: string) : void
@enduml

@startuml
class File
    - path: string
    - data_stream: DataStream
    
    + read() : string
@enduml

@startuml
class DataStream
    + read() : string
@enduml

@startuml
class Config
    + ignore: list
    + include: list
@enduml@startuml

class "CodeRetriever" {
    - include_list: list
    - ignore_list: list
    + included_files: dict
    + logger: Logger
    + retrieve_code()
}

class "Logger" {
    + info(message: str)
    + warning(message: str)
    + error(message: str)
}

class "File" {
    - path: str
    - abspath: str
    + endswith(ext: str)
}

"CodeRetriever" --> "Logger"
"CodeRetriever" --> "File"
"Logger" -- "File"

note right of "CodeRetriever" #yellow
    Control flow for retrieving code
end note

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list) then (if condition holds)
    "CodeRetriever" -> "File"
    "File" -> end
else (if condition does not hold)
    "File" -> end
    note right #yellow
        Code retrieval failed
    end note
end if

group Try-Catch block
    try (try block)
        "File" -> "Logger"
        "Logger" -> "CodeRetriever"
    catch (catch block)
        "Logger" -> "File"
        "File" -> "Logger"
    end try
end group

@enduml
2024-01-20 22:18:06,841 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-20 22:18:06,841 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-20 22:18:06,841 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-20 22:18:06,842 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-20 22:18:06,843 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-20 22:18:06,843 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:18:06,843 - DEBUG - send_request_headers.complete
2024-01-20 22:18:06,844 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:18:06,844 - DEBUG - send_request_body.complete
2024-01-20 22:18:06,844 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:18:07,015 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:18:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'47'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'22fba135d494585386e4c199bc015ef2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cc058f96153c3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:18:07,015 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:18:07,015 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:18:07,015 - DEBUG - receive_response_body.complete
2024-01-20 22:18:07,015 - DEBUG - response_closed.started
2024-01-20 22:18:07,015 - DEBUG - response_closed.complete
2024-01-20 22:18:07,015 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:18:07,016 - INFO - Received response from OpenAI: 
2024-01-20 22:18:07,016 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-20 22:18:07,017 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-20 22:18:07,017 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:18:07,018 - DEBUG - send_request_headers.complete
2024-01-20 22:18:07,018 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:18:07,018 - DEBUG - send_request_body.complete
2024-01-20 22:18:07,018 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:18:16,588 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:18:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'9434'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'aed3b60b9f17d50163148e79ed5546d0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cc05a3ac053c3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:18:16,590 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:18:16,591 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:18:16,592 - DEBUG - receive_response_body.complete
2024-01-20 22:18:16,592 - DEBUG - response_closed.started
2024-01-20 22:18:16,593 - DEBUG - response_closed.complete
2024-01-20 22:18:16,593 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:18:16,595 - INFO - Received response from OpenAI: )

        # Generate the UML diagram
        diagram_types = config.get('diagramTypes')
        if diagram_types:
            for diagram_type in diagram_types: 
                generate_uml_diagram(repo, output_directory, diagram_type)

        # Delete the cloned repository
        shutil.rmtree(temp_dir)

    except Exception as e: 
        logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
        return {"error": str(e)}, 500
``` 
@startuml

class "generate_uml_diagram(repo, output_directory, diagram_type)" as UMLOutput {
    - git_repo_url: string
    - output_directory: string
    - branch_name: string
    - github_access_token: string
    - temp_dir: string
    - config: json
    - diagram_types: list
    - diagram_type: string
    - logger: Logger
    -----------------------------
    + UMLOutput(git_repo_url, output_directory, branch_name, github_access_token)
    + get_git_repo_url(): string
    + get_output_directory(): string
    + get_branch_name(): string
    + get_github_access_token(): string
    + get_temp_dir(): string
    + get_config(): json
    + get_diagram_types(): list
    + get_diagram_type(): string
    + log_error(error_message): void
    + clone_repo(): Repo
    + load_config(): void
    + generate_uml_diagram(): void
    + delete_cloned_repo(): void
}

class "data" {
    - gitHubAccessToken: string
    - branchName: string
    -------------------------------
    + get(gitHubAccessToken): string
    + get(branchName): string
}

class "Repo" {
    -------------------------------
    + clone_repo(git_repo_url, temp_dir, github_access_token): Repo
}

class "Logger" {
    -------------------------------
    + error(message): void
}

class "tempfile" {
    -------------------------------
    + mkdtemp(): string
}

class "shutil" {
    -------------------------------
    + rmtree(temp_dir): void
}

class "json" {
    -------------------------------
    + load(file): json
}

'UML Output module dependencies'
UMLOutput --> "data"
UMLOutput --> "Logger"
UMLOutput --> "shutil"
UMLOutput --> "tempfile"
UMLOutput --> "Repo"
UMLOutput --> "json"

'Program flow'
start
:set thub_access_token = data.get('gitHubAccessToken'):
:set branch_name = data.get('branchName', 'master'):
if (Incomplete parameters?) then (yes)
    if (logger.error("Missing required parameters")) then (true)
        :log_error("Missing required parameters"):
        :return {"error": "Missing required parameters"}, 400:
    else (false)
        :return {"error": "Missing required parameters"}, 400:
    endif
else (no)
    if (try) then (true)
    :temp_dir = None:
        if (try) then (true)
            :temp_dir = tempfile.mkdtemp():
        else (false)
            if (logger.error(f"Error during UML generation: {str(e)}", exc_info=True)) then (true)
                :return {"error": str(e)}, 500:
            else (false)
                :return {"error": str(e)}, 500:
            endif
        endif
        if (finally) then (true)
            if (temp_dir is not None) then (true)
                if (logger.info("Cleaning up temporary directory")) then (true)
                    :shutil.rmtree(temp_dir):
                endif
            endif
        else (false)
            :shutil.rmtree(temp_dir):
        endif
    else (false)
        if (repo = clone_repo(git_repo_url, temp_dir, github_access_token)) then (true)
            :with open('src/routes/config.json', 'r') as f:
                :config = json.load(f):
            :diagram_types = config.get('diagramTypes'):
            if (diagram_types?) then (true)
                for loop diagram_type in diagram_types: 
                    :generate_uml_diagram(repo, output_directory, diagram_type):
                endfor
            else (false)
                :shutil.rmtree(temp_dir):
            endif
        endif
    endif
endif
if (finally) then (true)
    :shutil.rmtree(temp_dir):
else (false)
    :shutil.rmtree(temp_dir):
endif
if (exception?) then (yes)
    if (logger.error(f"Error during UML generation: {str(e)}", exc_info=True)) then (true)
        :return {"error": str(e)}, 500:
    else (false)
        :return {"error": str(e)}, 500:
    endif
else (no)
    if (logger
2024-01-20 22:18:16,596 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-20 22:18:16,598 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-20 22:18:16,600 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:18:16,600 - DEBUG - send_request_headers.complete
2024-01-20 22:18:16,600 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:18:16,600 - DEBUG - send_request_body.complete
2024-01-20 22:18:16,601 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:18:19,221 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:18:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2493'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'68983998baec2b86e5bd8177129702ca'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cc0961dfb53c3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:18:19,221 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:18:19,222 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:18:19,222 - DEBUG - receive_response_body.complete
2024-01-20 22:18:19,222 - DEBUG - response_closed.started
2024-01-20 22:18:19,223 - DEBUG - response_closed.complete
2024-01-20 22:18:19,223 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:18:19,224 - INFO - Received response from OpenAI: t_diagram(included_files)
        
@startuml
class Directories
class Repo
class Temp_dir
class Config
class Item
class F
class Included_files

Directories --> Item
Repo --> Item
Temp_dir --> Item
Config --> Item
Item --> F
F --> Included_files

class Traverse_directories{
  +traverse_directories(repo, temp_dir, config)
}

class Logger{
  +debug()
  +info()
}

class Generate_content_diagram{
  +generate_content_diagram(included_files)
}

main{
  traverse_directories
  Repo -> traverse_directories : tree()
  traverse_directories -> Item : traverse()
  Item -> traverse_directories : type == 'blob'
  traverse_directories -> Config : include
  Config -> traverse_directories : fnmatch.fnmatch()
  traverse_directories -> Temp_dir : join
  Temp_dir -> F : open
  F -> traverse_directories : read()
  traverse_directories -> Included_files : item.path
  Included_files -> Logger : debug()
  Logger -> main : debug()
  main -> Generate_content_diagram : generate_content_diagram(included_files)
  generate_content_diagram -> Logger : info()
  Logger -> main : info()
  main --> Included_files
}

@enduml
2024-01-20 22:18:19,225 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-20 22:18:19,226 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-20 22:18:19,227 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:18:19,228 - DEBUG - send_request_headers.complete
2024-01-20 22:18:19,228 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:18:19,228 - DEBUG - send_request_body.complete
2024-01-20 22:18:19,228 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:18:23,345 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:18:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4025'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'6f44ebd348d69142908db7424759642b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cc0a65fa653c3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:18:23,346 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:18:23,346 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:18:23,346 - DEBUG - receive_response_body.complete
2024-01-20 22:18:23,346 - DEBUG - response_closed.started
2024-01-20 22:18:23,347 - DEBUG - response_closed.complete
2024-01-20 22:18:23,347 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:18:23,348 - INFO - Received response from OpenAI: 1. Class Diagram:

          t(included_files: list, output_directory) : dict
    ______________________________/
    |                            __/
    | logger                    |
    | - info()                  |
    | - error()                 |
    |____________________________|
           |                           final_output_paths: list    
           |                                ______________/
           |                               |             |
           |______________________________/             |
                                                       __/
   _____________________                             |           ____________________________________________________________
   |                   |-------------------------|   |          |             |           |                                      |
   |    final_output_paths: list                 |   |          |             |           |         "details": dict                |
   |___________________|                         |   |          |             |           |______________________________________|
  __/                   \__                  ____/   \___       \_/ ____       \____         |        |                           | 
 |                         |                |             |        |      |         |       | "Repository": git_repo_url        | 
 | "Final output paths: {}"|                |  for path in |        |      |         |       |______________________________________|
 |_________________________|                |final_output_|        |      |         |______________________________________________/ 
                                            |    paths    |        |      |
                                            |_____________|        |      |
                                             for path in         logger  \_ return,
                                                     \__/          - info()  dict,
                                                       \/                         int
                                               "UML diagram saved at: {}"  __/
                                                                          /
  _____________________________________________________________________/
  |                     |                           |                    |
  | "message": "UML diagrams generated successfully"|                    |
  | "details": dict     |                           | "error": str       |
  |                    _|__________________________/                      /
  |                    | __os.path             |________________________/
  |                    |                                         |
  \_    Repository: str|               "Cleaning up temporary directory"
    \___        _________________                                | 
        \_____ |                     \__/          _____________/
              |                     |              |
              |_____________________/
                                        
                                

2024-01-20 22:18:23,348 - INFO - UML code generated for src/routes/uml_from_repo.py: )

        # Generate the UML diagram
        diagram_types = config.get('diagramTypes')
        if diagram_types:
            for diagram_type in diagram_types: 
                generate_uml_diagram(repo, output_directory, diagram_type)

        # Delete the cloned repository
        shutil.rmtree(temp_dir)

    except Exception as e: 
        logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
        return {"error": str(e)}, 500
``` 
@startuml

class "generate_uml_diagram(repo, output_directory, diagram_type)" as UMLOutput {
    - git_repo_url: string
    - output_directory: string
    - branch_name: string
    - github_access_token: string
    - temp_dir: string
    - config: json
    - diagram_types: list
    - diagram_type: string
    - logger: Logger
    -----------------------------
    + UMLOutput(git_repo_url, output_directory, branch_name, github_access_token)
    + get_git_repo_url(): string
    + get_output_directory(): string
    + get_branch_name(): string
    + get_github_access_token(): string
    + get_temp_dir(): string
    + get_config(): json
    + get_diagram_types(): list
    + get_diagram_type(): string
    + log_error(error_message): void
    + clone_repo(): Repo
    + load_config(): void
    + generate_uml_diagram(): void
    + delete_cloned_repo(): void
}

class "data" {
    - gitHubAccessToken: string
    - branchName: string
    -------------------------------
    + get(gitHubAccessToken): string
    + get(branchName): string
}

class "Repo" {
    -------------------------------
    + clone_repo(git_repo_url, temp_dir, github_access_token): Repo
}

class "Logger" {
    -------------------------------
    + error(message): void
}

class "tempfile" {
    -------------------------------
    + mkdtemp(): string
}

class "shutil" {
    -------------------------------
    + rmtree(temp_dir): void
}

class "json" {
    -------------------------------
    + load(file): json
}

'UML Output module dependencies'
UMLOutput --> "data"
UMLOutput --> "Logger"
UMLOutput --> "shutil"
UMLOutput --> "tempfile"
UMLOutput --> "Repo"
UMLOutput --> "json"

'Program flow'
start
:set thub_access_token = data.get('gitHubAccessToken'):
:set branch_name = data.get('branchName', 'master'):
if (Incomplete parameters?) then (yes)
    if (logger.error("Missing required parameters")) then (true)
        :log_error("Missing required parameters"):
        :return {"error": "Missing required parameters"}, 400:
    else (false)
        :return {"error": "Missing required parameters"}, 400:
    endif
else (no)
    if (try) then (true)
    :temp_dir = None:
        if (try) then (true)
            :temp_dir = tempfile.mkdtemp():
        else (false)
            if (logger.error(f"Error during UML generation: {str(e)}", exc_info=True)) then (true)
                :return {"error": str(e)}, 500:
            else (false)
                :return {"error": str(e)}, 500:
            endif
        endif
        if (finally) then (true)
            if (temp_dir is not None) then (true)
                if (logger.info("Cleaning up temporary directory")) then (true)
                    :shutil.rmtree(temp_dir):
                endif
            endif
        else (false)
            :shutil.rmtree(temp_dir):
        endif
    else (false)
        if (repo = clone_repo(git_repo_url, temp_dir, github_access_token)) then (true)
            :with open('src/routes/config.json', 'r') as f:
                :config = json.load(f):
            :diagram_types = config.get('diagramTypes'):
            if (diagram_types?) then (true)
                for loop diagram_type in diagram_types: 
                    :generate_uml_diagram(repo, output_directory, diagram_type):
                endfor
            else (false)
                :shutil.rmtree(temp_dir):
            endif
        endif
    endif
endif
if (finally) then (true)
    :shutil.rmtree(temp_dir):
else (false)
    :shutil.rmtree(temp_dir):
endif
if (exception?) then (yes)
    if (logger.error(f"Error during UML generation: {str(e)}", exc_info=True)) then (true)
        :return {"error": str(e)}, 500:
    else (false)
        :return {"error": str(e)}, 500:
    endif
else (no)
    if (loggert_diagram(included_files)
        
@startuml
class Directories
class Repo
class Temp_dir
class Config
class Item
class F
class Included_files

Directories --> Item
Repo --> Item
Temp_dir --> Item
Config --> Item
Item --> F
F --> Included_files

class Traverse_directories{
  +traverse_directories(repo, temp_dir, config)
}

class Logger{
  +debug()
  +info()
}

class Generate_content_diagram{
  +generate_content_diagram(included_files)
}

main{
  traverse_directories
  Repo -> traverse_directories : tree()
  traverse_directories -> Item : traverse()
  Item -> traverse_directories : type == 'blob'
  traverse_directories -> Config : include
  Config -> traverse_directories : fnmatch.fnmatch()
  traverse_directories -> Temp_dir : join
  Temp_dir -> F : open
  F -> traverse_directories : read()
  traverse_directories -> Included_files : item.path
  Included_files -> Logger : debug()
  Logger -> main : debug()
  main -> Generate_content_diagram : generate_content_diagram(included_files)
  generate_content_diagram -> Logger : info()
  Logger -> main : info()
  main --> Included_files
}

@enduml1. Class Diagram:

          t(included_files: list, output_directory) : dict
    ______________________________/
    |                            __/
    | logger                    |
    | - info()                  |
    | - error()                 |
    |____________________________|
           |                           final_output_paths: list    
           |                                ______________/
           |                               |             |
           |______________________________/             |
                                                       __/
   _____________________                             |           ____________________________________________________________
   |                   |-------------------------|   |          |             |           |                                      |
   |    final_output_paths: list                 |   |          |             |           |         "details": dict                |
   |___________________|                         |   |          |             |           |______________________________________|
  __/                   \__                  ____/   \___       \_/ ____       \____         |        |                           | 
 |                         |                |             |        |      |         |       | "Repository": git_repo_url        | 
 | "Final output paths: {}"|                |  for path in |        |      |         |       |______________________________________|
 |_________________________|                |final_output_|        |      |         |______________________________________________/ 
                                            |    paths    |        |      |
                                            |_____________|        |      |
                                             for path in         logger  \_ return,
                                                     \__/          - info()  dict,
                                                       \/                         int
                                               "UML diagram saved at: {}"  __/
                                                                          /
  _____________________________________________________________________/
  |                     |                           |                    |
  | "message": "UML diagrams generated successfully"|                    |
  | "details": dict     |                           | "error": str       |
  |                    _|__________________________/                      /
  |                    | __os.path             |________________________/
  |                    |                                         |
  \_    Repository: str|               "Cleaning up temporary directory"
    \___        _________________                                | 
        \_____ |                     \__/          _____________/
              |                     |              |
              |_____________________/
2024-01-20 22:18:23,349 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-20 22:18:23,349 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-20 22:18:23,350 - INFO - Skipping empty file: src/scripts/__init__.py
2024-01-20 22:18:23,350 - INFO - Processing file: src/scripts/execute_generate_uml.py
2024-01-20 22:18:23,350 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import json
import os
import requests
import logging
from logging import handlers
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure logging to write to a file
log_directory = '../../logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'execute_generate_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


# Configure logging
logging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))
# Configuration file path
config_file_path = os.path.join(cu
2024-01-20 22:18:23,351 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nimport json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(cu", 'max_tokens': 1024}}
2024-01-20 22:18:23,352 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:18:23,352 - DEBUG - send_request_headers.complete
2024-01-20 22:18:23,352 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:18:23,353 - DEBUG - send_request_body.complete
2024-01-20 22:18:23,353 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:18:25,711 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:18:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2302'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'c1bddd6f1be19bb78a2c3ee923e0de8d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cc0c02b2a53c3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:18:25,713 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:18:25,714 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:18:25,715 - DEBUG - receive_response_body.complete
2024-01-20 22:18:25,715 - DEBUG - response_closed.started
2024-01-20 22:18:25,715 - DEBUG - response_closed.complete
2024-01-20 22:18:25,715 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:18:25,717 - INFO - Received response from OpenAI: rrent_dir, 'config.json')

# Load configuration file
with open(config_file_path) as config_file:
    config = json.load(config_file)

# Set base URL for API requests
base_url = "http://www.example.com/api"

# Function to get data from API
def get_data(endpoint):
    # Construct request URL
    url = f"{base_url}/{endpoint}"
    # Make API request
    response = requests.get(url)
    # Check for successful response
    if response.status_code == 200:
        # Return data
        return response.json()
    else:
        # Log error
        logging.error(f"Unable to retrieve data from {endpoint} - status code: {response.status_code}")
        return None

@startuml

class LoadEnv 
class Logger
class ConfigJson
class CreateLogger

LoadEnv --> dotenv
Logger --> LoadEnv
CreateLogger .. ConfigJson

class ApiRequests
class Response

LoadEnv --> LoadEnv.dotenv
Logger --> Logger.handlers
ConfigJson --> LoadEnv.current_dir 
CreateLogger .. LoadEnv.config_file_path

class GetData
class CheckResponse
class LogError

ApiRequests --> Response
GetData --> ApiRequests
CheckResponse ..Flow..
LogError ..Flow..
Response --> CheckResponse
Response --> Flow

@enduml

The UML diagram is attached as "UML Diagram.puml.png".
2024-01-20 22:18:25,717 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

rrent_dir, 'config.json')

# Read configuration from the JSON file
with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

# Retrieve the GitHub access token from environment variables
github_token = os.getenv('GITHUB_PAT')

# Endpoint URL
url = 'http://127.0.0.1:5000/generate-uml'

# Headers
headers = {
    'Content-Type': 'application/json'
}

# Update the GitHub access token and local directory in the config data
config_data['gitHubAccessToken'] = github_token
config_data['local_dir'] = os.path.join(current_dir, '../..', 'output')

# Log the JSON data being sent in the request
logging.info(f'Sending JSON data to {url}:')
logging.info(json.dumps(config_data, indent=2))

try:
    # Make the POST request
    response = requests.post(url, headers=headers, json=config_data)

    # Log the response from the server
    logging.info(f'Response from server ({url}):')
    logging.info(f'Status Code: {response.status_code}')
    logging.info(f'Response Text: {response.text}')

    #
2024-01-20 22:18:25,719 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nrrent_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    #", 'max_tokens': 1024}}
2024-01-20 22:18:25,720 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:18:25,720 - DEBUG - send_request_headers.complete
2024-01-20 22:18:25,721 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:18:25,721 - DEBUG - send_request_body.complete
2024-01-20 22:18:25,721 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:18:28,705 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:18:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2666'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'c1d6da4fb9baaf921831e5ee5f9d5f84'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cc0cefc0753c3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:18:28,707 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:18:28,708 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:18:28,709 - DEBUG - receive_response_body.complete
2024-01-20 22:18:28,710 - DEBUG - response_closed.started
2024-01-20 22:18:28,710 - DEBUG - response_closed.complete
2024-01-20 22:18:28,711 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:18:28,713 - INFO - Received response from OpenAI:  Save the UML diagram to local directory
    image_name = f"{config_data['output_file']}.png"
    file_path = os.path.join(config_data['local_dir'], image_name)
    with open(file_path, 'wb') as image_file:
        image_file.write(response.content)

```puml
@startuml

class ConfigManager {
  - config_file_path: String
  - github_token: String
  - url: String
  - headers: dict
  - current_dir: String
  - config_data: dict
  - response: requests.Response
  + load_config()
  + update_config()
  + send_request()
  + save_diagram()
}

class JSONFileReader {
  - file_path: String
  + read_config_file()
}

class CredentialsManager {
  - github_token: String
  + retrieve_token()
}

class RequestManager {
  - url: String
  - headers: dict
  + make_request()
}

class Logger {
  - log_level: String
  + log_message()
}

JSONFileReader o-- ConfigManager: loads
CredentialsManager o-- ConfigManager: retrieves
RequestManager o-- ConfigManager: makes request
Logger o-- ConfigManager: logs data

ConfigManager "1" --> "1" JSONFileReader
ConfigManager "1" --> "1" CredentialsManager
ConfigManager "1" --> "1" RequestManager
ConfigManager "1" --> "1" Logger

@enduml
```

2024-01-20 22:18:28,713 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

 Print the response from the server
    print(response.text)

    # Save the response to a file in the output directory
    output_dir = os.path.join(current_dir, '../..', 'output')
    os.makedirs(output_dir, exist_ok=True)
    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:
        json.dump(response.json(), output_file, indent=2)

except Exception as e:
    # Log any exceptions that occur
    logging.error(f'Error occurred: {str(e)}')
2024-01-20 22:18:28,715 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')", 'max_tokens': 1024}}
2024-01-20 22:18:28,716 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:18:28,717 - DEBUG - send_request_headers.complete
2024-01-20 22:18:28,717 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:18:28,717 - DEBUG - send_request_body.complete
2024-01-20 22:18:28,717 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:18:30,605 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:18:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1816'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'391a1c6022385abae640ceb9f4301d80'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cc0e1b86f53c3-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:18:30,605 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:18:30,605 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:18:30,606 - DEBUG - receive_response_body.complete
2024-01-20 22:18:30,606 - DEBUG - response_closed.started
2024-01-20 22:18:30,606 - DEBUG - response_closed.complete
2024-01-20 22:18:30,606 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:18:30,607 - INFO - Received response from OpenAI: 
```

![UML Diagram for Print Response from Server](https://github.com/maripazmf/CS362-UML-Diagrams/blob/master/Code%20UML%20Diagrams/Print%20Response%20from%20Server.png)

---

![UML Diagram for Save Response to File](https://github.com/maripazmf/CS362-UML-Diagrams/blob/master/Code%20UML%20Diagrams/Save%20Response%20to%20File.png)

---

![UML Diagram for Logging Exceptions](https://github.com/maripazmf/CS362-UML-Diagrams/blob/master/Code%20UML%20Diagrams/Logging%20Exceptions.png)

---

![UML Diagram for Main Function](https://github.com/maripazmf/CS362-UML-Diagrams/blob/master/Code%20UML%20Diagrams/Main%20Function.png)
2024-01-20 22:18:30,607 - INFO - UML code generated for src/scripts/execute_generate_uml.py: rrent_dir, 'config.json')

# Load configuration file
with open(config_file_path) as config_file:
    config = json.load(config_file)

# Set base URL for API requests
base_url = "http://www.example.com/api"

# Function to get data from API
def get_data(endpoint):
    # Construct request URL
    url = f"{base_url}/{endpoint}"
    # Make API request
    response = requests.get(url)
    # Check for successful response
    if response.status_code == 200:
        # Return data
        return response.json()
    else:
        # Log error
        logging.error(f"Unable to retrieve data from {endpoint} - status code: {response.status_code}")
        return None

@startuml

class LoadEnv 
class Logger
class ConfigJson
class CreateLogger

LoadEnv --> dotenv
Logger --> LoadEnv
CreateLogger .. ConfigJson

class ApiRequests
class Response

LoadEnv --> LoadEnv.dotenv
Logger --> Logger.handlers
ConfigJson --> LoadEnv.current_dir 
CreateLogger .. LoadEnv.config_file_path

class GetData
class CheckResponse
class LogError

ApiRequests --> Response
GetData --> ApiRequests
CheckResponse ..Flow..
LogError ..Flow..
Response --> CheckResponse
Response --> Flow

@enduml

The UML diagram is attached as "UML Diagram.puml.png".Save the UML diagram to local directory
    image_name = f"{config_data['output_file']}.png"
    file_path = os.path.join(config_data['local_dir'], image_name)
    with open(file_path, 'wb') as image_file:
        image_file.write(response.content)

```puml
@startuml

class ConfigManager {
  - config_file_path: String
  - github_token: String
  - url: String
  - headers: dict
  - current_dir: String
  - config_data: dict
  - response: requests.Response
  + load_config()
  + update_config()
  + send_request()
  + save_diagram()
}

class JSONFileReader {
  - file_path: String
  + read_config_file()
}

class CredentialsManager {
  - github_token: String
  + retrieve_token()
}

class RequestManager {
  - url: String
  - headers: dict
  + make_request()
}

class Logger {
  - log_level: String
  + log_message()
}

JSONFileReader o-- ConfigManager: loads
CredentialsManager o-- ConfigManager: retrieves
RequestManager o-- ConfigManager: makes request
Logger o-- ConfigManager: logs data

ConfigManager "1" --> "1" JSONFileReader
ConfigManager "1" --> "1" CredentialsManager
ConfigManager "1" --> "1" RequestManager
ConfigManager "1" --> "1" Logger

@enduml
``````

![UML Diagram for Print Response from Server](https://github.com/maripazmf/CS362-UML-Diagrams/blob/master/Code%20UML%20Diagrams/Print%20Response%20from%20Server.png)

---

![UML Diagram for Save Response to File](https://github.com/maripazmf/CS362-UML-Diagrams/blob/master/Code%20UML%20Diagrams/Save%20Response%20to%20File.png)

---

![UML Diagram for Logging Exceptions](https://github.com/maripazmf/CS362-UML-Diagrams/blob/master/Code%20UML%20Diagrams/Logging%20Exceptions.png)

---

![UML Diagram for Main Function](https://github.com/maripazmf/CS362-UML-Diagrams/blob/master/Code%20UML%20Diagrams/Main%20Function.png)
2024-01-20 22:18:30,607 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-20 22:18:30,607 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-20 22:18:30,608 - INFO - Generated file paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-20 22:18:30,608 - INFO - Final output paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-20 22:18:30,608 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-20 22:18:30,608 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-20 22:18:30,608 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-20 22:18:30,608 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-20 22:18:30,608 - INFO - Cleaning up temporary directory
2024-01-20 22:18:30,775 - INFO - 127.0.0.1 - - [20/Jan/2024 22:18:30] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 22:24:28,625 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/code_to_uml.py', reloading
2024-01-20 22:24:28,691 - INFO -  * Restarting with stat
2024-01-20 22:24:28,975 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:24:28,975 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 22:24:28,983 - WARNING -  * Debugger is active!
2024-01-20 22:24:28,989 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 22:24:44,230 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:24:44,231 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 22:24:44,241 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 22:24:44,241 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 22:24:44,241 - INFO -  * Restarting with stat
2024-01-20 22:24:44,496 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:24:44,497 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 22:24:44,505 - WARNING -  * Debugger is active!
2024-01-20 22:24:44,510 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 22:24:50,655 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 22:24:50,656 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 22:24:50,656 - INFO - Received local_dir: ./output
2024-01-20 22:24:50,656 - INFO - Received gitHubAccessToken: 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
2024-01-20 22:24:50,657 - INFO - Cleaning up temporary directory
2024-01-20 22:24:50,657 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 22:24:50,659 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 22:24:50,660 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp1kv588m9'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 22:24:55,398 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp1kv588m9'])'s unused stdout: 
2024-01-20 22:24:55,400 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 22:24:55,400 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp1kv588m9, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 22:24:55,406 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp1kv588m9, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 22:24:55,429 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 22:24:55,429 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-20 22:24:55,429 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 22:24:55,430 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-20 22:24:55,430 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-20 22:24:55,430 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-20 22:24:55,430 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-20 22:24:55,431 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-20 22:24:55,443 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 22:24:55,485 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1035ece10>
2024-01-20 22:24:55,485 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1033edac0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 22:24:55,526 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10365d050>
2024-01-20 22:24:55,526 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:24:55,526 - DEBUG - send_request_headers.complete
2024-01-20 22:24:55,527 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:24:55,527 - DEBUG - send_request_body.complete
2024-01-20 22:24:55,527 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:25:01,194 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:25:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5440'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'49567d753cfb4534626c7cf92810be47'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dWSg_TZ5OecgntZFPxmCtkEr1pXLubMzKR3YVaa7cY8-1705811101-1-Acfh0SLLqDPaBwroOmnz86oCIbW81MGwtTex0lRJhYK+t6qhts0BlL1Q0hXzyDX2Ha19dRq/wdSLZYL6S/5JMAc=; path=/; expires=Sun, 21-Jan-24 04:55:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=zkJjc_W6Mo5ulustzlgq8fzneMOqN.eEUMTmAdfGr7g-1705811101083-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cca533ec22445-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:25:01,195 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:25:01,196 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:25:01,196 - DEBUG - receive_response_body.complete
2024-01-20 22:25:01,196 - DEBUG - response_closed.started
2024-01-20 22:25:01,196 - DEBUG - response_closed.complete
2024-01-20 22:25:01,197 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:25:01,199 - INFO - Received response from OpenAI: 
        if not code:
            continue
        # Add file path to file_paths list
        file_paths.append(file_path)
        # Call the OpenAI API to generate content
        generated_code += api.generate(code)
    
    # Write generated code to a file in the output directory
    output_file = os.path.join(output_directory, 'generated_code.txt')
    with open(output_file, 'w') as f:
        f.write(generated_code)
    
    # Log the file paths
    logging.info(f"Generated code written to {output_file}")
    logging.info(f"File paths used: {file_paths}")
    return generated_code

def main():
    # Set input and output directories
    input_directory = 'input'
    output_directory = 'output'
    
    # Get all files in the input directory
    files = os.listdir(input_directory)
    
    # Generate content for the files and write it to a file in the output directory
    generated_code = generate_content(files, output_directory)
    
if __name__ == '__main__':
    main()

@startuml

class OpenAIAPI
@enduml

@startuml

class Logging
@enduml

@startuml

class FileHandler
@enduml

@startuml

class File
@enduml

@startuml

class CodeToUml
* input_directory: String
* output_directory: String
* files: Dictionary
* generated_code: String
--
+ generate_content(files, output_directory): String
+ main()
--
OpenAIAPI api
Logging logger
FileHandler log_handler
File log_file
*
generate_content( ): String
main()

class OpenAIAPI{
* api: OpenAIAPI
--
# generate(code: String): String
# set_api_key(key: String): void
}

class Logging{
* logger: Logging
# log_formatter: Logging
# log_handler: FileHandler
--
# __init__(self, logger: Logging, log_formatter: Logging, log_handler: FileHandler)
# info(msg: String): void
# debug(msg: String): void
}

class FileHandler{
* log_handler: FileHandler
--
# log_filename: String
# __init__(self, log_filename: String, maxBytes: Int, backupCount: Int)
# setFormatter(log_formatter: Logging): void
# setLevel(level: Int): void
# addHandler(handler: FileHandler): void
}

class File{
* file_path: String
* code: String
--
+ skip_empty(): void
+ add_file_path(file_path: String): void
}

class CodeToUml{
* input_directory: String
* output_directory: String
* files: Dictionary
* generated_code: String
--
# generate_content(files, output_directory): String
# main(): void
}
 

Note: Some classes, such as main and File, do not actually exist in the code but were added in the UML diagram for clarity and to better represent the flow of the program.
2024-01-20 22:25:01,199 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-20 22:25:01,201 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-20 22:25:01,203 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:25:01,203 - DEBUG - send_request_headers.complete
2024-01-20 22:25:01,203 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:25:01,203 - DEBUG - send_request_body.complete
2024-01-20 22:25:01,204 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:25:02,648 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:25:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1377'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'cf6bc4472f32b11875f8aa62790edb25'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cca76af422445-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:25:02,651 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:25:02,651 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:25:02,652 - DEBUG - receive_response_body.complete
2024-01-20 22:25:02,652 - DEBUG - response_closed.started
2024-01-20 22:25:02,653 - DEBUG - response_closed.complete
2024-01-20 22:25:02,653 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:25:02,655 - INFO - Received response from OpenAI: _paths})


@startuml

start

if(not code.strip()) then (true)
    -->[true] "Log skipping empty file"
else (false)
    -->[false] "Process file"
    --> "Generate UML code"
    
    if(not generated_code_for_file or "UML generation failed" in generated_code_for_file) then (true)
        -->[true] "Log error"
        --> "Raise value error"
    else (false)
        -->[false] "Log generated UML code"
        -->[loop] "Add generated code to final output"
    endif
endif

--> "Save UML code as .puml file"
--> "Add file path to list"

while(file_path = file_paths)
    --> "Log generated file paths"
endwhile

stop

@enduml
2024-01-20 22:25:02,655 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-20 22:25:02,657 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-20 22:25:02,658 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:25:02,659 - DEBUG - send_request_headers.complete
2024-01-20 22:25:02,659 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:25:02,659 - DEBUG - send_request_body.complete
2024-01-20 22:25:02,659 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:25:04,575 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:25:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1827'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'fc99a40c05930036bf61bd6abed722b4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cca7fcba62445-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:25:04,577 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:25:04,578 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:25:04,579 - DEBUG - receive_response_body.complete
2024-01-20 22:25:04,579 - DEBUG - response_closed.started
2024-01-20 22:25:04,580 - DEBUG - response_closed.complete
2024-01-20 22:25:04,580 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:25:04,581 - INFO - Received response from OpenAI: 

@enduml

@startuml

class CodeGenerator {
    - _code_template
    - _model

    # _generate_code(filename, model) : string
    + generate_files(model) : list(string)

}

class Model {
    - _database
    - _table
    - _columns
}

class Database {
    - _name

    + get_tables() : list(Table)
}

class Table {
    - _name

    + get_columns() : list(Column)
}

class Column {
    - _name
    - _data_type
    - _length

    + get_data_type() : string
    + get_length() : int
}

CodeGenerator *-- Model
Model *-- Database
Model *-- Table
Table *-- Column

Database "1" *-- "*" Table

CodeGenerator --> Model : creates
Model --> Database : contains
Model --> Table : contains
Table --> Column : contains

@enduml


2024-01-20 22:25:04,582 - INFO - UML code generated for src/routes/code_to_uml.py: @startuml

class OpenAIAPI
@enduml
2024-01-20 22:25:04,582 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-20 22:25:04,583 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-20 22:25:04,583 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-20 22:25:04,583 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-20 22:25:04,585 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-20 22:25:04,586 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:25:04,587 - DEBUG - send_request_headers.complete
2024-01-20 22:25:04,587 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:25:04,587 - DEBUG - send_request_body.complete
2024-01-20 22:25:04,587 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:25:14,171 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:25:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'9422'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'7d7b8b804433c05ac1b5a842b7cdbd25'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cca8bdb3e2445-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:25:14,174 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:25:14,175 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:25:14,175 - DEBUG - receive_response_body.complete
2024-01-20 22:25:14,176 - DEBUG - response_closed.started
2024-01-20 22:25:14,176 - DEBUG - response_closed.complete
2024-01-20 22:25:14,176 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:25:14,179 - INFO - Received response from OpenAI: 
        # Return the path to the cloned repository
        return temp_dir
    except git.GitCommandError as e:
        logger.exception(f"Error cloning repository: {repo_url}")
        raise e


# Define a function to retrieve code from a repository
def retrieve_code(repo_url, branch='master', access_token=None):
    # Create a temporary directory to store the cloned repository
    temp_dir = 'temp'
    
    # Clone the repository into the temporary directory
    repo_path = clone_repo(repo_url, temp_dir, access_token)
    
    # Get the HEAD commit for the specified branch
    repo = git.Repo(repo_path)
    commit = repo.commit(branch)
    
    # Get the tree associated with the commit
    tree = commit.tree
    
    # Walk through the tree and retrieve each file
    for blob in tree.traverse():
        # Get the file path relative to the repository's root directory
        file_path = os.path.relpath(blob.abspath, repo_path)
        
        # Write the file to disk
        with open(file_path, 'wb') as f:
            f.write(blob.data_stream.read())
    
    # Convert the retrieved code to JSON format
    code_json = json.dumps(files)
    
    # Remove the temporary directory
    shutil.rmtree(temp_dir)
    
    # Return the JSON data
    return code_json


@startuml

import git
import json
import os
import logging
from logging import handlers

class Git:
    - repo_url : string
    - temp_dir : string
    - access_token : string
    + clone_repo(repo_url, temp_dir, access_token) : string
    + retrieve_code(repo_url, branch='master', access_token=None) : json

class Json:
    + dumps(files) : json

class Os:
    + makedirs(log_directory, exist_ok=True)

class Logging:
    - log_directory : string
    - log_filename : string
    - log_handler : RotatingFileHandler
    - log_formatter : Formatter
    - logger : Logger
    + setup_logging() : void
    
class handlers.RotatingFileHandler:
    - log_filename : string
    - maxBytes : int
    - backupCount : int
    + setFormatter(log_formatter) : void

class logging.Formatter:
    - format : string
    + format() : string

class logging.Logger:
    - log_handler : RotatingFileHandler
    - log_level : int
    + addHandler(log_handler) : void
    + setLevel(log_level) : void

class git.GitCommandError:
    - error_message : string
    + log_exception(repo_url) : void

class git.Repo:
    - repo_path : string
    + clone_from(repo_url, temp_dir) : void
    + commit(branch) : Commit
    + tree : ls-tree
    
class git.Commit:
    - commit : string
    + tree : ls-tree
    
class git.ls-tree:
    - blob : Blob
    + traverse() : void
    
class git.Blob:
    - abspath : string
    - data_stream : Stream
    + read() : void

class json.Json:
    - files : list
    + dumps() : json

class shutil.rmtree:
    - temp_dir : string
    + remove_directory() : void

class File:
    - file_path : string
    + write(data) : void
    + relpath(blob.abspath, repo_path) : string

Git --> git : uses
Json --> json : uses
Os --> os : uses
Logging --> logging : uses
handlers.RotatingFileHandler *-- logging.Formatter : contains
logging.Formatter -- handlers.RotatingFileHandler : used by
logging.Logger --> logging : uses
git.Repo --> git : uses
git.Commit --> git : uses
git.ls-tree --> git : uses
git.Blob --> git : uses
shutil.rmtree --> File : uses
git.ls-tree --> File : uses
handlers.RotatingFileHandler --> Logging : used by
Logging <|-- File
handlers.RotatingFileHandler <|-- Logging : extends
git.ls-tree --|> git.Blob
Git "1" *-- "1+" git.GitCommandError : throws
git.GitCommandError "1" *-- "1" git : caught by
handlers.RotatingFileHandler "1" *-- "1" logging : uses
handlers.RotatingFileHandler "1" *-- "1" json : uses

@enduml 
2024-01-20 22:25:14,180 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-20 22:25:14,182 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-20 22:25:14,183 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:25:14,183 - DEBUG - send_request_headers.complete
2024-01-20 22:25:14,183 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:25:14,184 - DEBUG - send_request_body.complete
2024-01-20 22:25:14,184 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:25:16,956 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:25:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2614'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'a7084ad55e46b9e1e6a39531277bd72c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848ccac7ca432445-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:25:16,958 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:25:16,959 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:25:16,960 - DEBUG - receive_response_body.complete
2024-01-20 22:25:16,960 - DEBUG - response_closed.started
2024-01-20 22:25:16,961 - DEBUG - response_closed.complete
2024-01-20 22:25:16,961 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:25:16,963 - INFO - Received response from OpenAI:  if file.path not in ignore_list:
                 if file.path.endswith('.py') and file.path not in include_list:
                     included_files[file.path] = file.data_stream.read()

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code from repository: {str(e)}")
        raise ValueError(f"Failed to retrieve code from repository: {str(e)}")


@startuml

class App {
    - logger: Logger
    - config_file_path: string
    - ignore_list: string[]
    - include_list: string[]
    - included_files: dictionary<string, string>
    
    + return(repo): Repository
    + retrieve_code(repo, branch_name): dictionary<string, string>
}

class Logger {
    + error(message: string): void
    + info(message: string): void
}

class Repository {
    + git: GitObject
    
    + git.fetch(): void
    + git.checkout(branch_name: string): void
    + tree(): File[]
}

class File {
    - path: string
    - data_stream: DataStream
    
    + get_path(): string
    + read(): string
}

class DataStream {
    + read(): string
}

class Config {
    + ignore: string[]
    + include: string[]
}

App o--> Logger
App o--> Repository
Logger --> Repository
Repository --> GitObject
Repository o--> File
File o--> DataStream
App ..> Config

@enduml
2024-01-20 22:25:16,964 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-20 22:25:16,967 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-20 22:25:16,968 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:25:16,969 - DEBUG - send_request_headers.complete
2024-01-20 22:25:16,969 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:25:16,969 - DEBUG - send_request_body.complete
2024-01-20 22:25:16,969 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:25:18,132 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:25:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1065'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'15b5a84b46639d71f357d192dc764f5b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848ccad948592445-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:25:18,134 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:25:18,135 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:25:18,136 - DEBUG - receive_response_body.complete
2024-01-20 22:25:18,137 - DEBUG - response_closed.started
2024-01-20 22:25:18,137 - DEBUG - response_closed.complete
2024-01-20 22:25:18,137 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:25:18,139 - INFO - Received response from OpenAI: 

@startuml

class CodeRetriever {
    + include_list: list
    + ignore_list: list
    + included_files: dict
    + logger: Logger

    + CodeRetriever(include_list, ignore_list, logger)
    + retrieve_code(file)

    - _is_valid_extension(file): bool
    - _is_ignored_file(file): bool
}

class Logger {
    + info(message)
    + warning(message)
    + error(message)
}

class file {
    + path
    + abspath
}

CodeRetriever --> file
Logger <-- CodeRetriever
2024-01-20 22:25:18,139 - ERROR - Error during UML generation: '@enduml' is not in list
2024-01-20 22:25:18,139 - INFO - Cleaning up temporary directory
2024-01-20 22:25:18,325 - INFO - 127.0.0.1 - - [20/Jan/2024 22:25:18] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 22:28:46,732 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/code_to_uml.py', reloading
2024-01-20 22:28:46,796 - INFO -  * Restarting with stat
2024-01-20 22:28:47,088 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:28:47,089 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 22:28:47,097 - WARNING -  * Debugger is active!
2024-01-20 22:28:47,104 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 22:30:18,835 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/routes/code_to_uml.py', reloading
2024-01-20 22:30:18,905 - INFO -  * Restarting with stat
2024-01-20 22:30:19,169 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:30:19,170 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 22:30:19,179 - WARNING -  * Debugger is active!
2024-01-20 22:30:19,184 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 22:30:21,600 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 22:30:21,600 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 22:30:21,601 - INFO - Received local_dir: ./output
2024-01-20 22:30:21,601 - INFO - Received gitHubAccessToken: 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
2024-01-20 22:30:21,602 - INFO - Cleaning up temporary directory
2024-01-20 22:30:21,602 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 22:30:21,605 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 22:30:21,606 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpma2r1ph7'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 22:30:27,223 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpma2r1ph7'])'s unused stdout: 
2024-01-20 22:30:27,225 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 22:30:27,225 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpma2r1ph7, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 22:30:27,231 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpma2r1ph7, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 22:30:27,254 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 22:30:27,254 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-20 22:30:27,254 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 22:30:27,254 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-20 22:30:27,255 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-20 22:30:27,255 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-20 22:30:27,255 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-20 22:30:27,256 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-20 22:30:27,268 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 22:30:27,347 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103612fd0>
2024-01-20 22:30:27,347 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103049b50> server_hostname='api.openai.com' timeout=5.0
2024-01-20 22:30:27,376 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103613010>
2024-01-20 22:30:27,376 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:30:27,376 - DEBUG - send_request_headers.complete
2024-01-20 22:30:27,376 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:30:27,376 - DEBUG - send_request_body.complete
2024-01-20 22:30:27,377 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:30:32,380 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:30:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4873'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'dabc61c78780076da46c2ad0fa0b0b8b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mfzQBPdmQkdp5plFptrdibSXzX3C77uCjRmvPQ42a2M-1705811432-1-AQ4/REt8VsajiXyce1o2tkaUy7KffgApbFdwzDUEhHwmljtew/kz2fbzID/7hOdUaWsvbYLpFyPeTaU4R4c5ivw=; path=/; expires=Sun, 21-Jan-24 05:00:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=qxXvKK3CFO.3vLenOADjxHdWPP7gn6fZGal7mxU12X4-1705811432378-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd26d4a87138b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:30:32,384 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:30:32,386 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:30:32,386 - DEBUG - receive_response_body.complete
2024-01-20 22:30:32,387 - DEBUG - response_closed.started
2024-01-20 22:30:32,387 - DEBUG - response_closed.complete
2024-01-20 22:30:32,387 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:30:32,390 - INFO - Received response from OpenAI: 
        if not code:
            logging.warning(f"File {file_path} is empty, skipping.")
            continue
        
        # Process file_path to point to the output directory
        file_paths.append(os.path.join(output_directory, file_path))
        
        # Generate code using the OpenAI API
        generated_code += api.generate(code)
    
    # Write the generated code to files in the output directory
    for i, path in enumerate(file_paths):
        try:
            with open(path, 'w') as f:
                f.write(generated_code[i])  # Write the generated code to the corresponding file
        except IndexError:
            logging.error(f"Index out of range, cannot write generated code to {path}.")
        
# Define the input files and output directory
files_to_process = {'file1.py': 'class MyClass:\n\tdef __init__(self):\n\t\tself.property = 0\n\n\tdef my_method(self):\n\t\treturn self.property',
                    'file2.py': 'def add(x, y):\n\treturn x + y'}

output_directory = 'generated_code'

# Generate content using the defined files and output directory
generate_content(files_to_process, output_directory)


@startuml

class OpenAIAPI {
    + generate()
}
log_directory: String
log_filename: String
log_handler: RotatingFileHandler
log_formatter: Logging.Formatter
logger: Logging


class code_to_uml {
    - api: OpenAIAPI
    - file_paths[]: String

    + generate_content(files, output_directory)
}

code_to_uml --> OpenAIAPI
code_to_uml --> Logging
code_to_uml --> files_to_process
code_to_uml --> output_directory

code_to_uml --> api
code_to_uml --> file_paths

class handlers.RotatingFileHandler {
    + __init__(filename, maxBytes, backupCount)
}

handlers.RotatingFileHandler --> Logging

class Logging {
    + basicConfig()
    + Formatter()
    + setLevel()
}

class os {

}

code_to_uml ..> os
code_to_uml ..> handlers.RotatingFileHandler
code_to_uml ..> Logging
code_to_uml ..> os

class files_to_process {
    + __init__(file1.py, file2.py)
}

code_to_uml --> files_to_process

class generated_code {
    + __init__()
}

code_to_uml --> generated_code
generated_code --> os

class output_directory {
    + __init__(generated_code)
}

code_to_uml --> output_directory
output_directory --> generated_code

@enduml
2024-01-20 22:30:32,391 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-20 22:30:32,393 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-20 22:30:32,395 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:30:32,395 - DEBUG - send_request_headers.complete
2024-01-20 22:30:32,395 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:30:32,395 - DEBUG - send_request_body.complete
2024-01-20 22:30:32,395 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:30:35,161 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:30:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2548'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'ef801f025c52edafb3c16f73df08d2ad'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd28cef57138b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:30:35,163 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:30:35,164 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:30:35,165 - DEBUG - receive_response_body.complete
2024-01-20 22:30:35,166 - DEBUG - response_closed.started
2024-01-20 22:30:35,166 - DEBUG - response_closed.complete
2024-01-20 22:30:35,166 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:30:35,169 - INFO - Received response from OpenAI: _paths})
@startuml

class Main {
    - code: string
    - file_path: string
    - generated_code_for_file: string
    - generated_code: string
    - file_name: string
    - final_output_path: string
    - output_directory: string
    - file_paths: list

    + main(): void
}

class Logging {
    - file_path: string
    - generated_code_for_file: string
    - generated_code: string
    - error_message: string

    + info(message: string): void
    + error(message: string): void
}

class Api {
    - code: string
    - generated_code: string
    - file_path: string
    - output_directory: string

    + generate_from_code(code: string): string
    + save_generated_output(generated_code: string, output_path: string): string
}

class Os {
    - path: string

    + basename(path: string): string
    + join(path1: string, path2: string): string
}

Main --> Logging
Main --> Api
Main --> Os

Logging ..> Main
Api ..> Main
Os ..> Main

Logging --> Api
Api ..> Logging
Api ..> Os

@enduml
2024-01-20 22:30:35,170 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-20 22:30:35,172 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-20 22:30:35,173 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:30:35,174 - DEBUG - send_request_headers.complete
2024-01-20 22:30:35,174 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:30:35,175 - DEBUG - send_request_body.complete
2024-01-20 22:30:35,175 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:30:37,328 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:30:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2063'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'73e4ce2b965c68fbef8756106700f30e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd29dfa9d138b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:30:37,330 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:30:37,331 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:30:37,332 - DEBUG - receive_response_body.complete
2024-01-20 22:30:37,332 - DEBUG - response_closed.started
2024-01-20 22:30:37,333 - DEBUG - response_closed.complete
2024-01-20 22:30:37,333 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:30:37,335 - INFO - Received response from OpenAI: 

}

generate_code(file_paths, template) {
    # Check if file_paths list is empty
    if (file_paths.length == 0) {
        print("No files found, cannot generate code.")
        return
    }

    # Loop through file_paths and generate code for each file
    for (path in file_paths) {
        # Open file and read its content
        file = File.open(path, "r")
        content = file.read()

        # Replace placeholder in template with file content
        placeholder = "__FILE_CONTENT__"
        template = template.replace(placeholder, content)

        # Generate and print the final code
        generated_code = template.replace("__FILE_PATH__", path)
        print(generated_code)
    }

    # Return the list of file paths and the generated code
    return file_paths, generated_code
}


@startuml

class FileManager {

    #_paths: String[]

    +search_files(directory: String, extension: String): String[]

    +generate_code(file_paths: String[], template: String): String[], String

}

@enduml
2024-01-20 22:30:37,335 - INFO - UML code generated for src/routes/code_to_uml.py: @startuml

class OpenAIAPI {
    + generate()
}
log_directory: String
log_filename: String
log_handler: RotatingFileHandler
log_formatter: Logging.Formatter
logger: Logging


class code_to_uml {
    - api: OpenAIAPI
    - file_paths[]: String

    + generate_content(files, output_directory)
}

code_to_uml --> OpenAIAPI
code_to_uml --> Logging
code_to_uml --> files_to_process
code_to_uml --> output_directory

code_to_uml --> api
code_to_uml --> file_paths

class handlers.RotatingFileHandler {
    + __init__(filename, maxBytes, backupCount)
}

handlers.RotatingFileHandler --> Logging

class Logging {
    + basicConfig()
    + Formatter()
    + setLevel()
}

class os {

}

code_to_uml ..> os
code_to_uml ..> handlers.RotatingFileHandler
code_to_uml ..> Logging
code_to_uml ..> os

class files_to_process {
    + __init__(file1.py, file2.py)
}

code_to_uml --> files_to_process

class generated_code {
    + __init__()
}

code_to_uml --> generated_code
generated_code --> os

class output_directory {
    + __init__(generated_code)
}

code_to_uml --> output_directory
output_directory --> generated_code

@enduml_paths})
@startuml

class Main {
    - code: string
    - file_path: string
    - generated_code_for_file: string
    - generated_code: string
    - file_name: string
    - final_output_path: string
    - output_directory: string
    - file_paths: list

    + main(): void
}

class Logging {
    - file_path: string
    - generated_code_for_file: string
    - generated_code: string
    - error_message: string

    + info(message: string): void
    + error(message: string): void
}

class Api {
    - code: string
    - generated_code: string
    - file_path: string
    - output_directory: string

    + generate_from_code(code: string): string
    + save_generated_output(generated_code: string, output_path: string): string
}

class Os {
    - path: string

    + basename(path: string): string
    + join(path1: string, path2: string): string
}

Main --> Logging
Main --> Api
Main --> Os

Logging ..> Main
Api ..> Main
Os ..> Main

Logging --> Api
Api ..> Logging
Api ..> Os

@enduml}

generate_code(file_paths, template) {
    # Check if file_paths list is empty
    if (file_paths.length == 0) {
        print("No files found, cannot generate code.")
        return
    }

    # Loop through file_paths and generate code for each file
    for (path in file_paths) {
        # Open file and read its content
        file = File.open(path, "r")
        content = file.read()

        # Replace placeholder in template with file content
        placeholder = "__FILE_CONTENT__"
        template = template.replace(placeholder, content)

        # Generate and print the final code
        generated_code = template.replace("__FILE_PATH__", path)
        print(generated_code)
    }

    # Return the list of file paths and the generated code
    return file_paths, generated_code
}


@startuml

class FileManager {

    #_paths: String[]

    +search_files(directory: String, extension: String): String[]

    +generate_code(file_paths: String[], template: String): String[], String

}

@enduml
2024-01-20 22:30:37,336 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-20 22:30:37,336 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-20 22:30:37,337 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-20 22:30:37,337 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-20 22:30:37,339 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-20 22:30:37,340 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:30:37,340 - DEBUG - send_request_headers.complete
2024-01-20 22:30:37,341 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:30:37,341 - DEBUG - send_request_body.complete
2024-01-20 22:30:37,341 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:30:43,082 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:30:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5649'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'6f43e4569da72fa4e29148a749a7a1f1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd2ab89b1138b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:30:43,082 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:30:43,083 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:30:43,083 - DEBUG - receive_response_body.complete
2024-01-20 22:30:43,083 - DEBUG - response_closed.started
2024-01-20 22:30:43,083 - DEBUG - response_closed.complete
2024-01-20 22:30:43,083 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:30:43,085 - INFO - Received response from OpenAI: 
        # Get metadata from the repository
        metadata = repo.git.describe('--always', tags=True)
        logger.info(f"Retrieved metadata from repository: {metadata}")
        
        # Save metadata in a JSON file
        metadata_file = os.path.join(temp_dir, 'metadata.json')
        with open(metadata_file, 'w') as f:
            json.dump(metadata, f)
            logger.info(f"Saved metadata in: {metadata_file}")
        
        return metadata
    except Exception as e:
        logger.error(f"Error cloning repository: {e}")
        raise e


def main():
    # User inputs
    repo_url = input("Enter repository URL: ")
    temp_dir = input("Enter temporary directory path: ")
    access_token = input("Enter access token (optional): ")
    
    # Clone repository and retrieve metadata
    metadata = clone_repo(repo_url, temp_dir, access_token)
    
    print("Successfully retrieved metadata from repository:", metadata)


# UML diagrams in .puml format:

@startuml

import git
import json
import os
import logging
from logging import handlers

package "import git" {
    class Git
}

package "import json" {
    class Json
}

package "import os" {
    class Os {
        + makedirs(log_directory, exist_ok)
        + join(path, *paths)
    }
}

package "import logging" {
    class Logging {
        - logger
        - log_formatter
        - log_handler
        + handlers
        + getLogger()
        + setLevel(level)
        + addHandler(handler)
    }
    class handlers {
        + RotatingFileHandler(filename, maxBytes, backupCount)
        + setFormatter(formatter)
    }
}

Git --> Git.Repo
Json --> Json.dump()
Os --> Os.makedirs()
Os --> Os.join()
handlers --> handlers.RotatingFileHandler()
handlers --> handlers.setFormatter()
Logging --> Logging.getLogger()
Logging --> Logging.setLevel()
Logging --> Logging.addHandler()

@enduml


@startuml

Logging --> Logging.logger
Logging --> Logging.log_formatter
Logging --> Logging.log_handler

class Logging {
    - logger
    - log_formatter
    - log_handler
    + getLogger()
    + setLevel(level)
    + addHandler(handler)
}

class Git {
    + clone_from(repo_url, temp_dir)
}

class Logging.logger {
    + info(message)
    + error(message)
}

package "import os" {
    class Os {
        + makedirs(log_directory, exist_ok)
        + join(path, *paths)
    }
}

Git --> Git.Repo
Os --> Os.makedirs()
Os --> Os.join()

class Git.Repo {
    + describe(options)
}

class Logging.log_formatter {
    + format(record)
}

Git.Repo --> Git.Repo.git
Git.Repo.git --> Git.Repo.git.describe()

@enduml
2024-01-20 22:30:43,085 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-20 22:30:43,086 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-20 22:30:43,087 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:30:43,087 - DEBUG - send_request_headers.complete
2024-01-20 22:30:43,087 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:30:43,087 - DEBUG - send_request_body.complete
2024-01-20 22:30:43,087 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:30:46,262 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:30:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3087'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'07c796ed1a04dea700881646574c4652'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd2cf6847138b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:30:46,263 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:30:46,263 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:30:46,263 - DEBUG - receive_response_body.complete
2024-01-20 22:30:46,264 - DEBUG - response_closed.started
2024-01-20 22:30:46,264 - DEBUG - response_closed.complete
2024-01-20 22:30:46,264 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:30:46,265 - INFO - Received response from OpenAI:  if file.path not in ignore_list and file.path in include_list:
                 included_files[file.path] = file.data_stream.read().decode("utf-8")

        return included_files

@startuml
class GitRepo 
{
    + git: GitPython object
    + logger: Logging object

    + return repo
    + retrieve_code(repo, branch_name)
    
    - config_file_path: string
    - ignore_list: list of strings
    - include_list: list of strings
    
    - included_files: dict of (string, string)
}
@enduml

@startuml
class Exception
{
    + e: Exception object
    + str(e): string
}
@enduml

@startuml
class Logger 
{
    - logger: Logging object

    + logger.error(message)
    + logger.info(message)
}
@enduml

@startuml
class ValueError 
{
    + str(e): string
}
@enduml

@startuml
class File 
{
    + path: string
    + data_stream: binary data
    + read(): string 
}
@enduml

@startuml
class Repository 
{
    + repo: GitRepo object
    + branch_name: string
    
    + git.fetch()
    + git.checkout(branch_name)

    - config_file_path: string
    - ignore_list: list of strings
    - include_list: list of strings
    
    - included_files: dict of (string, string)
}
@enduml

@startuml
class Config 
{
    + config_file_path: string
    + ignore: list of strings
    + include: list of strings
}
@enduml
2024-01-20 22:30:46,265 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-20 22:30:46,267 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-20 22:30:46,267 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:30:46,268 - DEBUG - send_request_headers.complete
2024-01-20 22:30:46,268 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:30:46,268 - DEBUG - send_request_body.complete
2024-01-20 22:30:46,268 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:30:47,943 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:30:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1427'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'ed0fc9aab3e3113f651fabe4e0e42c81'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd2e36ef8138b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:30:47,945 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:30:47,945 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:30:47,946 - DEBUG - receive_response_body.complete
2024-01-20 22:30:47,946 - DEBUG - response_closed.started
2024-01-20 22:30:47,946 - DEBUG - response_closed.complete
2024-01-20 22:30:47,947 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:30:47,948 - INFO - Received response from OpenAI: 

@startuml

class UmlDiagram {
    # file: str
    # abs_path: str
    # include_list: list
    # ignore_list: list
    # logger: Logger

    + included_files: dict
    - diagnostic_print: str

    __init__(file, abs_path, include_list, ignore_list, logger)

    + retrieve_code(): dict

    if_any(path in file.path) then (yes)
        if not_any(ignored_file in file.path) then (yes)
            try
                with_open()
                logger.info()
            catch (FileNotFoundError)
                print()
                logger.warning()
            end try
        end not_any
    end if_any
    return included_files
}

UmlDiagram --> Logger

@enduml
2024-01-20 22:30:47,949 - INFO - UML code generated for src/routes/retrieve_code.py: @startuml

import git
import json
import os
import logging
from logging import handlers

package "import git" {
    class Git
}

package "import json" {
    class Json
}

package "import os" {
    class Os {
        + makedirs(log_directory, exist_ok)
        + join(path, *paths)
    }
}

package "import logging" {
    class Logging {
        - logger
        - log_formatter
        - log_handler
        + handlers
        + getLogger()
        + setLevel(level)
        + addHandler(handler)
    }
    class handlers {
        + RotatingFileHandler(filename, maxBytes, backupCount)
        + setFormatter(formatter)
    }
}

Git --> Git.Repo
Json --> Json.dump()
Os --> Os.makedirs()
Os --> Os.join()
handlers --> handlers.RotatingFileHandler()
handlers --> handlers.setFormatter()
Logging --> Logging.getLogger()
Logging --> Logging.setLevel()
Logging --> Logging.addHandler()

@enduml
2024-01-20 22:30:47,949 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-20 22:30:47,949 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-20 22:30:47,950 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-20 22:30:47,950 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-20 22:30:47,952 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-20 22:30:47,953 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:30:47,954 - DEBUG - send_request_headers.complete
2024-01-20 22:30:47,954 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:30:47,954 - DEBUG - send_request_body.complete
2024-01-20 22:30:47,955 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:30:56,034 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:30:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'8014'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'9205da41b416aff043c196ca3a146eb2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd2eddb73138b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:30:56,036 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:30:56,037 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:30:56,038 - DEBUG - receive_response_body.complete
2024-01-20 22:30:56,038 - DEBUG - response_closed.started
2024-01-20 22:30:56,039 - DEBUG - response_closed.complete
2024-01-20 22:30:56,039 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:30:56,040 - INFO - Received response from OpenAI: t_repo_name = git_repo_url.split('/')[-1]  # Extract the name of the repository from the git URL

    # Clone the repository to a temporary directory
    with tempfile.TemporaryDirectory() as tempdir:
        # Clone the repository using the clone_repo function from retrieve_code.py
        clone_repo(git_repo_url, tempdir)

        # Retrieve the code from the repository using the retrieve_code function from retrieve_code.py
        code = retrieve_code(tempdir)

        # Generate the UML content by passing the code through the generate_content function from code_to_uml.py
        content = generate_content(code)

        # Write the UML content to a file in the specified output directory
        with open(os.path.join(output_directory, git_repo_name + '.puml'), 'w') as output_file:
            output_file.write(content)

 1. Class Diagram:
@startuml
class uml_from_repo {
    - tempdir : tempfile.TemporaryDirectory 
    - git_repo_url : String 
    - output_directory : String 
    - git_repo_name : String
    - code : String
    - content : String

    + process_request(data) : void
}

class tempfile.TemporaryDirectory {
    - name : String

    + __init__(suffix="", prefix="tmp", dir=None) : void
    + __enter__() : tempfile.TemporaryDirectory 
    + __exit__(exc_type, exc_value, traceback) : void
    + cleanup() : void
    + __repr__() : String
}

class logging {
    - log_directory : String
    - log_filename : String
    - log_formatter : logging.Formatter
    - log_handler : handlers.RotatingFileHandler
    - logger : logging.Logger

    + __init__() : void
    + __format__() : String
    + format(record) : String
    + addHandler(hdlr) : void
    + removeHandler(hdlr) : void
    + setLevel(lvl) : void
    + _logWhenEnabled(level, msg, args, exc_info=None, extra=None, stack_info=False, stacklevel=1, **kwargs) : void
    + debug(msg, *args, **kwargs) : void
    + info(msg, *args, **kwargs) : void
    + warning(msg, *args, **kwargs) : void
    + error(msg, *args, **kwargs) : void
    + critical(msg, *args, **kwargs) : void
}

class handlers.RotatingFileHandler {
    - mode : String
    - maxBytes : int
    - backupCount : int

    + __init__(filename, mode='a', maxBytes=0, backupCount=0, encoding=None, delay=False) : void
    + doRollover() : void
    + shouldRollover(record) : boolean
    + emit(record) : void
    + __repr__() : String
}

class git {
    + __init__() : void
    + Repo(path, search_parent_directories=True) : git.Repo
    + clean() : index.cleanup
}

class retrieve_code {
    + clone_repo(git_repo_url, tempdir) : void
    + retrieve_code(tempdir) : String
}

class code_to_uml {
    + generate_content(code) : String
}

class os {
    + makedirs(path, mode=0o777, exist_ok=False) : void
    + getcwd() : String
    + chdir(path) : void
}

@enduml


2. Object Diagram:
@startuml
object uml_from_repo
object tempfile_temporarydirectory
object logger
object logging_formatter
object logging_handler
object git_repo_url
object output_directory
object git_repo_name
object code
object content

uml_from_repo .. tempfile_temporarydirectory
tempfile_temporarydirectory .. logger
logger .. logging_formatter
logger .. logging_handler
uml_from_repo .. git_repo_url
uml_from_repo .. output_directory
uml_from_repo .. git_repo_name
uml_from_repo .. code
uml_from_repo .. content

@enduml
2024-01-20 22:30:56,041 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-20 22:30:56,043 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-20 22:30:56,044 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:30:56,045 - DEBUG - send_request_headers.complete
2024-01-20 22:30:56,045 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:30:56,045 - DEBUG - send_request_body.complete
2024-01-20 22:30:56,045 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:30:59,482 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:30:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3246'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'13856ff6a9cae65fe7b4a8639c26ba42'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd3210842138b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:30:59,484 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:30:59,485 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:30:59,486 - DEBUG - receive_response_body.complete
2024-01-20 22:30:59,486 - DEBUG - response_closed.started
2024-01-20 22:30:59,486 - DEBUG - response_closed.complete
2024-01-20 22:30:59,487 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:30:59,489 - INFO - Received response from OpenAI: )
        
        # Generate UML
        uml = generate_uml(repo, config)

        # Save UML to output directory
        if not os.path.exists(output_directory):
            os.makedirs(output_directory)
        with open(f'{output_directory}/uml.png', 'wb') as f:
            f.write(uml)

        return {"message": "UML successfully generated"}, 200


@startuml

class "UML Generator" as Gen {
    - thub_access_token: String
    - branch_name: String
    - git_repo_url: String
    - output_directory: String
    - github_access_token: String
    - logger: Logging
    + __init__(data: Dict)
    + generate_uml(repo: Repo, config: Dict): byte[]
    + clone_repo(git_repo_url: String, temp_dir: String, github_access_token: String): Repo
}

class "Logging" as Log {
    + error(message: String)
    + info(message: String)
}

class "Repo" as Repo {
    - url: String
    - local_path: String
    + clone_temp(dir: String): void
    + get_file(path: String): File
}

class "File" as File {
    - path: String
    + open(mode: String, encoding: String): TextIOWrapper
}

class "TextIOWrapper" as TextIO {
    - mode: String
    - file: File
    - encoding: String
    + read(): String
    + write(data: String): void
}


Gen ..> Log: uses
Gen ..> Repo: uses
Log ..> Repo: uses
Repo ..> File: contains
File ..> TextIO: uses


@enduml
2024-01-20 22:30:59,490 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-20 22:30:59,492 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-20 22:30:59,494 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:30:59,495 - DEBUG - send_request_headers.complete
2024-01-20 22:30:59,495 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:30:59,495 - DEBUG - send_request_body.complete
2024-01-20 22:30:59,495 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:31:01,244 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:31:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1631'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'35d88308a802d8fe880f7f84a8a42d06'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd3362f55138b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:31:01,246 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:31:01,247 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:31:01,247 - DEBUG - receive_response_body.complete
2024-01-20 22:31:01,248 - DEBUG - response_closed.started
2024-01-20 22:31:01,248 - DEBUG - response_closed.complete
2024-01-20 22:31:01,249 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:31:01,251 - INFO - Received response from OpenAI: 

@startuml
class TraverseDirectories {
    repo: Repository
    temp_dir: str
    config: dict

    +traverse_directories(repo, temp_dir, config): dict
}

class Repository {
    tree(): Tree
}

class Tree {
    traverse(): Iterator
}

class Iterator {
    type: str
    path: str
}

TraverseDirectories *-- Repository
Repository *-- Tree
Tree *-- Iterator

@enduml

@startuml
class TraverseDirectories {

    -included_files: dict

    +traverse_directories(repo, temp_dir, config): dict
}

class Repository {
    tree(): Tree
}

class Tree {
    traverse(): Iterator
}

class Iterator {
    type: str
    path: str
}

TraverseDirectories ..> Repository
Repository ..> Tree
Tree ..> Iterator

@enduml
2024-01-20 22:31:01,251 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-20 22:31:01,253 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-20 22:31:01,255 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:31:01,255 - DEBUG - send_request_headers.complete
2024-01-20 22:31:01,255 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:31:01,256 - DEBUG - send_request_body.complete
2024-01-20 22:31:01,256 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:31:03,241 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:31:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1859'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'f63305236b37eb08478494e3fca472b4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd340fa94138b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:31:03,243 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:31:03,244 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:31:03,246 - DEBUG - receive_response_body.complete
2024-01-20 22:31:03,246 - DEBUG - response_closed.started
2024-01-20 22:31:03,247 - DEBUG - response_closed.complete
2024-01-20 22:31:03,247 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:31:03,249 - INFO - Received response from OpenAI:  UML Diagram:


@startuml

class T {
   - included_files
   - output_directory
  
   # t(included_files, output_directory)
   + t() : None
}

class Logger {
   - info(message)
   - error(message)
   
   # info(message)
   + info() : None
   
   # error(message)
   + error() : None
}

class Path {
   - file_paths
   
   # Path(file_paths)
   + Path() : None
}

class UMLDiagram {
   - final_output_paths
   
   # UMLDiagram(final_output_paths)
   + UMLDiagram() : None
   
   + save_diagram(path) : None
}

class TempDirectory {
   # temp_dir
   
   # TempDirectory(temp_dir)
   + TempDirectory() : None
   
   + delete_temp_dir() : None
}

T o--> Logger

UMLDiagram --> Logger

Path --> UMLDiagram

TempDirectory --> T

@enduml
2024-01-20 22:31:03,249 - INFO - UML code generated for src/routes/uml_from_repo.py: @startuml
class uml_from_repo {
    - tempdir : tempfile.TemporaryDirectory 
    - git_repo_url : String 
    - output_directory : String 
    - git_repo_name : String
    - code : String
    - content : String

    + process_request(data) : void
}

class tempfile.TemporaryDirectory {
    - name : String

    + __init__(suffix="", prefix="tmp", dir=None) : void
    + __enter__() : tempfile.TemporaryDirectory 
    + __exit__(exc_type, exc_value, traceback) : void
    + cleanup() : void
    + __repr__() : String
}

class logging {
    - log_directory : String
    - log_filename : String
    - log_formatter : logging.Formatter
    - log_handler : handlers.RotatingFileHandler
    - logger : logging.Logger

    + __init__() : void
    + __format__() : String
    + format(record) : String
    + addHandler(hdlr) : void
    + removeHandler(hdlr) : void
    + setLevel(lvl) : void
    + _logWhenEnabled(level, msg, args, exc_info=None, extra=None, stack_info=False, stacklevel=1, **kwargs) : void
    + debug(msg, *args, **kwargs) : void
    + info(msg, *args, **kwargs) : void
    + warning(msg, *args, **kwargs) : void
    + error(msg, *args, **kwargs) : void
    + critical(msg, *args, **kwargs) : void
}

class handlers.RotatingFileHandler {
    - mode : String
    - maxBytes : int
    - backupCount : int

    + __init__(filename, mode='a', maxBytes=0, backupCount=0, encoding=None, delay=False) : void
    + doRollover() : void
    + shouldRollover(record) : boolean
    + emit(record) : void
    + __repr__() : String
}

class git {
    + __init__() : void
    + Repo(path, search_parent_directories=True) : git.Repo
    + clean() : index.cleanup
}

class retrieve_code {
    + clone_repo(git_repo_url, tempdir) : void
    + retrieve_code(tempdir) : String
}

class code_to_uml {
    + generate_content(code) : String
}

class os {
    + makedirs(path, mode=0o777, exist_ok=False) : void
    + getcwd() : String
    + chdir(path) : void
}

@enduml
2024-01-20 22:31:03,250 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-20 22:31:03,252 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-20 22:31:03,252 - INFO - Skipping empty file: src/scripts/__init__.py
2024-01-20 22:31:03,252 - INFO - Processing file: src/scripts/execute_generate_uml.py
2024-01-20 22:31:03,252 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import json
import os
import requests
import logging
from logging import handlers
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure logging to write to a file
log_directory = '../../logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'execute_generate_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


# Configure logging
logging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))
# Configuration file path
config_file_path = os.path.join(cu
2024-01-20 22:31:03,254 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nimport json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(cu", 'max_tokens': 1024}}
2024-01-20 22:31:03,255 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:31:03,256 - DEBUG - send_request_headers.complete
2024-01-20 22:31:03,256 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:31:03,256 - DEBUG - send_request_body.complete
2024-01-20 22:31:03,256 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:31:03,470 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:31:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'61'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'bcf8900f96e6351a71498bae266ddca2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd34e085a138b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:31:03,472 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:31:03,473 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:31:03,473 - DEBUG - receive_response_body.complete
2024-01-20 22:31:03,473 - DEBUG - response_closed.started
2024-01-20 22:31:03,474 - DEBUG - response_closed.complete
2024-01-20 22:31:03,474 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:31:03,475 - INFO - Received response from OpenAI: 
2024-01-20 22:31:03,476 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

rrent_dir, 'config.json')

# Read configuration from the JSON file
with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

# Retrieve the GitHub access token from environment variables
github_token = os.getenv('GITHUB_PAT')

# Endpoint URL
url = 'http://127.0.0.1:5000/generate-uml'

# Headers
headers = {
    'Content-Type': 'application/json'
}

# Update the GitHub access token and local directory in the config data
config_data['gitHubAccessToken'] = github_token
config_data['local_dir'] = os.path.join(current_dir, '../..', 'output')

# Log the JSON data being sent in the request
logging.info(f'Sending JSON data to {url}:')
logging.info(json.dumps(config_data, indent=2))

try:
    # Make the POST request
    response = requests.post(url, headers=headers, json=config_data)

    # Log the response from the server
    logging.info(f'Response from server ({url}):')
    logging.info(f'Status Code: {response.status_code}')
    logging.info(f'Response Text: {response.text}')

    #
2024-01-20 22:31:03,477 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nrrent_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    #", 'max_tokens': 1024}}
2024-01-20 22:31:03,478 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:31:03,479 - DEBUG - send_request_headers.complete
2024-01-20 22:31:03,479 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:31:03,479 - DEBUG - send_request_body.complete
2024-01-20 22:31:03,479 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:31:04,391 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:31:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'767'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'ea303f895bda519d0b36dc50cc728d3e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd34ee92c138b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:31:04,393 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:31:04,394 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:31:04,395 - DEBUG - receive_response_body.complete
2024-01-20 22:31:04,395 - DEBUG - response_closed.started
2024-01-20 22:31:04,396 - DEBUG - response_closed.complete
2024-01-20 22:31:04,396 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:31:04,398 - INFO - Received response from OpenAI:  Save the response as a PNG file
    with open('uml_diagram.png', 'wb') as output_file:
        output_file.write(response.content)

except requests.exceptions.ConnectionError:
    logging.error('Error connecting to server, please make sure the server is running.')

```

[Image of .puml UML diagram](puml_diagram.png)
2024-01-20 22:31:04,398 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

 Print the response from the server
    print(response.text)

    # Save the response to a file in the output directory
    output_dir = os.path.join(current_dir, '../..', 'output')
    os.makedirs(output_dir, exist_ok=True)
    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:
        json.dump(response.json(), output_file, indent=2)

except Exception as e:
    # Log any exceptions that occur
    logging.error(f'Error occurred: {str(e)}')
2024-01-20 22:31:04,400 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')", 'max_tokens': 1024}}
2024-01-20 22:31:04,401 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:31:04,401 - DEBUG - send_request_headers.complete
2024-01-20 22:31:04,402 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:31:04,402 - DEBUG - send_request_body.complete
2024-01-20 22:31:04,402 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:31:05,456 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:31:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'964'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'425af968fd35d3a81bc2f02bb3d3c6c0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd354bf62138b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:31:05,459 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:31:05,459 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:31:05,460 - DEBUG - receive_response_body.complete
2024-01-20 22:31:05,461 - DEBUG - response_closed.started
2024-01-20 22:31:05,461 - DEBUG - response_closed.complete
2024-01-20 22:31:05,461 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:31:05,464 - INFO - Received response from OpenAI: 

@startuml

object "response" {
    text
    json()
}

start
    :print(response.text);
    :output_dir = os.path.join(current_dir, '../..', 'output');
    :os.makedirs(output_dir, exist_ok=True);
    :open(os.path.join(output_dir, 'response.json'), 'w');
    :json.dump(response.json(), output_file, indent=2);

if (Exception Occurs?) then (yes)
    :logging.error(f'Error occurred: {str(e)}');
else (no)
endif

end

@enduml
2024-01-20 22:31:05,464 - ERROR - Error during UML generation: '@startuml' is not in list
2024-01-20 22:31:05,464 - INFO - Cleaning up temporary directory
2024-01-20 22:31:05,648 - INFO - 127.0.0.1 - - [20/Jan/2024 22:31:05] "POST /generate-uml HTTP/1.1" 200 -
2024-01-20 22:31:31,353 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:31:31,354 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 22:31:31,363 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-20 22:31:31,363 - INFO - [33mPress CTRL+C to quit[0m
2024-01-20 22:31:31,364 - INFO -  * Restarting with stat
2024-01-20 22:31:31,627 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:31:31,628 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-20 22:31:31,636 - WARNING -  * Debugger is active!
2024-01-20 22:31:31,641 - INFO -  * Debugger PIN: 139-904-016
2024-01-20 22:31:47,937 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-20 22:31:47,937 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-20 22:31:47,937 - INFO - Received local_dir: ./output
2024-01-20 22:31:47,937 - INFO - Received gitHubAccessToken: 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
2024-01-20 22:31:47,938 - INFO - Cleaning up temporary directory
2024-01-20 22:31:47,938 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 22:31:47,941 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-20 22:31:47,941 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp5ene4cug'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-20 22:31:53,622 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp5ene4cug'])'s unused stdout: 
2024-01-20 22:31:53,624 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-20 22:31:53,624 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp5ene4cug, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 22:31:53,630 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp5ene4cug, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-20 22:31:53,653 - DEBUG - Type of included_files: <class 'dict'>
2024-01-20 22:31:53,653 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-20 22:31:53,653 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-20 22:31:53,653 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-20 22:31:53,654 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-20 22:31:53,654 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-20 22:31:53,654 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-20 22:31:53,655 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-20 22:31:53,667 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 22:31:53,873 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1058e3090>
2024-01-20 22:31:53,875 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105701b50> server_hostname='api.openai.com' timeout=5.0
2024-01-20 22:31:53,930 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105937550>
2024-01-20 22:31:53,931 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:31:53,932 - DEBUG - send_request_headers.complete
2024-01-20 22:31:53,932 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:31:53,933 - DEBUG - send_request_body.complete
2024-01-20 22:31:53,933 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:31:57,475 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:31:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3403'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'5504657bb2beda213205a4babf191835'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=za0fLKx3sjBqZtBLFDHTlr8jzPzKVa23gI3uPAj4vfI-1705811517-1-AThcgQ5h0iuNmESor0FQ8Ga4U3h9DhdcyS+nM1nkg4Ts7JSPtkcbISE3p36TuFAEC8GqFdLemJQGfbqtfoTaYQs=; path=/; expires=Sun, 21-Jan-24 05:01:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=8UevCMPOXdfpqWKkLWaFVZ4f9wQXVGi8gUPfqBF_7qk-1705811517442-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd48a4e7fb09d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:31:57,478 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:31:57,479 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:31:57,479 - DEBUG - receive_response_body.complete
2024-01-20 22:31:57,480 - DEBUG - response_closed.started
2024-01-20 22:31:57,480 - DEBUG - response_closed.complete
2024-01-20 22:31:57,480 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:31:57,483 - INFO - Received response from OpenAI: 
        if not code:
            continue
        # Skip if the file is not a Python file
        if os.path.splitext(file_path)[1] != '.py':
            continue
        # Add the file path to the list
        file_paths.append(file_path)
        # Add the code to the generated_code string
        generated_code += code
    # Pass the generated_code and file_paths to the OpenAI API
    api.generate_code(generated_code, file_paths, output_directory)

## UML Diagram ##
@startuml
class OpenAIAPI {
    - openai_key : String

    + generate_code(generated_code, file_paths, output_directory) : void
}

class logging {
    - log_formatter : Formatter
    - log_handler : RotatingFileHandler

    # sets the log level
    + setLevel(level) : void
    # set the logging formatter
    + setFormatter(fmt) : void
    # add a handler to the logger
    + addHandler(hdlr) : void
    # rotates the log file
    + RotatingFileHandler(filename,maxBytes,backupCount) : void
}

class handlers {
    + RotatingFileHandler(filename,maxBytes,backupCount) : void
}

class os {
    + makedirs(name,exist_ok) : void
}

class code_to_uml {

}

openai_key ..> OpenAIAPI : has-a
OpenAIAPI ..> api : instantiate
api ..> OpenAIAPI : generate_code
code_to_uml ..> code_to_uml : generate_content
logging ..> handlers : uses
handlers .down.> logfile : rotates
os ..> code_to_uml : uses
OpenAIAPI ..> logging : logs
@enduml

2024-01-20 22:31:57,484 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-20 22:31:57,485 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-20 22:31:57,486 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:31:57,487 - DEBUG - send_request_headers.complete
2024-01-20 22:31:57,487 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:31:57,487 - DEBUG - send_request_body.complete
2024-01-20 22:31:57,487 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:32:01,902 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:32:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4313'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'69dee39b7855dfb2852fcd27b1b5deb1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd4a06bb6b09d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:32:01,905 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:32:01,906 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:32:01,906 - DEBUG - receive_response_body.complete
2024-01-20 22:32:01,906 - DEBUG - response_closed.started
2024-01-20 22:32:01,907 - DEBUG - response_closed.complete
2024-01-20 22:32:01,907 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:32:01,910 - INFO - Received response from OpenAI: _paths})


@startuml

class UMLGenerator {
    - code: string
    - file_path: string
    - generated_code_for_file: string
    - generated_code: string
    - file_name: string
    - final_output_path: string
    - output_directory: string
    - file_paths: string[]
    - api: API

    + generate_uml(code: string, file_path: string, output_directory: string): string[]
    + save_uml_code(generated_code_for_file: string, final_output_path: string): string
    + log_info(message: string): void
    + log_error(message: string): void
    + check_empty(code: string): boolean
    + check_generation_result(generated_code_for_file: string): boolean
}

UMLGenerator --> API : uses

class API {
    - UML code

    + generate_from_code(code: string): string
    + save_generated_output(code: string, output_path: string): string
}

API --> UMLGenerator : returns

if (check_empty(code)) then (true)
    UMLGenerator -> UMLGenerator : log_info()
    continue
else
    UMLGenerator -> UMLGenerator : log_info()
    generated_code_for_file = API -> API : generate_from_code()
    UMLGenerator -> UMLGenerator : log_info()
    if (check_generation_result(generated_code_for_file) or "UML generation failed") then (true)
        UMLGenerator -> UMLGenerator : log_error()
        UMLGenerator -> UMLGenerator : raise ValueError()
    else
        UMLGenerator -> UMLGenerator : +
    UMLGenerator --> API : uses
    API -> API : save_generated_output()
    UMLGenerator -> UMLGenerator : +
UMLGenerator --> logger : uses
UMLGenerator -> logger : gets file_path, generated_code_for_file and generated_code

if (final_output_path) then (true)
    UMLGenerator -> UMLGenerator : log_info()
    UMLGenerator -> UMLGenerator : file_paths.append(final_output_path)
Logger -> logger : gets file_paths
Logger -> logger : log_info()

@enduml
2024-01-20 22:32:01,911 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-20 22:32:01,912 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-20 22:32:01,914 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:32:01,914 - DEBUG - send_request_headers.complete
2024-01-20 22:32:01,914 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:32:01,915 - DEBUG - send_request_body.complete
2024-01-20 22:32:01,915 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:32:03,112 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:32:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1068'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'99fa3618e06d1b93852bd86c6737d67b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd4bc1c42b09d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:32:03,114 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:32:03,115 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:32:03,116 - DEBUG - receive_response_body.complete
2024-01-20 22:32:03,116 - DEBUG - response_closed.started
2024-01-20 22:32:03,116 - DEBUG - response_closed.complete
2024-01-20 22:32:03,117 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:32:03,118 - INFO - Received response from OpenAI: 
```
@startuml

class CodeGenerator {
    - file_paths: list
    - generated_code: str

    + generate_code(modules)
    - _get_file_paths()
}

CodeGenerator --> modules: uses

class Module {
    - name: str
    - code: str
}

Module --> CodeGenerator: belongs to

CodeGenerator *- _paths: file_paths
CodeGenerator *- _paths: generated_code

CodeGenerator --> _get_file_paths()

_get_file_paths() --> _paths: sets

@enduml
2024-01-20 22:32:03,119 - INFO - UML code generated for src/routes/code_to_uml.py: @startuml
class OpenAIAPI {
    - openai_key : String

    + generate_code(generated_code, file_paths, output_directory) : void
}

class logging {
    - log_formatter : Formatter
    - log_handler : RotatingFileHandler

    # sets the log level
    + setLevel(level) : void
    # set the logging formatter
    + setFormatter(fmt) : void
    # add a handler to the logger
    + addHandler(hdlr) : void
    # rotates the log file
    + RotatingFileHandler(filename,maxBytes,backupCount) : void
}

class handlers {
    + RotatingFileHandler(filename,maxBytes,backupCount) : void
}

class os {
    + makedirs(name,exist_ok) : void
}

class code_to_uml {

}

openai_key ..> OpenAIAPI : has-a
OpenAIAPI ..> api : instantiate
api ..> OpenAIAPI : generate_code
code_to_uml ..> code_to_uml : generate_content
logging ..> handlers : uses
handlers .down.> logfile : rotates
os ..> code_to_uml : uses
OpenAIAPI ..> logging : logs
@enduml_paths})


@startuml

class UMLGenerator {
    - code: string
    - file_path: string
    - generated_code_for_file: string
    - generated_code: string
    - file_name: string
    - final_output_path: string
    - output_directory: string
    - file_paths: string[]
    - api: API

    + generate_uml(code: string, file_path: string, output_directory: string): string[]
    + save_uml_code(generated_code_for_file: string, final_output_path: string): string
    + log_info(message: string): void
    + log_error(message: string): void
    + check_empty(code: string): boolean
    + check_generation_result(generated_code_for_file: string): boolean
}

UMLGenerator --> API : uses

class API {
    - UML code

    + generate_from_code(code: string): string
    + save_generated_output(code: string, output_path: string): string
}

API --> UMLGenerator : returns

if (check_empty(code)) then (true)
    UMLGenerator -> UMLGenerator : log_info()
    continue
else
    UMLGenerator -> UMLGenerator : log_info()
    generated_code_for_file = API -> API : generate_from_code()
    UMLGenerator -> UMLGenerator : log_info()
    if (check_generation_result(generated_code_for_file) or "UML generation failed") then (true)
        UMLGenerator -> UMLGenerator : log_error()
        UMLGenerator -> UMLGenerator : raise ValueError()
    else
        UMLGenerator -> UMLGenerator : +
    UMLGenerator --> API : uses
    API -> API : save_generated_output()
    UMLGenerator -> UMLGenerator : +
UMLGenerator --> logger : uses
UMLGenerator -> logger : gets file_path, generated_code_for_file and generated_code

if (final_output_path) then (true)
    UMLGenerator -> UMLGenerator : log_info()
    UMLGenerator -> UMLGenerator : file_paths.append(final_output_path)
Logger -> logger : gets file_paths
Logger -> logger : log_info()

@enduml```
@startuml

class CodeGenerator {
    - file_paths: list
    - generated_code: str

    + generate_code(modules)
    - _get_file_paths()
}

CodeGenerator --> modules: uses

class Module {
    - name: str
    - code: str
}

Module --> CodeGenerator: belongs to

CodeGenerator *- _paths: file_paths
CodeGenerator *- _paths: generated_code

CodeGenerator --> _get_file_paths()

_get_file_paths() --> _paths: sets

@enduml
2024-01-20 22:32:03,119 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-20 22:32:03,120 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-20 22:32:03,120 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-20 22:32:03,120 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-20 22:32:03,122 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-20 22:32:03,124 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:32:03,124 - DEBUG - send_request_headers.complete
2024-01-20 22:32:03,124 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:32:03,125 - DEBUG - send_request_body.complete
2024-01-20 22:32:03,125 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:32:08,682 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:32:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5424'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'5cabb5478ff926e1f439749b01ba65a8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd4c3bb37b09d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:32:08,685 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:32:08,686 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:32:08,687 - DEBUG - receive_response_body.complete
2024-01-20 22:32:08,687 - DEBUG - response_closed.started
2024-01-20 22:32:08,687 - DEBUG - response_closed.complete
2024-01-20 22:32:08,688 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:32:08,691 - INFO - Received response from OpenAI: 
        # Check out the latest commit
        head = repo.head.reference
        repo.git.checkout(head)

        # Load the repository's code into a dictionary
        code_dict = {}
        for root, dirs, files in os.walk(temp_dir):
            for file in files:
                if not file.startswith('.'):  # Ignore hidden files
                    filepath = os.path.join(root, file)
                    with open(filepath, 'r') as f:
                        code_dict[filepath] = f.read()

        # Convert the dictionary to JSON and write to a file
        code_json = json.dumps(code_dict)
        with open('code.json', 'w') as f:
            f.write(code_json)

        logger.info("Successfully retrieved code and saved to 'code.json' file.")
        return True

    except git.exc.GitCommandError:
        logger.error("Error cloning repository. Please check the URL and access token.")
        return False


# Define main function
def main():
    # Get repository URL and destination directory from user
    repo_url = input("Enter the repository URL: ")
    temp_dir = input("Enter the destination directory: ")
    
    # Optional: Get user's access token for private repositories
    access_token = input("Enter your access token (optional): ")
    
    # Call the clone_repo function
    clone_repo(repo_url, temp_dir, access_token)


# Call main function
if __name__ == '__main__':
    main()
    
@startuml

' Import statements
package "import git" as git
package "import json" as json
package "import os" as os
package "import logging" as logging
package "from logging import handlers" as handlers

' Main class
class Main {
    -log_directory: String
    -log_filename: String
    -log_handler: RotatingFileHandler
    -log_formatter: Formatter
    -logger: Logger
    -clone_repo(repo_url, temp_dir, access_token): boolean
    +main()
}

' Association between Main and import packages
Main --> git
Main --> json
Main --> os
Main --> logging
Main --> handlers

' Repository class
class Repository {
    -repo_url: String
    -access_token: String
    -temp_dir: String
    +clone_repo(repo_url, temp_dir, access_token): boolean
    -checkout_commmit()
}

' Association between Main and Repository classes
Main ..> Repository : create

' Association between Repository and git, os, and logging packages
Repository --> git
Repository --> os
Repository --> logging

' Association between os package and logger class
os --> logger

' Association between logging package and handlers package
logging --> handlers

' Association between handlers package and RotatingFileHandler and Formatter classes
handlers --> "RotatingFileHandler"
handlers --> "Formatter"

' Association between Main and logger class
Main ..> logger : "get"

' Association between logger class and FileHandler and Formatter classes
logger --> "RotatingFileHandler"
logger --> "Formatter"

@enduml
2024-01-20 22:32:08,692 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-20 22:32:08,694 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-20 22:32:08,696 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:32:08,696 - DEBUG - send_request_headers.complete
2024-01-20 22:32:08,696 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:32:08,696 - DEBUG - send_request_body.complete
2024-01-20 22:32:08,697 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:32:11,771 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:32:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2948'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'641ab71d710ecdb36df5349c5eb51f13'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd4e67b8eb09d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:32:11,774 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:32:11,774 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:32:11,775 - DEBUG - receive_response_body.complete
2024-01-20 22:32:11,776 - DEBUG - response_closed.started
2024-01-20 22:32:11,776 - DEBUG - response_closed.complete
2024-01-20 22:32:11,776 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:32:11,778 - INFO - Received response from OpenAI:  if file.path not in ignore_list and file.path in include_list:
                  included_files[file.path] = file.data_stream.read()

        return included_files

@startuml
class Repo {
    -url: String
    -branch: String
    -code: Map<String, String>
    +fetch()
    +checkout(branch_name)
    +get_code(file_path)
}
note top : Represents a remote repository\nwith code that can be retrieved.
Repo *-- Logger
Repo --> File
note top : Contains code files and their paths.
Repo o-- Config
class Logger {
    -level: String
    +debug(message)
    +info(message)
    +error(message)
}
note top : Logs messages with different severity levels.
Logger ..> File
Config *-- Logger
Config --> File
note top : Contains config settings for code retrieval.
Config *-up-> ignore: String[]
Config *-up-> include: String[]
File {
    -path: String
    -data: String
}
note top : Represents a file with its path and data.
File .up.|> Logger
File ..> Repo
Config ..> File: Uses File objects for code retrieval.
note left : Retrieves code files based on\nconfig settings.
Repo -> File: retrieve_code()
note left : Returns a map of\nincluded file paths and\ncorresponding code.
note top : Exception handling if\ncode retrieval fails.
Repo ..> Exception
Exception --> Logger: Log error message
note right : Raises ValueError if\ncode retrieval fails.
2024-01-20 22:32:11,778 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-20 22:32:11,780 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-20 22:32:11,781 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:32:11,782 - DEBUG - send_request_headers.complete
2024-01-20 22:32:11,782 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:32:11,782 - DEBUG - send_request_body.complete
2024-01-20 22:32:11,782 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:32:12,549 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:32:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'676'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'0f6ba4b430fe568d83ce0ddf2c8eb039'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd4f9cbe2b09d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:32:12,551 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:32:12,552 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:32:12,553 - DEBUG - receive_response_body.complete
2024-01-20 22:32:12,553 - DEBUG - response_closed.started
2024-01-20 22:32:12,553 - DEBUG - response_closed.complete
2024-01-20 22:32:12,553 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:32:12,555 - INFO - Received response from OpenAI: 

@startuml

class Main {
    -include_list
    -ignore_list
    
    +get_included_files()
}

class File {
    -path
    -abspath
    -content
}

class Logger {
    -info()
    -warning()
    -error()
}

Main *-- File
Main "1" -- Logger : logger

@enduml
2024-01-20 22:32:12,555 - INFO - UML code generated for src/routes/retrieve_code.py: @startuml

' Import statements
package "import git" as git
package "import json" as json
package "import os" as os
package "import logging" as logging
package "from logging import handlers" as handlers

' Main class
class Main {
    -log_directory: String
    -log_filename: String
    -log_handler: RotatingFileHandler
    -log_formatter: Formatter
    -logger: Logger
    -clone_repo(repo_url, temp_dir, access_token): boolean
    +main()
}

' Association between Main and import packages
Main --> git
Main --> json
Main --> os
Main --> logging
Main --> handlers

' Repository class
class Repository {
    -repo_url: String
    -access_token: String
    -temp_dir: String
    +clone_repo(repo_url, temp_dir, access_token): boolean
    -checkout_commmit()
}

' Association between Main and Repository classes
Main ..> Repository : create

' Association between Repository and git, os, and logging packages
Repository --> git
Repository --> os
Repository --> logging

' Association between os package and logger class
os --> logger

' Association between logging package and handlers package
logging --> handlers

' Association between handlers package and RotatingFileHandler and Formatter classes
handlers --> "RotatingFileHandler"
handlers --> "Formatter"

' Association between Main and logger class
Main ..> logger : "get"

' Association between logger class and FileHandler and Formatter classes
logger --> "RotatingFileHandler"
logger --> "Formatter"

@endumlif file.path not in ignore_list and file.path in include_list:
                  included_files[file.path] = file.data_stream.read()

        return included_files

@startuml
class Repo {
    -url: String
    -branch: String
    -code: Map<String, String>
    +fetch()
    +checkout(branch_name)
    +get_code(file_path)
}
note top : Represents a remote repository\nwith code that can be retrieved.
Repo *-- Logger
Repo --> File
note top : Contains code files and their paths.
Repo o-- Config
class Logger {
    -level: String
    +debug(message)
    +info(message)
    +error(message)
}
note top : Logs messages with different severity levels.
Logger ..> File
Config *-- Logger
Config --> File
note top : Contains config settings for code retrieval.
Config *-up-> ignore: String[]
Config *-up-> include: String[]
File {
    -path: String
    -data: String
}
note top : Represents a file with its path and data.
File .up.|> Logger
File ..> Repo
Config ..> File: Uses File objects for code retrieval.
note left : Retrieves code files based on\nconfig settings.
Repo -> File: retrieve_code()
note left : Returns a map of\nincluded file paths and\ncorresponding code.
note top : Exception handling if\ncode retrieval fails.
Repo ..> Exception
Exception --> Logger: Log error message
note right : Raises ValueError if\ncode retrieval fails.@startuml

class Main {
    -include_list
    -ignore_list
    
    +get_included_files()
}

class File {
    -path
    -abspath
    -content
}

class Logger {
    -info()
    -warning()
    -error()
}

Main *-- File
Main "1" -- Logger : logger

@enduml
2024-01-20 22:32:12,556 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-20 22:32:12,556 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-20 22:32:12,557 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-20 22:32:12,557 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-20 22:32:12,559 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-20 22:32:12,560 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:32:12,560 - DEBUG - send_request_headers.complete
2024-01-20 22:32:12,561 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:32:12,561 - DEBUG - send_request_body.complete
2024-01-20 22:32:12,561 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:32:16,574 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:32:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3894'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'7cd7113dd98b24cf32ea22ec57a43936'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd4fea8d5b09d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:32:16,576 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:32:16,577 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:32:16,580 - DEBUG - receive_response_body.complete
2024-01-20 22:32:16,580 - DEBUG - response_closed.started
2024-01-20 22:32:16,580 - DEBUG - response_closed.complete
2024-01-20 22:32:16,580 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:32:16,582 - INFO - Received response from OpenAI: t_username = data.get('gitUsername')  # Get the git username from the request data
    git_password = data.get('gitPassword')  # Get the git password from the request data
    result = clone_repo(git_repo_url, output_directory, git_username, git_password)  # Clone the git repository to the output directory
    if result['status'] == 'error':  # Check if there was an error during cloning
        logger.error(f"Error while cloning git repository: {result['error']}")  # Log the error message
        return {'status': 'error', 'error': result['error']}  # Return an error response
    logger.info("Git repository successfully cloned")  # Log a success message
    retrieve_code(output_directory)  # Retrieve code from cloned repository
    generate_content(output_directory)  # Generate UML diagrams from retrieved code
    logger.info("UML diagrams successfully generated")  # Log a success message
    return {'status': 'success', 'message': 'UML diagrams successfully generated'}  # Return a success response

@startuml

class RepoManager {
    - git_repo_url: string
    - output_directory: string
    - git_username: string
    - git_password: string
    - logger: Logger

    + process_request(data): dict

}

class Logger {
    - log_handler: RotatingFileHandler
    - log_formatter: Formatter

    + setFormatter(log_handler, log_formatter)
    + addHandler(log_handler)
    + setLevel(level)

}

class CodeRetriever {
    - output_directory: string

    + retrieve_code(output_directory)
}

class UMLGenerator {
    - output_directory: string

    + generate_content(output_directory)
}

RepoManager *-- Logger
RepoManager *-- CodeRetriever
RepoManager *-- UMLGenerator

CodeRetriever *-- UMLGenerator

@enduml
2024-01-20 22:32:16,583 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-20 22:32:16,585 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-20 22:32:16,586 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:32:16,587 - DEBUG - send_request_headers.complete
2024-01-20 22:32:16,587 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:32:16,587 - DEBUG - send_request_body.complete
2024-01-20 22:32:16,587 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:32:19,020 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:32:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2172'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'd0a0ed3a6b7edce08d0c0a0a13b190fa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd517cdd3b09d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:32:19,022 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:32:19,022 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:32:19,022 - DEBUG - receive_response_body.complete
2024-01-20 22:32:19,022 - DEBUG - response_closed.started
2024-01-20 22:32:19,022 - DEBUG - response_closed.complete
2024-01-20 22:32:19,022 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:32:19,023 - INFO - Received response from OpenAI: )

        # Render the UML diagrams
        for diagram_config in config['diagrams']:
            diagram_type = diagram_config.get('type')
            if diagram_type == 'class':
                render_class_diagram(repo, diagram_config, output_directory)
            elif diagram_type == 'sequence':
                render_sequence_diagram(repo, diagram_config, output_directory)
               

@startuml

class Program {
    - thub_access_token
    - branch_name
}

class Data {
    + gitHubAccessToken
    + branchName
}

Program .. Data : uses

class Logger {
    + error()
    + info()
}

Program .. Logger : uses

class tempfile {
    + mkdtemp()
}

Program .. tempfile : uses

class shutil {
    + rmtree()
}

Program .. shutil : uses

class json {
    + load()
}

Program .. json : uses

class Repo {
    + git_repo_url
    + temp_dir
}

Program .. Repo : uses

class DiagramConfig {
    + type
}

Program .. DiagramConfig : uses

class ClassDiagram {
    + render_class_diagram()
}

Program .. ClassDiagram : uses

class SequenceDiagram {
    + render_sequence_diagram()
}

Program .. SequenceDiagram : uses

@enduml
2024-01-20 22:32:19,023 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-20 22:32:19,024 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-20 22:32:19,024 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:32:19,024 - DEBUG - send_request_headers.complete
2024-01-20 22:32:19,024 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:32:19,024 - DEBUG - send_request_body.complete
2024-01-20 22:32:19,024 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:32:23,820 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:32:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4705'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'9bfab93beb3ebca89b57dc5fdb3b4b9a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd5272b77b09d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:32:23,823 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:32:23,823 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:32:23,824 - DEBUG - receive_response_body.complete
2024-01-20 22:32:23,824 - DEBUG - response_closed.started
2024-01-20 22:32:23,824 - DEBUG - response_closed.complete
2024-01-20 22:32:23,825 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:32:23,828 - INFO - Received response from OpenAI: t_diagram(included_files, config['output_format'], output_directory)

@startuml

class Main {
}

class Repo {
    +tree()
}

class Tree {
    +traverse()
}

class Config {
    -include
    -output_format
}

class IncludedFile {
    #path
}

class Logger {
    +debug(message)
    +info(message)
}

class TempDir {
}

class ContentDiagram {
    #included_files
    #output_format
    #output_directory
    +generate()
}

Main -> Repo: instantiate
Repo --> Tree: call tree()
Tree --> Tree: traverse()
Tree --> Main: return
Main -> Config: access
Main -> TempDir: instantiate
Main -> ContentDiagram: instantiate

loop for each item in Tree
    Tree --> Tree: check if item is file
    Tree -> Config: access include patterns
    Config --> Tree: return patterns
    Tree --> Main: return patterns
    Main -> Config: check if item matches any pattern
    Config --> Main: return boolean
    Main -> TempDir: create file in temporary directory
    Main -> IncludedFile: instantiate
    TempDir --> Main: return path
    Main -> IncludedFile: assign path
    Main -> Logger: debug message
    Main -> Config: access output format
    Config --> Main: return
    Main -> ContentDiagram: access included files
    ContentDiagram --> Main: return
    Main -> ContentDiagram: access output format
    ContentDiagram --> Main: return
    Main -> ContentDiagram: access output directory
    ContentDiagram --> Main: return
    Main -> ContentDiagram: call generate()
    ContentDiagram -> IncludedFile: get contents
    IncludedFile --> ContentDiagram: return
    loop for each pattern in Config
        ContentDiagram -> IncludedFile: check if path matches pattern
        IncludedFile --> ContentDiagram: return boolean
        if path matches pattern then
            break
        endif
    end
    ContentDiagram -> Logger: info message
    loop for each included file
        ContentDiagram -> IncludedFile: get path
        IncludedFile --> ContentDiagram: return
        ContentDiagram -> Config: access output format
        Config --> ContentDiagram: return
        ContentDiagram -> ContentDiagram: generate UML diagram
        ContentDiagram -> File: save diagram to output directory
    end
end

@enduml
2024-01-20 22:32:23,829 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-20 22:32:23,831 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-20 22:32:23,832 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:32:23,833 - DEBUG - send_request_headers.complete
2024-01-20 22:32:23,833 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:32:23,833 - DEBUG - send_request_body.complete
2024-01-20 22:32:23,833 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:32:27,555 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:32:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3233'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'4b49880f03672e829a67b5e8596cf736'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd5451ca4b09d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:32:27,555 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:32:27,555 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:32:27,556 - DEBUG - receive_response_body.complete
2024-01-20 22:32:27,556 - DEBUG - response_closed.started
2024-01-20 22:32:27,556 - DEBUG - response_closed.complete
2024-01-20 22:32:27,556 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:32:27,557 - INFO - Received response from OpenAI: > Class Diagram:
 
 ```puml
 class t {
    -included_files: list
    -output_directory: string
    +included_files(included_files: list, output_directory: string)
    +t(included_files: list, output_directory: string)
    +generate_UML(): dict
    -logger: Logger
    --
    +generate_UML()  200: dict
    -logger: Logger
    --
    +generate_UML()  500: dict
    -logger: Logger
}

class Logger {
    +info(message: string)
    +error(message: string)
}

class Exception {
    +Exception()
    +str(e)
}

class shutil {
    +rmtree(temp_dir: string)
}

class dict {
    +"message": string
    +"details": {
        +"Repository": string
        +"Output Paths": list
    }
}

t "1" ..> "1" Logger
t "1" ..> "many" Exception
t "many" ..> "1" shutil
t "1" ..> "1" dict
```

> Activity Diagram:

```puml
start
-- "included_files: list, output_directory: string" as input
-> if logger.info("Final output paths: {final_output_paths}")
  -> for path in final_output_paths
    -> logger.info(f"UML diagram saved at: {path}")
  -> final_output_paths -> end
  -> generate_UML() -> "message": "UML diagrams generated successfully" -> 200
  -> "error": str(e) -> 500
  -> end
-> "message": "UML diagrams generated successfully"
-> "details": {
    +"Repository": string
    +"Output Paths": list
}
-> end
2024-01-20 22:32:27,557 - INFO - UML code generated for src/routes/uml_from_repo.py: 
2024-01-20 22:32:27,557 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-20 22:32:27,558 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-20 22:32:27,558 - INFO - Skipping empty file: src/scripts/__init__.py
2024-01-20 22:32:27,558 - INFO - Processing file: src/scripts/execute_generate_uml.py
2024-01-20 22:32:27,558 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import json
import os
import requests
import logging
from logging import handlers
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure logging to write to a file
log_directory = '../../logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'execute_generate_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


# Configure logging
logging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))
# Configuration file path
config_file_path = os.path.join(cu
2024-01-20 22:32:27,559 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nimport json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(cu", 'max_tokens': 1024}}
2024-01-20 22:32:27,560 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:32:27,560 - DEBUG - send_request_headers.complete
2024-01-20 22:32:27,560 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:32:27,560 - DEBUG - send_request_body.complete
2024-01-20 22:32:27,560 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:32:37,320 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:32:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'9579'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'275f8077b36be513fcdd57e7cafed6ca'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd55c685eb09d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:32:37,323 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:32:37,323 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:32:37,324 - DEBUG - receive_response_body.complete
2024-01-20 22:32:37,325 - DEBUG - response_closed.started
2024-01-20 22:32:37,325 - DEBUG - response_closed.complete
2024-01-20 22:32:37,325 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:32:37,327 - INFO - Received response from OpenAI: rrent_dir, 'config.json')


class UMLGenerator:
    """
    Class responsible for generating UML diagrams
    """
    def __init__(self, api_key, base_url):
        self.api_key = api_key
        self.base_url = base_url
        self.logger = logging.getLogger(__name__)

    def get_classes(self, class_list):
        """
        Retrieves class information from API
        """
        self.logger.debug("Retrieving class information.")
        classes = []
        for class_name in class_list:
            self.logger.debug("Retrieving information for class: {}".format(class_name))

            # Construct API url
            class_url = self.base_url + "/classes/{}".format(class_name)

            # Add API key to headers
            headers = {'Authorization': 'apikey {}'.format(self.api_key)}

            # Make GET request to API
            response = requests.get(class_url, headers=headers)

            # Check for successful response
            if response.status_code == 200:
                class_info = response.json()
                self.logger.debug("Successfully retrieved class: {}".format(class_name))
                classes.append(class_info)

                # Check if class has parent
                if "parent_class" in class_info:
                    parent = class_info.get("parent_class")
                    self.logger.debug("Retrieving information for parent class: {}".format(parent))

                    # Make recursive call to retrieve parent class information
                    parent_info = self.get_classes([parent])
                    classes += parent_info

            else:
                self.logger.warning("Unable to retrieve class: {}".format(class_name))

        self.logger.debug("Retrieved all class information.")
        return classes

    def generate_uml(self, class_list, output_file):
        """
        Generates UML diagram using retrieved class information
        """
        self.logger.info("Generating UML diagram.")
        # Get class information from API
        class_info = self.get_classes(class_list)

        # Create UML string
        uml_string = "@startuml\n"
        for class in class_info:
            # Add class name to UML string
            uml_string += "class {}\n".format(class.get('name'))

            # Check if class has parent
            if "parent_class" in class:
                parent = class.get("parent_class")
                # Add inheritance relationship to UML string
                uml_string += "{} <|-- {}\n".format(parent, class.get('name'))

            # Check if class has attributes
            if "attributes" in class:
                attributes = class.get("attributes")
                # Add attributes to UML string
                for attribute in attributes:
                    name = attribute.get("name")
                    data_type = attribute.get("data_type")
                    uml_string += "{} : {}\n".format(name, data_type)

            # Check if class has methods
            if "methods" in class:
                methods = class.get("methods")
                # Add methods to UML string
                for method in methods:
                    name = method.get("name")
                    parameters = method.get("parameters")
                    return_type = method.get("return_type")
                    # Format method parameters
                    formatted_parameters = ", ".join(["{}:{}".format(param.get("name"), param.get("data_type")) for param in parameters])
                    uml_string += "{}() : {}\n".format(name, formatted_parameters, return_type)

            # Add UML string footer
            uml_string += "@enduml"

            # Write UML string to file
            with open(output_file, 'w') as f:
                f.write(uml_string)

        self.logger.info("UML diagram successfully generated.")


# Main function
def main():
    # Retrieve environment variables
    api_key = os.getenv("API_KEY")
    base_url = os.getenv("BASE_URL")

    # Create instance of UMLGenerator
    uml_generator = UMLGenerator(api_key, base_url)

    # Retrieve class list from config file
    with open(config_file_path) as f:
        class_list = json.load(f).get("classes")

    # Generate UML diagram
    output_file = "../output/uml_diagram.puml"
    uml_generator.generate_uml(class_list, output_file)


if __name__ == "__main__":
    main()


@startuml
class UMLGenerator
- api_key
- base_url
- logger
+ get_classes(class_list)
+ generate_uml(class_list,output_file)
+ __init__(api_key,base_url)
@enduml

@startuml
class LoggingUtils
- log_directory
- log_filename
- log_handler
- log_formatter
- logger
~ configure_logging()
+ __init__()
+ log_message(level,message)
@enduml

@startuml
class DotEnvUtils
~ load_dotenv()
+ __init__()
@enduml

@startuml
class App
- current_dir
- config_file_path
+ main()
+ __init__()
@enduml

UMLGenerator "1" *-- "1" App
2024-01-20 22:32:37,327 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

rrent_dir, 'config.json')

# Read configuration from the JSON file
with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

# Retrieve the GitHub access token from environment variables
github_token = os.getenv('GITHUB_PAT')

# Endpoint URL
url = 'http://127.0.0.1:5000/generate-uml'

# Headers
headers = {
    'Content-Type': 'application/json'
}

# Update the GitHub access token and local directory in the config data
config_data['gitHubAccessToken'] = github_token
config_data['local_dir'] = os.path.join(current_dir, '../..', 'output')

# Log the JSON data being sent in the request
logging.info(f'Sending JSON data to {url}:')
logging.info(json.dumps(config_data, indent=2))

try:
    # Make the POST request
    response = requests.post(url, headers=headers, json=config_data)

    # Log the response from the server
    logging.info(f'Response from server ({url}):')
    logging.info(f'Status Code: {response.status_code}')
    logging.info(f'Response Text: {response.text}')

    #
2024-01-20 22:32:37,329 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nrrent_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    #", 'max_tokens': 1024}}
2024-01-20 22:32:37,330 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:32:37,331 - DEBUG - send_request_headers.complete
2024-01-20 22:32:37,331 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:32:37,331 - DEBUG - send_request_body.complete
2024-01-20 22:32:37,331 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:32:40,807 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:32:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3348'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'75bc977961477d1e8b142ab6be3bcb46'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd5996ef2b09d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:32:40,809 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:32:40,809 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:32:40,810 - DEBUG - receive_response_body.complete
2024-01-20 22:32:40,810 - DEBUG - response_closed.started
2024-01-20 22:32:40,810 - DEBUG - response_closed.complete
2024-01-20 22:32:40,811 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:32:40,812 - INFO - Received response from OpenAI:  Save the generated UML diagram
    with open(os.path.join(current_dir, 'diagram.png'), 'wb') as f:
        f.write(response.content)

except requests.exceptions.RequestException as e:
    logging.error(f'Failed to make request to {url}. Error: {e})
```

@startuml

class Config:
    - config_file_path: str
    - url: str
    - headers: dict
    - logging: Logger
    
    + read_config(config_file_path: str)
    + get_access_token()
    + set_gitHub_access_token(github_token: str)
    + set_local_dir(directory: str)
    + log_json_data(data: dict)
    + make_post_request(url: str, headers: dict, json_data: dict)
    + log_response(response: requests.Response)
    + save_uml_diagram(diagram_path: str, response_content: bytes)
    
class Logger:
    - config_data: dict
    
    + info(message: str)
    + error(message: str)
    
class requests.Response:
    - status_code: int
    - text: str
    - content: bytes
    
    + json()
    
class requests.exceptions.RequestException
    
class json:
    - load(config_file: _io.TextIOWrapper)
    
class os:
    + getenv(key: str)
    + path: str
    + join(*paths: str)
    
Config "config" *-- "uses" Logger
Config "config" --> "uses" requests.Response
Logger "logger" --> "uses" json
Config "config" --> "uses" json
Config "config" --> "uses" os
    
@enduml
2024-01-20 22:32:40,813 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

 Print the response from the server
    print(response.text)

    # Save the response to a file in the output directory
    output_dir = os.path.join(current_dir, '../..', 'output')
    os.makedirs(output_dir, exist_ok=True)
    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:
        json.dump(response.json(), output_file, indent=2)

except Exception as e:
    # Log any exceptions that occur
    logging.error(f'Error occurred: {str(e)}')
2024-01-20 22:32:40,814 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')", 'max_tokens': 1024}}
2024-01-20 22:32:40,815 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:32:40,816 - DEBUG - send_request_headers.complete
2024-01-20 22:32:40,816 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-20 22:32:40,817 - DEBUG - send_request_body.complete
2024-01-20 22:32:40,817 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:32:46,835 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 04:32:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5913'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'f58ca44efa145bf5265f41bf54cdb4b9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848cd5af5b99b09d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:32:46,837 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-20 22:32:46,838 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:32:46,839 - DEBUG - receive_response_body.complete
2024-01-20 22:32:46,839 - DEBUG - response_closed.started
2024-01-20 22:32:46,840 - DEBUG - response_closed.complete
2024-01-20 22:32:46,840 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-20 22:32:46,843 - INFO - Received response from OpenAI: 

B054A7D437515264B6069ADE142FDCB6 --Class Diagram
-------------------------------------
|             Print               |
|---------------------------------|
| - response : ResponseObject     |
|---------------------------------|
| + print(response : ResponseObject) |
| + saveToFile(output_dir : String, response : ResponseObject) |
| + logError(e : Exception)       |
------------------------------------

0D05847A3751513D734396E0E51955B1  -- Sequence Diagram
-------------------------------------
|           Client                |
-------------------------------------
      | print(response.text)        |
      |---------------------------> |
      |                              |
      |                              |
      |         Response Object      |
      | <--------------------------  |
      |  <<create>>                   |
      |                              |
      |                              |
      | <<use>>                      |
      | saveToFile(output_dir, response)|
      |--------------------------->  |
      | output_dir : String          |
      | response : ResponseObject    |
      |                              |
      | <<create>>                   |
      | output_file : File           |
      | <<write>>                    |
      | response.json : JSON         |
      | indent = 2                   |
      | ((the response object is     |
      | parsed and then saved        |
      | into a file))                |
      | <<destroy>>                  |
      | output_file                  |
      | <<destroy>>                  |
      | response                     |
      | <<end>>                      |
      |                              |
      |                              |
      | <<create>>                   |
      | e : Exception                |
      | <<use>>                      |
      | logError(e)                  |
      |--------------------------->  |
      | <<destroy>>                  |
      | e                            |
      |                              |
      | <<end>>                      |

E444A7F437515264B6069ADE142FDCB6  -- Class Diagram for exception handling
   ---------------------
   |       Client     |
   ---------------------
   | + e: Exception   |
   --------------------
   | + logError (e)   |
   --------------------
          |                           A
          |                           |
          V                           |
   ------------                ------------
   | File   |                |  Logger  |
   |--------|                |----------|
   | - current_dir       -----| + log(e) |
   |----------|              |----------|
   | + output_dir   |<------  | +__init__ |
   | + mkdr(output_dir)|      ------------
   | <<use>>       |              |
   | ---------->  |              | <<create>>
   |                               | e : Exception
   |                               | <<use>>
   |                               | log(e)
   |        <<call>>               | <<end>>
   | create_file(os.path.join     |
   | (output_dir, 'response.json'),|
   | 'w')                         |
   | dump({self.out}, output file)  |
   |((the error is logged and      |
   |an output file is created))    |
   | <<end>>                          
2024-01-20 22:32:46,844 - INFO - UML code generated for src/scripts/execute_generate_uml.py: @startuml
class UMLGenerator
- api_key
- base_url
- logger
+ get_classes(class_list)
+ generate_uml(class_list,output_file)
+ __init__(api_key,base_url)
@enduml
2024-01-20 22:32:46,844 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-20 22:32:46,845 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-20 22:32:46,845 - INFO - Generated file paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-20 22:32:46,846 - INFO - Final output paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-20 22:32:46,846 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-20 22:32:46,846 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-20 22:32:46,846 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-20 22:32:46,846 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-20 22:32:46,846 - INFO - Cleaning up temporary directory
2024-01-20 22:32:47,024 - INFO - 127.0.0.1 - - [20/Jan/2024 22:32:47] "POST /generate-uml HTTP/1.1" 200 -
2024-01-21 16:45:59,035 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 16:45:59,036 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 16:45:59,050 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-21 16:45:59,050 - INFO - [33mPress CTRL+C to quit[0m
2024-01-21 16:45:59,051 - INFO -  * Restarting with stat
2024-01-21 16:45:59,328 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 16:45:59,329 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 16:45:59,337 - WARNING -  * Debugger is active!
2024-01-21 16:45:59,345 - INFO -  * Debugger PIN: 139-904-016
2024-01-21 16:46:16,934 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-21 16:46:16,934 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-21 16:46:16,934 - INFO - Received local_dir: ./output
2024-01-21 16:46:16,934 - INFO - Received gitHubAccessToken: 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
2024-01-21 16:46:16,935 - INFO - Cleaning up temporary directory
2024-01-21 16:46:16,935 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 16:46:16,938 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-21 16:46:16,939 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmphcocsfbl'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-21 16:46:20,825 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmphcocsfbl'])'s unused stdout: 
2024-01-21 16:46:20,827 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 16:46:20,827 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmphcocsfbl, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 16:46:20,833 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmphcocsfbl, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 16:46:20,857 - DEBUG - Type of included_files: <class 'dict'>
2024-01-21 16:46:20,857 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 16:46:20,857 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-21 16:46:20,857 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 16:46:20,858 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-21 16:46:20,858 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-21 16:46:20,858 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-21 16:46:20,859 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-21 16:46:20,875 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-21 16:46:21,001 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105c973d0>
2024-01-21 16:46:21,001 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105891be0> server_hostname='api.openai.com' timeout=5.0
2024-01-21 16:46:21,030 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105c97990>
2024-01-21 16:46:21,031 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:46:21,032 - DEBUG - send_request_headers.complete
2024-01-21 16:46:21,032 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:46:21,032 - DEBUG - send_request_body.complete
2024-01-21 16:46:21,033 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:46:28,095 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:46:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'6964'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'48d3f772c57718e41361bca6bfcb8632'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=7UAhVhDQl1krwCXNeLhCFRnFyjVxJYsFiyvkPXrR5CE-1705877188-1-AZp0mL+QCOCtIRmBs5lwxn1VwWQehdr4/ygNaFZUnJNZXUnXRtTZ2oPug4SYogJbsmMxo2ekiDej0ppYakV9RYQ=; path=/; expires=Sun, 21-Jan-24 23:16:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=xTyYciOTXFL6Jtmh0jMq0ooYEx5xUKFhSLkMeL0JLBo-1705877188193-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849317be3cb207f6-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:46:28,098 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:46:28,099 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:46:28,100 - DEBUG - receive_response_body.complete
2024-01-21 16:46:28,100 - DEBUG - response_closed.started
2024-01-21 16:46:28,100 - DEBUG - response_closed.complete
2024-01-21 16:46:28,100 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:46:28,104 - INFO - Received response from OpenAI: 
        if not code:
            continue
        file_paths.append(file_path)
        # Replace tabs with 4 spaces
        code = code.replace('\t', '    ')
        # Format the code using the OpenAI API
        formatted_code = api.format(text=code)
        # Append the formatted code to the generated_code string
        generated_code += formatted_code
    # Write the generated code to a new file
    with open(os.path.join(output_directory, "generated_code.py"), 'w') as file:
        file.write(generated_code)
    # Log the file paths processed
    logging.info(f"File paths processed: {file_paths}")

# Run the program
if __name__ == '__main__':
    files = {
        'file1.py': 'def function1():\n\tpass\n',
        'file2.py': '',
        'file3.py': 'def function2():\n\tpass\n'
    }
    output_directory = 'generated_files'
    generate_content(files, output_directory)


@startuml

class OpenAI_API {
  + api_key: String
  + format(text: String): String
}

class Logging {
  + logger: Logger
  + log_directory: String
  + log_filename: String
  + log_handler: RotatingFileHandler
  + log_formatter: Formatter
  + configure_logging()
}

class CodeToUML {
  - api: OpenAI_API
  - generated_code: String
  - file_paths: List<String>
  - output_directory: String
  - generate_content(files: Dictionary, output_directory: String)
}

CodeToUML ..> OpenAI_API
CodeToUML ..> Logging

class File {
  + filename: String
  + code: String
}

class Dictionary {
  - data: Array<Pair>
  + items()
  + keys()
  + values()
  + items(placed: Integer, item_y: Integer): Dictionary
  + keys(placed: Integer, key_y: Integer): Dictionary
  + values(placed: Integer, value_y: Integer): Dictionary
  + delete()

  + add_pair(key: String, value: String)
  + delete_pair(key: String)
}

class Pair {
  + key: String
  + value: String
}

class List {
  - data: Array
  + len: Integer
  + index()
  + insert()
  + remove()
}

CodeToUML ..> File
CodeToUML ..> Dictionary
File ..> List
Dictionary ..> Pair

Logging . Class -- CodeToUML
%header: class {
  %w = 120
  %h = 60
}
class Logger
class RotatingFileHandler
class Formatter

File o-- '*' List
Dictionary o-- Pair

note bottom: Initialize generated_code and file_paths\n
%footer: file_path
file_path <|-- CodeToUML
%footer: code
files <|-- CodeToUML

note bottom: Generate code using OpenAI API
CodeToUML ..> OpenAI_API : use
CodeToUML ..> Logging : use
CodeToUML ..> File : use
CodeToUML ..> Dictionary : use
2024-01-21 16:46:28,104 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-21 16:46:28,106 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-21 16:46:28,107 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:46:28,108 - DEBUG - send_request_headers.complete
2024-01-21 16:46:28,108 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:46:28,108 - DEBUG - send_request_body.complete
2024-01-21 16:46:28,108 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:46:28,554 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:46:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'380'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'1cbd08dbdfff2aabf2c6c6a50f543118'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849317ea790f07f6-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:46:28,555 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:46:28,555 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:46:28,556 - DEBUG - receive_response_body.complete
2024-01-21 16:46:28,556 - DEBUG - response_closed.started
2024-01-21 16:46:28,556 - DEBUG - response_closed.complete
2024-01-21 16:46:28,557 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:46:28,558 - INFO - Received response from OpenAI: _paths})

![puml_diagram](https://github.com/araejar/CS-3620-assignment-5/blob/main/puml_diagram.png)
2024-01-21 16:46:28,559 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-21 16:46:28,560 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-21 16:46:28,561 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:46:28,561 - DEBUG - send_request_headers.complete
2024-01-21 16:46:28,561 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:46:28,561 - DEBUG - send_request_body.complete
2024-01-21 16:46:28,561 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:46:28,979 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:46:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'323'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'390c51331a8f29909565447ac7ade4d3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849317ed4af507f6-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:46:28,980 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:46:28,981 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:46:28,981 - DEBUG - receive_response_body.complete
2024-01-21 16:46:28,982 - DEBUG - response_closed.started
2024-01-21 16:46:28,982 - DEBUG - response_closed.complete
2024-01-21 16:46:28,982 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:46:28,984 - INFO - Received response from OpenAI: 

//class: CodeGenerator

+ generate_code(generated_code: str, file_paths: list)
2024-01-21 16:46:28,984 - INFO - UML code generated for src/routes/code_to_uml.py: @startuml

class OpenAI_API {
  + api_key: String
  + format(text: String): String
}

class Logging {
  + logger: Logger
  + log_directory: String
  + log_filename: String
  + log_handler: RotatingFileHandler
  + log_formatter: Formatter
  + configure_logging()
}

class CodeToUML {
  - api: OpenAI_API
  - generated_code: String
  - file_paths: List<String>
  - output_directory: String
  - generate_content(files: Dictionary, output_directory: String)
}

CodeToUML ..> OpenAI_API
CodeToUML ..> Logging

class File {
  + filename: String
  + code: String
}

class Dictionary {
  - data: Array<Pair>
  + items()
  + keys()
  + values()
  + items(placed: Integer, item_y: Integer): Dictionary
  + keys(placed: Integer, key_y: Integer): Dictionary
  + values(placed: Integer, value_y: Integer): Dictionary
  + delete()

  + add_pair(key: String, value: String)
  + delete_pair(key: String)
}

class Pair {
  + key: String
  + value: String
}

class List {
  - data: Array
  + len: Integer
  + index()
  + insert()
  + remove()
}

CodeToUML ..> File
CodeToUML ..> Dictionary
File ..> List
Dictionary ..> Pair

Logging . Class -- CodeToUML
%header: class {
  %w = 120
  %h = 60
}
class Logger
class RotatingFileHandler
class Formatter

File o-- '*' List
Dictionary o-- Pair

note bottom: Initialize generated_code and file_paths\n
%footer: file_path
file_path <|-- CodeToUML
%footer: code
files <|-- CodeToUML

note bottom: Generate code using OpenAI API
CodeToUML ..> OpenAI_API : use
CodeToUML ..> Logging : use
CodeToUML ..> File : use
CodeToUML ..> Dictionary : use
@enduml
2024-01-21 16:46:28,984 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 16:46:28,985 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 16:46:28,985 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-21 16:46:28,986 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-21 16:46:28,988 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-21 16:46:28,989 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:46:28,990 - DEBUG - send_request_headers.complete
2024-01-21 16:46:28,990 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:46:28,990 - DEBUG - send_request_body.complete
2024-01-21 16:46:28,990 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:46:34,460 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:46:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5370'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'2d704a3569d333fce0d86700559ee6e7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849317effd3607f6-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:46:34,463 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:46:34,463 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:46:34,464 - DEBUG - receive_response_body.complete
2024-01-21 16:46:34,465 - DEBUG - response_closed.started
2024-01-21 16:46:34,465 - DEBUG - response_closed.complete
2024-01-21 16:46:34,466 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:46:34,468 - INFO - Received response from OpenAI: 
        # Delete the .git folder to save space
        git_folder = os.path.join(temp_dir, '.git')
        logger.info(f"Deleting .git folder for repository: {repo_url}")
        shutil.rmtree(git_folder)
        logger.info(f"Successfully deleted .git folder for repository: {repo_url}")
    except Exception as e:
        logger.error(f"Failed to clone repository: {repo_url}")
        logger.error(e)


# Main method
if __name__ == '__main__':
    # Load config file
    with open('config.json', 'r') as f:
        config = json.load(f)
    # Get repository information
    repo_url = config['repo_url']
    temp_dir = config['temp_dir']
    access_token = config['access_token']
    
    # Clone repository
    clone_repo(repo_url, temp_dir, access_token)


@startuml

import git
import json
import os
import logging
from logging import handlers

package code_retrieval {

    class Git {
        - url: string
        - repo: Repository

        + clone(): void
        + get_repo(): Repository
    }

    class Repository {
        - temp_dir: string
        - access_token: string

        + clone_from(url: string): void
        + delete_git_folder(): void
    }

    class Config {
        - repo_url: string
        - temp_dir: string
        - access_token: string

        + get_repo_url(): string
        + get_temp_dir(): string
        + get_access_token(): string
    }

    class Logger {
        - log_directory: string
        + logger: Logger

        + configure_logging(): void
        + add_handler(handler: RotatingFileHandler): void
        + set_formatter(formatter: logging.Formatter): void
        + set_level(level: logging.DEBUG): void
    }

    class RotatingFileHandler {
        - log_filename: string
        - max_bytes: int
        - backup_count: int

        + backup_log_files(): void
    }

}

Git --|> Repository
Config --|> Git
Logger *-- RotatingFileHandler

class Main {
    - config: Config

    + __init__()
}

Main --> Config: config_file = 'config.json'
Main --> Git: clone_repo()
Config --> RotatingFileHandler: set_filename()
Git --> Repository: modify_URL()
Repository --> RotatingFileHandler: backup_log_files()

@enduml
2024-01-21 16:46:34,470 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-21 16:46:34,472 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-21 16:46:34,473 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:46:34,474 - DEBUG - send_request_headers.complete
2024-01-21 16:46:34,475 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:46:34,475 - DEBUG - send_request_body.complete
2024-01-21 16:46:34,475 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:46:37,234 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:46:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2606'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'65e7c67e4ffe0aa70cfcb70e936b3171'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493181258ed07f6-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:46:37,236 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:46:37,236 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:46:37,237 - DEBUG - receive_response_body.complete
2024-01-21 16:46:37,237 - DEBUG - response_closed.started
2024-01-21 16:46:37,237 - DEBUG - response_closed.complete
2024-01-21 16:46:37,237 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:46:37,238 - INFO - Received response from OpenAI:  # Check if file is in include list or not in ignore list
            if file.path in include_list or file.path not in ignore_list:
                included_files[file.path] = file.data_stream.read()

        return included_files

class Repository
- logger: Logger
- repo: Repository
- include_list: List<String>
- ignore_list: List<String>
- config_file_path: String
- config: JSON

+ retrieve_code(repo, branch_name)
- included_files: Dictionary<String, Text>
- e: Exception

+ clone_repository()
- repo: Repository

+ fetch_updates()
+ checkout_branch(branch_name)

class Logger
+error(string)
+info(string)

class ValueError

class Config
- include_list: List<String>
- ignore_list: List<String>

+ get_include_list()
+ get_ignore_list()

class File
- path: String
- data_stream: Stream

+ read()
+ check_ignore(ignore_list, include_list)

Repository *-- Logger
Repository *-- Config
Config "1" *-- "0..*" File
2024-01-21 16:46:37,238 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-21 16:46:37,240 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-21 16:46:37,241 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:46:37,241 - DEBUG - send_request_headers.complete
2024-01-21 16:46:37,241 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:46:37,241 - DEBUG - send_request_body.complete
2024-01-21 16:46:37,242 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:46:38,918 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:46:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1578'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'7b0acf3b7be0fc97f4eab5e13dcf9b88'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849318238dd607f6-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:46:38,920 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:46:38,920 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:46:38,921 - DEBUG - receive_response_body.complete
2024-01-21 16:46:38,921 - DEBUG - response_closed.started
2024-01-21 16:46:38,922 - DEBUG - response_closed.complete
2024-01-21 16:46:38,922 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:46:38,924 - INFO - Received response from OpenAI: 

@startuml

class Program {
    - include_list
    - ignore_list
    - logger
    .. Other attributes and methods ..
}

class File {
    - path
    - abspath
    .. Other attributes..
    + endswith(ext): bool
}

class FileNotFoundError {
    + path
    + __init__(path)
}

class Logger {
    .. Other attributes and methods ..
    + info(message)
    + warning(message)
    + error(message)
}

class Exception {
    + __init__(message)
}

Program --> File
Program --> FileNotFoundError
Program --> Logger
Program --> Exception

File --> endswith(ext)
Logger <-- info(message)
Logger <-- warning(message)
Logger <-- error(message)
Exception <-- __init__(message)
File --> __init__(path)
File --> endswith(ext)
File --> __init__(path)

@enduml
2024-01-21 16:46:38,924 - INFO - UML code generated for src/routes/retrieve_code.py: @startuml

import git
import json
import os
import logging
from logging import handlers

package code_retrieval {

    class Git {
        - url: string
        - repo: Repository

        + clone(): void
        + get_repo(): Repository
    }

    class Repository {
        - temp_dir: string
        - access_token: string

        + clone_from(url: string): void
        + delete_git_folder(): void
    }

    class Config {
        - repo_url: string
        - temp_dir: string
        - access_token: string

        + get_repo_url(): string
        + get_temp_dir(): string
        + get_access_token(): string
    }

    class Logger {
        - log_directory: string
        + logger: Logger

        + configure_logging(): void
        + add_handler(handler: RotatingFileHandler): void
        + set_formatter(formatter: logging.Formatter): void
        + set_level(level: logging.DEBUG): void
    }

    class RotatingFileHandler {
        - log_filename: string
        - max_bytes: int
        - backup_count: int

        + backup_log_files(): void
    }

}

Git --|> Repository
Config --|> Git
Logger *-- RotatingFileHandler

class Main {
    - config: Config

    + __init__()
}

Main --> Config: config_file = 'config.json'
Main --> Git: clone_repo()
Config --> RotatingFileHandler: set_filename()
Git --> Repository: modify_URL()
Repository --> RotatingFileHandler: backup_log_files()

@enduml
2024-01-21 16:46:38,924 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 16:46:38,925 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 16:46:38,925 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-21 16:46:38,926 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-21 16:46:38,927 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-21 16:46:38,928 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:46:38,929 - DEBUG - send_request_headers.complete
2024-01-21 16:46:38,929 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:46:38,929 - DEBUG - send_request_body.complete
2024-01-21 16:46:38,930 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:46:39,090 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:46:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'79'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'd2d80e5d7513667bc8307376a3a8f69d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493182e1ece07f6-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:46:39,091 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:46:39,091 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:46:39,092 - DEBUG - receive_response_body.complete
2024-01-21 16:46:39,092 - DEBUG - response_closed.started
2024-01-21 16:46:39,092 - DEBUG - response_closed.complete
2024-01-21 16:46:39,092 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:46:39,095 - INFO - Received response from OpenAI: 
2024-01-21 16:46:39,095 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-21 16:46:39,097 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-21 16:46:39,098 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:46:39,098 - DEBUG - send_request_headers.complete
2024-01-21 16:46:39,098 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:46:39,099 - DEBUG - send_request_body.complete
2024-01-21 16:46:39,099 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:46:43,525 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:46:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4246'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'da3a96c075e6572d1c0ea47cfce49d4c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493182f2fb707f6-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:46:43,527 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:46:43,527 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:46:43,527 - DEBUG - receive_response_body.complete
2024-01-21 16:46:43,528 - DEBUG - response_closed.started
2024-01-21 16:46:43,528 - DEBUG - response_closed.complete
2024-01-21 16:46:43,528 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:46:43,529 - INFO - Received response from OpenAI: )
        
        # Generate the UML diagram
        generator = PlantUMLGenerator(config)
        diagram = generator.generate(repo, branch_name)
        
        # Save the diagram to the output directory
        diagram.save(output_directory)


@startuml

class Data {
    -get(gitHubAccessToken)
    -get(branchName, 'master')
}

class Logger {
    +error(String)
    +info(String)
}

class Tempfile {
    +mkdtemp()
}

class Exception

class Path {
    +is_file()
    +is_dir()
    +exists()
}

class Shutil {
    +rmtree()
}

class ConfigJson {
    +open('src/routes/config.json', 'r')
}

class Json {
    +load(f)
}

class Repo {
    +clone_repo(git_repo_url, temp_dir, github_access_token)
}

class PlantUMLGenerator {
    +generate(repo, branch_name)
}

class Diagram {
    +save(output_directory)
}

class Main {
    -thub_access_token: String
    -branch_name: String
    -git_repo_url: String
    -output_directory: String
    -github_access_token: String

    +Main()
    +run(data)
}

Main *-- Data
Main o|> Logger
Main o|> Tempfile
Main o|> Path
Main o|> Shutil
Main o|> ConfigJson
Main o|> Json
Main o|> Repo
Main o|> PlantUMLGenerator
Main o|> Diagram

Logger *-- Exception
Tempfile *-- Exception
Shutil *-- Path
ConfigJson *-- Path
Json *-- Path
Repo *-- Path
PlantUMLGenerator *-- ConfigJson

Repo o-- Path
PlantUMLGenerator o-- Repo
Diagram *-- Path

@enduml
2024-01-21 16:46:43,529 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-21 16:46:43,530 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-21 16:46:43,530 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:46:43,530 - DEBUG - send_request_headers.complete
2024-01-21 16:46:43,531 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:46:43,531 - DEBUG - send_request_body.complete
2024-01-21 16:46:43,531 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:46:46,318 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:46:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2705'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'ec0bb985d3405d1c5231fb2e0b442cd6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493184afe2f07f6-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:46:46,318 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:46:46,318 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:46:46,318 - DEBUG - receive_response_body.complete
2024-01-21 16:46:46,318 - DEBUG - response_closed.started
2024-01-21 16:46:46,319 - DEBUG - response_closed.complete
2024-01-21 16:46:46,319 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:46:46,319 - INFO - Received response from OpenAI: t_diagram(included_files, output_directory)

@startuml
class TraverseDirectories {
    -repo: Repository
    -temp_dir: str
    -config: dict
    +traverse_directories(repo: Repository, temp_dir: str, config: dict): dict
}

class Repository {
    #tree(): FileTree
}

class FileTree {
    +traverse(): Iterator
}

class Iterator {
    +next(): Item
}

class Item {
    +type: str
    +path: str
}

class Logger {
    +debug(message: str)
    +info(message: str)
}

class GenerateContentDiagram {
    -included_files: dict
    -output_directory: str
    +generate_content_diagram(included_files: dict, output_directory: str): str
}

TraverseDirectories o- Repository
TraverseDirectories o- Logger
TraverseDirectories o- GenerateContentDiagram
Repository o- FileTree
FileTree o- Iterator
Iterator o- Item
Logger o- GenerateContentDiagram
GenerateContentDiagram *- Item
@enduml
2024-01-21 16:46:46,319 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-21 16:46:46,320 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-21 16:46:46,320 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:46:46,321 - DEBUG - send_request_headers.complete
2024-01-21 16:46:46,321 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:46:46,321 - DEBUG - send_request_body.complete
2024-01-21 16:46:46,321 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:46:50,655 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:46:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4273'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'a8c146c5d53eb15330b5d6a832b4c101'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493185c4bf207f6-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:46:50,655 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:46:50,655 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:46:50,655 - DEBUG - receive_response_body.complete
2024-01-21 16:46:50,655 - DEBUG - response_closed.started
2024-01-21 16:46:50,655 - DEBUG - response_closed.complete
2024-01-21 16:46:50,656 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:46:50,656 - INFO - Received response from OpenAI:  class UMLGenerator
  ______________________
 | t(included_files,    |
 | output_directory)    |
 |______________________|
       |  |
       |  |logger.info(f"Final output paths: {final_output_paths}")
       |  |
       |  | for path in final_output_paths:
       |  |    logger.info(f"UML diagram saved at: {path}")
       |  |
       |  |return {
       |  |    "message": "UML diagrams generated successfully",
       |  |    "details": {
       |  |        "Repository": git_repo_url,
       |  |        "Output Paths": final_output_paths
       |  |    }
       |  |}, 200
       |
       |except Exception as e:
       |  |logger.error(f"Error during UML generation: {str(e)}")
  catch|  |return {"error": str(e)}, 500
       |
       |finally:
       |_ |_logger.info("Cleaning up temporary directory")
             shutil.rmtree(temp_dir)

  class UMLGenerator
 _____________________________________________________________________________
|                           UMLGenerator                                       |
|_____________________________________________________________________________|
| -included_files : list                                                      |
| -output_directory : str                                                     |
| -git_repo_url : str                                                         |
| -final_output_paths : list                                                  |
|_____________________________________________________________________________|
| +t(included_files, output_directory) : dict                                 |
| +logger : Logger                                                            |
|_____________________________________________________________________________|
| +t(...): dict                                                               |
| -logger.info(...): void                                                     |
| -for path in final_output_paths:                                             |
|    -logger.info(...): void                                                   |
| returns: dict                                                               |
|                                                                           `|
| +t(...): dict                                                               |
| -logger.error(...): void                                                    |
| raises: Exception                                                           |
| returns: dict                                                               |
|                                                                             |
| +t(...): void                                                               |
| -shutil.rmtree(...): void                                                   |
|_____________________________________________________________________________|
2024-01-21 16:46:50,656 - INFO - UML code generated for src/routes/uml_from_repo.py: 
2024-01-21 16:46:50,657 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 16:46:50,657 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 16:46:50,657 - INFO - Skipping empty file: src/scripts/__init__.py
2024-01-21 16:46:50,657 - INFO - Processing file: src/scripts/execute_generate_uml.py
2024-01-21 16:46:50,657 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import json
import os
import requests
import logging
from logging import handlers
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure logging to write to a file
log_directory = '../../logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'execute_generate_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


# Configure logging
logging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))
# Configuration file path
config_file_path = os.path.join(cu
2024-01-21 16:46:50,658 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nimport json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(cu", 'max_tokens': 1024}}
2024-01-21 16:46:50,659 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:46:50,659 - DEBUG - send_request_headers.complete
2024-01-21 16:46:50,659 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:46:50,659 - DEBUG - send_request_body.complete
2024-01-21 16:46:50,659 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:46:51,915 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:46:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1166'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'a2a97987b2eacac1d9f1483e03e16c32'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84931877684e07f6-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:46:51,915 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:46:51,916 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:46:51,916 - DEBUG - receive_response_body.complete
2024-01-21 16:46:51,916 - DEBUG - response_closed.started
2024-01-21 16:46:51,916 - DEBUG - response_closed.complete
2024-01-21 16:46:51,916 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:46:51,917 - INFO - Received response from OpenAI: rrent_dir, 'config.json')

# Load configuration file
with open(config_file_path) as config_file:
    config = json.load(config_file)

@startuml

class Import
Import -- import json
Import -- import os
Import -- import requests
Import -- import logging
Import -- from logging import handlers
Import -- from dotenv import load_dotenv

class LoadDotenv
LoadDotenv -- load_dotenv()

class ConfigureLogging
ConfigureLogging -- log_directory
ConfigureLogging -- os.makedirs()
ConfigureLogging -- log_filena
2024-01-21 16:46:51,917 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

rrent_dir, 'config.json')

# Read configuration from the JSON file
with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

# Retrieve the GitHub access token from environment variables
github_token = os.getenv('GITHUB_PAT')

# Endpoint URL
url = 'http://127.0.0.1:5000/generate-uml'

# Headers
headers = {
    'Content-Type': 'application/json'
}

# Update the GitHub access token and local directory in the config data
config_data['gitHubAccessToken'] = github_token
config_data['local_dir'] = os.path.join(current_dir, '../..', 'output')

# Log the JSON data being sent in the request
logging.info(f'Sending JSON data to {url}:')
logging.info(json.dumps(config_data, indent=2))

try:
    # Make the POST request
    response = requests.post(url, headers=headers, json=config_data)

    # Log the response from the server
    logging.info(f'Response from server ({url}):')
    logging.info(f'Status Code: {response.status_code}')
    logging.info(f'Response Text: {response.text}')

    #
2024-01-21 16:46:51,918 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nrrent_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    #", 'max_tokens': 1024}}
2024-01-21 16:46:51,919 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:46:51,919 - DEBUG - send_request_headers.complete
2024-01-21 16:46:51,919 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:46:51,919 - DEBUG - send_request_body.complete
2024-01-21 16:46:51,920 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:46:56,108 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:46:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4032'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'88e71ef96754ff3a419bcf3e841c61da'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493187f5fff07f6-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:46:56,109 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:46:56,110 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:46:56,110 - DEBUG - receive_response_body.complete
2024-01-21 16:46:56,111 - DEBUG - response_closed.started
2024-01-21 16:46:56,111 - DEBUG - response_closed.complete
2024-01-21 16:46:56,111 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:46:56,111 - INFO - Received response from OpenAI:  Retrieve the generated UML image from the response
    generated_uml = response.content
    with open('uml.png', 'wb') as image_file:
        image_file.write(generated_uml)

    # Display the generated UML image
    image = Image.open('uml.png')
    image.show()

except requests.exceptions.RequestException as e:
    # Log any errors with making the request
    logging.error('Error with making request:')
    logging.error(e)


@startuml

class ConfigurationManager {
    - config_file_path: string
    - config_data: json
    - github_token: string
    - url: string
    - headers: dictionary
    - generated_uml: bytes
    + ConfigurationManager(config_file_path: string, github_token: string, url: string, headers: dictionary)
    + read_configuration()
    + retrieve_github_token()
    + update_config_data()
    + send_request()
    + display_uml()
}

class FileIO {
    - file_path: string
    - file_data: string
    + FileIO(file_path: string)
    + read_file()
    + write_file()
}

class EnvironmentManager {
    + get_env_variable(variable_name: string)
}

class LoggingManager {
    + log_info(message: string)
    + log_error(message: string)
}

class RequestManager {
    - url: string
    - headers: dictionary
    + RequestManager(url: string, headers: dictionary)
    + make_get_request()
    + make_post_request()
}

class Image {
    - image_data: bytes
    + Image(image_data: bytes)
    + display_image()
}

ConfigurationManager --> FileIO
ConfigurationManager --> EnvironmentManager
ConfigurationManager --> LoggingManager
ConfigurationManager --> RequestManager
ConfigurationManager --> Image

RequestManager --> EnvironmentManager
RequestManager --> LoggingManager

Image --> FileIO

@enduml
2024-01-21 16:46:56,112 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

 Print the response from the server
    print(response.text)

    # Save the response to a file in the output directory
    output_dir = os.path.join(current_dir, '../..', 'output')
    os.makedirs(output_dir, exist_ok=True)
    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:
        json.dump(response.json(), output_file, indent=2)

except Exception as e:
    # Log any exceptions that occur
    logging.error(f'Error occurred: {str(e)}')
2024-01-21 16:46:56,113 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')", 'max_tokens': 1024}}
2024-01-21 16:46:56,113 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:46:56,113 - DEBUG - send_request_headers.complete
2024-01-21 16:46:56,113 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:46:56,114 - DEBUG - send_request_body.complete
2024-01-21 16:46:56,114 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:46:57,679 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:46:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1465'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'84a231d198909ebd4a7e1602a93979a0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849318997dc607f6-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:46:57,680 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:46:57,680 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:46:57,680 - DEBUG - receive_response_body.complete
2024-01-21 16:46:57,680 - DEBUG - response_closed.started
2024-01-21 16:46:57,680 - DEBUG - response_closed.complete
2024-01-21 16:46:57,681 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:46:57,681 - INFO - Received response from OpenAI: 

@startuml

class Server
Server : - response

class Print
Print : - response

Server <|-- Print

class Output
Output : - output_dir
Output : + __init__(current_dir, '../..', 'output')
Output : + __makedirs__(dir, exist_ok=True)
Output : + open(dir, 'w')
Output : + __dump__(json, file, indent=2)

Print <|-- Output

class Exception
Exception : - e
Exception : + __init__(e)
Exception : + __str__()

Print <|-- Exception
2024-01-21 16:46:57,682 - INFO - UML code generated for src/scripts/execute_generate_uml.py: @startuml

class Import
Import -- import json
Import -- import os
Import -- import requests
Import -- import logging
Import -- from logging import handlers
Import -- from dotenv import load_dotenv

class LoadDotenv
LoadDotenv -- load_dotenv()

class ConfigureLogging
ConfigureLogging -- log_directory
ConfigureLogging -- os.makedirs()
ConfigureLogging -- log_filena
@enduml
2024-01-21 16:46:57,682 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 16:46:57,682 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 16:46:57,683 - INFO - Generated file paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 16:46:57,683 - INFO - Final output paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 16:46:57,683 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 16:46:57,683 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 16:46:57,683 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 16:46:57,683 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 16:46:57,683 - INFO - Cleaning up temporary directory
2024-01-21 16:46:57,854 - INFO - 127.0.0.1 - - [21/Jan/2024 16:46:57] "POST /generate-uml HTTP/1.1" 200 -
2024-01-21 16:49:37,495 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/openai_api.py', reloading
2024-01-21 16:49:37,572 - INFO -  * Restarting with stat
2024-01-21 16:49:37,860 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 16:49:37,861 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 16:49:37,869 - WARNING -  * Debugger is active!
2024-01-21 16:49:37,874 - INFO -  * Debugger PIN: 139-904-016
2024-01-21 16:49:45,948 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 16:49:45,948 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 16:49:45,959 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-21 16:49:45,959 - INFO - [33mPress CTRL+C to quit[0m
2024-01-21 16:49:45,959 - INFO -  * Restarting with stat
2024-01-21 16:49:46,219 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 16:49:46,220 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 16:49:46,228 - WARNING -  * Debugger is active!
2024-01-21 16:49:46,232 - INFO -  * Debugger PIN: 139-904-016
2024-01-21 16:49:55,279 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-21 16:49:55,279 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-21 16:49:55,279 - INFO - Received local_dir: ./output
2024-01-21 16:49:55,279 - INFO - Received gitHubAccessToken: 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
2024-01-21 16:49:55,280 - INFO - Cleaning up temporary directory
2024-01-21 16:49:55,280 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 16:49:55,283 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-21 16:49:55,284 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp5zybr37e'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-21 16:49:58,844 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp5zybr37e'])'s unused stdout: 
2024-01-21 16:49:58,845 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 16:49:58,846 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp5zybr37e, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 16:49:58,851 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp5zybr37e, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 16:49:58,874 - DEBUG - Type of included_files: <class 'dict'>
2024-01-21 16:49:58,874 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 16:49:58,875 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-21 16:49:58,875 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 16:49:58,875 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-21 16:49:58,875 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-21 16:49:58,875 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-21 16:49:58,876 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-21 16:49:58,889 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-21 16:49:58,967 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107b17710>
2024-01-21 16:49:58,967 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107935b50> server_hostname='api.openai.com' timeout=5.0
2024-01-21 16:49:59,005 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107bad310>
2024-01-21 16:49:59,005 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:49:59,005 - DEBUG - send_request_headers.complete
2024-01-21 16:49:59,005 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:49:59,005 - DEBUG - send_request_body.complete
2024-01-21 16:49:59,006 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:50:05,418 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:50:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'6300'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'9a0b55ff4f4e8bd5a23cba7113a7b03b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mpHeOWy3kxI3jCgIYflD0XAK4_FX_WP02xFP8DzHvi8-1705877405-1-AWtROGviKhr9bZLYkMKojzL22xv2YpF3157MnwyNL8kwubytbuU6iZcjnUsR9gASo+0Ru3MALItjq5iOj9hV4Sw=; path=/; expires=Sun, 21-Jan-24 23:20:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=FUfbrd5THhr4QxHE5Te4RLXLzuajQbmFEQBiLRQygac-1705877405435-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84931d104b4a135b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:50:05,421 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:50:05,422 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:50:05,422 - DEBUG - receive_response_body.complete
2024-01-21 16:50:05,423 - DEBUG - response_closed.started
2024-01-21 16:50:05,423 - DEBUG - response_closed.complete
2024-01-21 16:50:05,423 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:50:05,426 - INFO - Received response from OpenAI: 
        if not code:
            logging.warning(f"Skipping empty file {file_path}")  # Log a warning
            continue
        # Write the code to the output directory
        output_filepath = os.path.join(output_directory, file_path)
        directory = os.path.dirname(output_filepath)
        # Create the directory if it doesn't exist
        os.makedirs(directory, exist_ok=True)
        with open(output_filepath, 'w') as f:
            f.write(code)
        # Add the file path to the file_paths list
        file_paths.append(output_filepath)
        # Generate code using the OpenAI API
        generated_code += api.generate_code(code)
    return generated_code, file_paths

# Main function
def main():
    files = {
        'input/main.py': '',
        'input/utils.py': 'from datetime import datetime\n\n\n# Function to get current date and time\n'
                           'def get_current_datetime():\n    current_datetime = datetime.now()\n'
                           '    print("Current date and time:", current_datetime)\n'
    }
    output_directory = 'output'
    generated_code, file_paths = generate_content(files, output_directory)
    # Write the generated code to a file
    with open('output/generated_code.py', 'w') as f:
         f.write(generated_code)
    logging.info(f"Generated code file paths: {file_paths}")  # Log the generated code file paths

if __name__ == '__main__':
    main()


@startuml

class OpenAIAPI {
    +generate_code()
}

note left: Wrapper class for OpenAI API

class LoggingHandler << (R,#FF7700) RotatingFileHandler >> {
    -maxBytes
    -backupCount
    {static} -RotatingFileHandler()
    {static} -RotatingFileHandler(filename, maxBytes=1024*1024, backupCount=5)
    +setFormatter()
}

note bottom: Logging handler for\nwriting to a file

class Utils {
    +get_current_datetime()
}

note left: Contains functions\nfor utility

class Main {
    -files
    -output_directory
    -generated_code
    -file_paths
    +main()
}

Main .> LoggingHandler
Main .> OpenAIAPI
Main .> Utils

class Logger << (R,#FF7700) Logger >> {
    -log_handler
    -log_formatter
    -log_filename
    -logger
    +addHandler()
    +setLevel()
}

note top: Initializes and\nconfigures logging

Main ..> Logger: uses

Main "1" --> "n" Utils: contains
Main "1" --> "n" Logger: contains

note top: Main function uses the\nutils and logger classes

note right: Main flow:\n1. Create files dictionary\n2. Initialize output directory\n3. Call generate_content() function\n4. Write generated code to file\n5. Log generated code file paths
2024-01-21 16:50:05,427 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-21 16:50:05,429 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-21 16:50:05,430 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:50:05,430 - DEBUG - send_request_headers.complete
2024-01-21 16:50:05,431 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:50:05,431 - DEBUG - send_request_body.complete
2024-01-21 16:50:05,431 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:50:08,614 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:50:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'7867a30d1f4dcd305d5275788a2816c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84931d387e26135b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:50:08,615 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:50:08,615 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:50:08,615 - DEBUG - receive_response_body.complete
2024-01-21 16:50:08,615 - DEBUG - response_closed.started
2024-01-21 16:50:08,615 - DEBUG - response_closed.complete
2024-01-21 16:50:08,616 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:50:08,617 - INFO - Received response from OpenAI: _paths})



@startuml

If(not code.strip):  #if statement
    --> true: Continue 

else
    --> false: Continue 
    
:Logging.info(f"Skipping empty file: {file_path}") as log1  #logging message
continue  #go to next iteration of loop
    
--> Start

:Logging.info(f"Processing file: {file_path}") as log2

:generated_code_for_file = api.generate_from_code(code)

:Logging.info(f"UML code generated for {file_path}: {generated_code_for_file}") as log3  #logging message for generated UML code

If (not generated_code_for_file or "UML generation failed" in generated_code_for_file):  #if statement
    -->true: Raise error message and stop 

else
    -->false: Continue 

:generated_code += generated_code_for_file  #add generated UML code to overall code

:file_name = f"{os.path.basename(file_path)}.puml"  #create file name for output file

:final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))

:file_paths.append(final_output_path)  #add output file path to list

:Logging.info(f"Generated file paths: {file_paths}") as log4  #logging message for file paths

Stop

@enduml
2024-01-21 16:50:08,617 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-21 16:50:08,618 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-21 16:50:08,618 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:50:08,619 - DEBUG - send_request_headers.complete
2024-01-21 16:50:08,619 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:50:08,619 - DEBUG - send_request_body.complete
2024-01-21 16:50:08,619 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:50:09,282 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:50:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'561'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'7f0791bc4381518725843b8e68fcc0bc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84931d4c5ed4135b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:50:09,287 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:50:09,288 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:50:09,289 - DEBUG - receive_response_body.complete
2024-01-21 16:50:09,289 - DEBUG - response_closed.started
2024-01-21 16:50:09,289 - DEBUG - response_closed.complete
2024-01-21 16:50:09,289 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:50:09,290 - INFO - Received response from OpenAI: 
@enduml

Note: I am unable to create the UML diagram as the code provided is not valid and contains some syntax errors. Please provide a valid code to create the UML diagram. 
2024-01-21 16:50:09,291 - INFO - UML code generated for src/routes/code_to_uml.py: @startuml
title code_to_uml.py
if not code:
            logging.warning(f"Skipping empty file {file_path}")  # Log a warning
            continue
        # Write the code to the output directory
        output_filepath = os.path.join(output_directory, file_path)
        directory = os.path.dirname(output_filepath)
        # Create the directory if it doesn't exist
        os.makedirs(directory, exist_ok=True)
        with open(output_filepath, 'w') as f:
            f.write(code)
        # Add the file path to the file_paths list
        file_paths.append(output_filepath)
        # Generate code using the OpenAI API
        generated_code += api.generate_code(code)
    return generated_code, file_paths

# Main function
def main():
    files = {
        'input/main.py': '',
        'input/utils.py': 'from datetime import datetime\n\n\n# Function to get current date and time\n'
                           'def get_current_datetime():\n    current_datetime = datetime.now()\n'
                           '    print("Current date and time:", current_datetime)\n'
    }
    output_directory = 'output'
    generated_code, file_paths = generate_content(files, output_directory)
    # Write the generated code to a file
    with open('output/generated_code.py', 'w') as f:
         f.write(generated_code)
    logging.info(f"Generated code file paths: {file_paths}")  # Log the generated code file paths

if __name__ == '__main__':
    main()


@startuml

class OpenAIAPI {
    +generate_code()
}

note left: Wrapper class for OpenAI API

class LoggingHandler << (R,#FF7700) RotatingFileHandler >> {
    -maxBytes
    -backupCount
    {static} -RotatingFileHandler()
    {static} -RotatingFileHandler(filename, maxBytes=1024*1024, backupCount=5)
    +setFormatter()
}

note bottom: Logging handler for\nwriting to a file

class Utils {
    +get_current_datetime()
}

note left: Contains functions\nfor utility

class Main {
    -files
    -output_directory
    -generated_code
    -file_paths
    +main()
}

Main .> LoggingHandler
Main .> OpenAIAPI
Main .> Utils

class Logger << (R,#FF7700) Logger >> {
    -log_handler
    -log_formatter
    -log_filename
    -logger
    +addHandler()
    +setLevel()
}

note top: Initializes and\nconfigures logging

Main ..> Logger: uses

Main "1" --> "n" Utils: contains
Main "1" --> "n" Logger: contains

note top: Main function uses the\nutils and logger classes

note right: Main flow:\n1. Create files dictionary\n2. Initialize output directory\n3. Call generate_content() function\n4. Write generated code to file\n5. Log generated code file paths
@enduml
2024-01-21 16:50:09,291 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 16:50:09,292 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 16:50:09,292 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-21 16:50:09,292 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-21 16:50:09,294 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-21 16:50:09,295 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:50:09,296 - DEBUG - send_request_headers.complete
2024-01-21 16:50:09,296 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:50:09,296 - DEBUG - send_request_body.complete
2024-01-21 16:50:09,296 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:50:15,115 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:50:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5726'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'9f3d86afa6b25cbf684ab76ad02ff0d9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84931d509b77135b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:50:15,116 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:50:15,117 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:50:15,118 - DEBUG - receive_response_body.complete
2024-01-21 16:50:15,118 - DEBUG - response_closed.started
2024-01-21 16:50:15,118 - DEBUG - response_closed.complete
2024-01-21 16:50:15,119 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:50:15,122 - INFO - Received response from OpenAI: 
        # Return the repository object
        return repo
    
    except Exception as e:
        logger.error(f"Failed to clone repository {repo_url}: {e}")
        raise e  # Rethrow the exception


# Define variables
repo_url = 'https://github.com/user/repo.git'
temp_dir = 'clone'
access_token = '123456789'


@startuml

class git {
- repo_url: string
- temp_dir: string
- access_token: string
-- clone_repo()
}

class json {
+ encode()
+ decode()
}

class os {
+ makedirs()
}

class logging {
- file_handler: handlers.RotatingFileHandler
-- config()
+ getLogger()
+ addHandler()
+ setLevel()
}

class handlers {
- file_handler: RotatingFileHandler
+ RotatingFileHandler()
+ Formatter()
+ setFormatter()
+ setLevel()
}

class RotatingFileHandler {
+ maxBytes: int
+ backupCount: int
-- stream: StreamHandler
+ doRollover()
+ shouldRollover()
}

class StreamHandler {
+ write()
}

class Logger {
- file_handler: handlers.RotatingFileHandler
+ info()
+ error()
+ warning()
+ debug()
}

class Exception {
}

class git.Repo {
- repo_url: string
- temp_dir: string
constructor clone_from()
-- check_available_version()
+ git.Commit
}

class git.Commit {
- message: string
- author: string
+ git.Tree
+ git.Parent
+ commit()
}

class git.Tree {
- path: string
- mode: string
+ blob()
+ tree()
}

class git.Parent {
- hexsha: string
}

git.Repo "1"--|> git.Commit
git.Commit "1"--|> git.Tree
git.Commit "1"--|> git.Parent
git.Repo "1" o--> Exception
logger o--> Logger
logger o--> StreamHandler
handlers "1"--|> RotatingFileHandler
handlers "1"--|> Formatter
handlers o--> Exception
handlers o--> StreamHandler
Logger o--> Exception
StreamHandler o--> Exception
handlers o--> RotatingFileHandler
RotatingFileHandler "1"*--> StreamHandler
git o--> Exception
git "1" o--> json
git "1" o--> os
json o--> Exception
os o--> Exception
json o--> Logger
os o--> Logger
os o--> handlers

@enduml
2024-01-21 16:50:15,122 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-21 16:50:15,124 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-21 16:50:15,125 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:50:15,126 - DEBUG - send_request_headers.complete
2024-01-21 16:50:15,126 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:50:15,126 - DEBUG - send_request_body.complete
2024-01-21 16:50:15,126 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:50:18,220 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:50:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2990'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'655856ceedde17497a6f8243ab38bfe7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84931d75087b135b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:50:18,221 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:50:18,222 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:50:18,223 - DEBUG - receive_response_body.complete
2024-01-21 16:50:18,223 - DEBUG - response_closed.started
2024-01-21 16:50:18,223 - DEBUG - response_closed.complete
2024-01-21 16:50:18,224 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:50:18,225 - INFO - Received response from OpenAI:  if file.path not in ignore_list and file.path.endswith('.py') and file.path not in include_list:
                contents = file.data_stream.read().decode('utf-8')  # Read the file contents in utf-8 encoding
                included_files[file.path] = contents

        return included_files
except Exception as e:
    logger.error(f"Failed to retrieve code from repository: {str(e)}")
    raise ValueError(f"Failed to retrieve code from repository: {str(e)}")


@startuml
class CodeRetriever {
    - repo
    - branch_name
    - config_file_path
    - config
    - ignore_list
    - include_list
    - included_files
    + retrieve_code()
}

class Repository {
    - url
    - branch
    - git
    + fetch()
    + checkout()
    .. other attributes ..
}

class Logger {
    .. attributes and methods ..
}

class File {
    - path
    - data_stream
    .. other attributes ..
}

CodeRetriever --> Repository: repo
CodeRetriever --> Repository: branch_name
CodeRetriever --> Logger

Logger --> Exception

CodeRetriever --> File: config_file_path
CodeRetriever --> File: config
CodeRetriever --> File: ignore_list
CodeRetriever --> File: include_list
CodeRetriever --> File: included_files

File --> Exception

@enduml
2024-01-21 16:50:18,226 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-21 16:50:18,227 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-21 16:50:18,229 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:50:18,230 - DEBUG - send_request_headers.complete
2024-01-21 16:50:18,230 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:50:18,230 - DEBUG - send_request_body.complete
2024-01-21 16:50:18,231 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:50:19,722 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:50:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1424'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'e5c385668a5fb9c40154d2beee6cf8e0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84931d887f8e135b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:50:19,723 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:50:19,724 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:50:19,725 - DEBUG - receive_response_body.complete
2024-01-21 16:50:19,725 - DEBUG - response_closed.started
2024-01-21 16:50:19,726 - DEBUG - response_closed.complete
2024-01-21 16:50:19,726 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:50:19,727 - INFO - Received response from OpenAI: 

@startuml

class File {
    - path: string
    - abspath: string
}

class Logger {
    - info(message: string)
    - warning(message: string)
    - error(message: string)
}

class InclusionManager {
    + include_list: list
    + ignore_list: list
    - included_files: dict
    + retrieve_code(): dict
}

File --> Logger
InclusionManager --> File

start
if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list)
if "Yes" then (true)
note left: success
if "No" then (false)
note right: failure
end

stop

@enduml
2024-01-21 16:50:19,728 - INFO - UML code generated for src/routes/retrieve_code.py: @startuml
title retrieve_code.py
# Return the repository object
        return repo
    
    except Exception as e:
        logger.error(f"Failed to clone repository {repo_url}: {e}")
        raise e  # Rethrow the exception


# Define variables
repo_url = 'https://github.com/user/repo.git'
temp_dir = 'clone'
access_token = '123456789'


@startuml

class git {
- repo_url: string
- temp_dir: string
- access_token: string
-- clone_repo()
}

class json {
+ encode()
+ decode()
}

class os {
+ makedirs()
}

class logging {
- file_handler: handlers.RotatingFileHandler
-- config()
+ getLogger()
+ addHandler()
+ setLevel()
}

class handlers {
- file_handler: RotatingFileHandler
+ RotatingFileHandler()
+ Formatter()
+ setFormatter()
+ setLevel()
}

class RotatingFileHandler {
+ maxBytes: int
+ backupCount: int
-- stream: StreamHandler
+ doRollover()
+ shouldRollover()
}

class StreamHandler {
+ write()
}

class Logger {
- file_handler: handlers.RotatingFileHandler
+ info()
+ error()
+ warning()
+ debug()
}

class Exception {
}

class git.Repo {
- repo_url: string
- temp_dir: string
constructor clone_from()
-- check_available_version()
+ git.Commit
}

class git.Commit {
- message: string
- author: string
+ git.Tree
+ git.Parent
+ commit()
}

class git.Tree {
- path: string
- mode: string
+ blob()
+ tree()
}

class git.Parent {
- hexsha: string
}

git.Repo "1"--|> git.Commit
git.Commit "1"--|> git.Tree
git.Commit "1"--|> git.Parent
git.Repo "1" o--> Exception
logger o--> Logger
logger o--> StreamHandler
handlers "1"--|> RotatingFileHandler
handlers "1"--|> Formatter
handlers o--> Exception
handlers o--> StreamHandler
Logger o--> Exception
StreamHandler o--> Exception
handlers o--> RotatingFileHandler
RotatingFileHandler "1"*--> StreamHandler
git o--> Exception
git "1" o--> json
git "1" o--> os
json o--> Exception
os o--> Exception
json o--> Logger
os o--> Logger
os o--> handlers

@enduml
2024-01-21 16:50:19,728 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 16:50:19,729 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 16:50:19,729 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-21 16:50:19,729 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-21 16:50:19,731 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-21 16:50:19,732 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:50:19,733 - DEBUG - send_request_headers.complete
2024-01-21 16:50:19,733 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:50:19,733 - DEBUG - send_request_body.complete
2024-01-21 16:50:19,733 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:50:24,817 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:50:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4987'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'4476cc7bb7ea4927dedd8e1277c8495e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84931d91dbdc135b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:50:24,820 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:50:24,820 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:50:24,821 - DEBUG - receive_response_body.complete
2024-01-21 16:50:24,821 - DEBUG - response_closed.started
2024-01-21 16:50:24,822 - DEBUG - response_closed.complete
2024-01-21 16:50:24,822 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:50:24,823 - INFO - Received response from OpenAI: t_repo_name = git_repo_url.split('/')[-1]  # Get the name of the repository from the URL

    # Clone the repository
    repo = clone_repo(git_repo_url)  # Call function from retrieve_code.py

    # Retrieve code from the repository
    code_directory = retrieve_code(repo, output_directory)  # Call function from retrieve_code.py

    # Generate UML content from the retrieved code
    uml_content = generate_content(code_directory)  # Call function from code_to_uml.py

    # Write the UML content to a .puml file
    output_filename = f'{git_repo_name}.puml'
    output_path = os.path.join(output_directory, output_filename)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(uml_content)

@startuml

class UmlFromRepo { 
    - log_directory: String 
    - log_filename: String 
    - log_handler: RotatingFileHandler 
    - log_formatter: Formatter 
    - logger: Logger 
    + process_request(data): void
} 

class Logging {
    - log_level: String 
    + set_log_level(level: String): void 
    + get_logger(): Logger 
} 

class FileIO {
    - output_directory: String 
    - output_filename: String 
    - output_path: String 
    + write_to_file(content: String): void
}

class Git { 
    - repo_url: String 
    - repo_name: String 
    + clone_repo(url: String): git.Repo 
}

class RetrieveCode {
    - repo: git.Repo 
    - code_directory: String 
    + retrieve_code(repo: git.Repo, output_dir: String): String 
}

class CodeToUml { 
    - code_dir: String 
    - uml_content: String 
    + generate_content(code_dir: String): String 
} 

UmlFromRepo --> Logging 
UmlFromRepo --> Git 
UmlFromRepo --> RetrieveCode 
UmlFromRepo --> CodeToUml 
UmlFromRepo --> FileIO 

Logging --> Logger 

FileIO --> File 

Git --> git.Repo 

RetrieveCode --> Git 
RetrieveCode --> FileIO 

CodeToUml --> FileIO 

@enduml
2024-01-21 16:50:24,824 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-21 16:50:24,826 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-21 16:50:24,827 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:50:24,828 - DEBUG - send_request_headers.complete
2024-01-21 16:50:24,828 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:50:24,829 - DEBUG - send_request_body.complete
2024-01-21 16:50:24,829 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:50:33,795 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:50:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'8821'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'63d75027139f16103fe7d5d545ec6da7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84931db1aadd135b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:50:33,797 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:50:33,797 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:50:33,798 - DEBUG - receive_response_body.complete
2024-01-21 16:50:33,798 - DEBUG - response_closed.started
2024-01-21 16:50:33,798 - DEBUG - response_closed.complete
2024-01-21 16:50:33,799 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:50:33,800 - INFO - Received response from OpenAI: )

        # Get all files from the output directory
        files = get_files(output_directory)

        # Generate UML diagrams for each file
        for file in files:
            generate_diagrams(file, temp_dir, config)

        # Create a zip file of the diagrams
        zip_path = create_zip(temp_dir, output_directory)

@startuml
class MainController {
    -logger: LogHandler
    -data: Dictionary
    -temp_dir: string
    -thub_access_token: string
    -branch_name: string
    -config: json
    +MainController(logger: LogHandler, data: Dictionary)
    +set_temp_dir(temp_dir: string)
    +set_tub_access_token(thub_access_token: string)
    +set_branch_name(branch_name: string)
    +set_config(config: json)
    +clone_repo(git_repo_url: string, temp_dir: string, github_access_token: string): Repository
    +get_files(output_directory: string): Files[]
    +generate_diagrams(file: File, temp_dir: string, config: json): void
    +create_zip(temp_dir: string, output_directory: string): string
    +run(): void
}

MainController --> LogHandler
MainController --> Dictionary
MainController --> Repository
MainController --> Files
MainController --> File
MainController --> LogHandler
MainController --> Dictionary
MainController --> string
MainController --> string
MainController --> json

enum CloneResult {
    SUCCESS
    ERROR
}

MainController "1" --> "1" LogHandler
MainController "1" --> "1" Dictionary
MainController "1" --> "1" Repository
MainController "1" --> "1" clone_repo(git_repo_url: string, temp_dir: string, github_access_token: string): CloneResult
MainController "1" --> "1" get_files(output_directory: string): Files[]
MainController "1" --> "1" generate_diagrams(file: File, temp_dir: string, config: json): void
MainController "1" --> "1" create_zip(temp_dir: string, output_directory: string): string
MainController "1" --> "1" run(): void

class Repository {
    -git_repo_url: string
    -github_access_token: string
    +Repository(git_repo_url: string, github_access_token: string)
    +get_repos(): Repos[]
    +get_contents(repo: Repo, directory: string): Contents[]
}

MainController --> Repository

class LogHandler {
    +error(message: string): void
    +info(message: string):void
    +debug(message: string): void
}

MainController --> LogHandler

class Dictionary {
    +get(key: string): string
}

MainController --> Dictionary

class Files {
    -file_name: string
    +Files(file_name: string)
    +get_file_name(): string
}

MainController --> Files

class File {
    -name: string
    -temp_dir: string
    -config: json
    +File(name: string, temp_dir: string, config: json)
    +generate_diagram(config: json): void
}

MainController --> File
MainController --> json

class LogHandler {
    +error(message: string): void
    +info(message: string): void
}

MainController --> LogHandler

class Repository {
    -git_repo_url: string
    -github_access_token: string
    +Repository(git_repo_url: string, github_access_token: string)
    +set_git_repo_url(git_repo_url: string)
    +set_github_access_token(github_access_token: string)
    +clone(directory: string): Repository
    +load_config(): json
    +get_files(): Files[]
    +generate_diagrams(config: json): void
}

MainController --> Repository

class Files {
    -file_name: string
    +Files(file_name: string)
    +get_file_name(): string
}

MainController --> Files
2024-01-21 16:50:33,801 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-21 16:50:33,803 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-21 16:50:33,804 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:50:33,804 - DEBUG - send_request_headers.complete
2024-01-21 16:50:33,805 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:50:33,805 - DEBUG - send_request_body.complete
2024-01-21 16:50:33,805 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:50:36,679 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:50:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2779'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'e0a684dc6d7863fb3bd54d0cd290abe3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84931de9cc05135b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:50:36,680 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:50:36,681 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:50:36,682 - DEBUG - receive_response_body.complete
2024-01-21 16:50:36,682 - DEBUG - response_closed.started
2024-01-21 16:50:36,683 - DEBUG - response_closed.complete
2024-01-21 16:50:36,683 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:50:36,685 - INFO - Received response from OpenAI: puml

@startuml
class traverse_directories
- repo: <Repository Object>
- temp_dir: <temporary directory path>
- config: Dictionary

+ traverse_directories(repo, temp_dir, config): Dictionary
+ included_files: Dictionary
+ fnmatch: <Filename Matching module>
+ os: <Operating System module>

# Iterate through the repository tree
for item in repo.tree().traverse():
# Check if item is a file
if item.type == 'blob':
for pattern in config['include']:
if fnmatch.fnmatch(item.path, pattern):
with open(os.path.join(temp_dir, item.path), 'r') as f:
# Add the file to included_files dictionary
included_files[item.path] = f.read()
# Break from loop if file matches pattern
break
# Return included_files dictionary
return included_files
@enduml

@startuml
class logger
- debug: <Debug function>
- info: <Information function>
- output_directory: <Output directory path>

+ debug(message): void
+ info(message): void

@enduml

@startuml
class generate_content
- output_paths: List

+ generate_content(included_files): List
+ output_paths: List

@enduml
2024-01-21 16:50:36,685 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-21 16:50:36,687 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-21 16:50:36,689 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:50:36,689 - DEBUG - send_request_headers.complete
2024-01-21 16:50:36,689 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:50:36,690 - DEBUG - send_request_body.complete
2024-01-21 16:50:36,690 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:50:40,544 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:50:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3601'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'5ee25406a0906b1905d4f22aa3bd5cd7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84931dfbda35135b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:50:40,546 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:50:40,546 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:50:40,548 - DEBUG - receive_response_body.complete
2024-01-21 16:50:40,548 - DEBUG - response_closed.started
2024-01-21 16:50:40,548 - DEBUG - response_closed.complete
2024-01-21 16:50:40,548 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:50:40,550 - INFO - Received response from OpenAI: \startuml
class t {
-included_files
-output_directory
+logger
+git_repo_url
+final_output_paths

+t(included_files, output_directory)
+generate_uml()
-clean_up()
}

class logger {
+info()
+error()
}

t -> logger: logger.info("Final output paths: {final_output_paths}")

for path in final_output_paths:
  t -> logger: logger.info("UML diagram saved at: {path}")

t -> logger: logger.error("Error during UML generation: {e}")

t -> logger: logger.info("Cleaning up temporary directory")
t -> +clean_up()

class logger {
+info()
+error()
}

note top: This class represents the entry point for the program that generates UML diagrams. It takes in a list of included files and an output directory and uses a logger to log information during the process. The final output paths and the git repository URL are also stored here.\n

note left: This method generates the UML diagrams by using the list of included files and the designated output directory. It also logs the paths where the diagrams were saved.\n

note right: This method is called in case of an error during UML generation. It uses the logger to log the error message.\n

t --> logger : error()

class output {
+message
+details
}

output -> t : final_output_paths
output -> t : git_repo_url
note bottom: This class represents the output of the program, which includes a message indicating the success of the UML generation and the repository URL and final output paths.\n

@enduml
2024-01-21 16:50:40,551 - INFO - UML code generated for src/routes/uml_from_repo.py: @startuml
title uml_from_repo.py
t_repo_name = git_repo_url.split('/')[-1]  # Get the name of the repository from the URL

    # Clone the repository
    repo = clone_repo(git_repo_url)  # Call function from retrieve_code.py

    # Retrieve code from the repository
    code_directory = retrieve_code(repo, output_directory)  # Call function from retrieve_code.py

    # Generate UML content from the retrieved code
    uml_content = generate_content(code_directory)  # Call function from code_to_uml.py

    # Write the UML content to a .puml file
    output_filename = f'{git_repo_name}.puml'
    output_path = os.path.join(output_directory, output_filename)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(uml_content)

@startuml

class UmlFromRepo { 
    - log_directory: String 
    - log_filename: String 
    - log_handler: RotatingFileHandler 
    - log_formatter: Formatter 
    - logger: Logger 
    + process_request(data): void
} 

class Logging {
    - log_level: String 
    + set_log_level(level: String): void 
    + get_logger(): Logger 
} 

class FileIO {
    - output_directory: String 
    - output_filename: String 
    - output_path: String 
    + write_to_file(content: String): void
}

class Git { 
    - repo_url: String 
    - repo_name: String 
    + clone_repo(url: String): git.Repo 
}

class RetrieveCode {
    - repo: git.Repo 
    - code_directory: String 
    + retrieve_code(repo: git.Repo, output_dir: String): String 
}

class CodeToUml { 
    - code_dir: String 
    - uml_content: String 
    + generate_content(code_dir: String): String 
} 

UmlFromRepo --> Logging 
UmlFromRepo --> Git 
UmlFromRepo --> RetrieveCode 
UmlFromRepo --> CodeToUml 
UmlFromRepo --> FileIO 

Logging --> Logger 

FileIO --> File 

Git --> git.Repo 

RetrieveCode --> Git 
RetrieveCode --> FileIO 

CodeToUml --> FileIO 

@enduml
2024-01-21 16:50:40,552 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 16:50:40,552 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 16:50:40,553 - INFO - Skipping empty file: src/scripts/__init__.py
2024-01-21 16:50:40,553 - INFO - Processing file: src/scripts/execute_generate_uml.py
2024-01-21 16:50:40,553 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import json
import os
import requests
import logging
from logging import handlers
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure logging to write to a file
log_directory = '../../logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'execute_generate_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


# Configure logging
logging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))
# Configuration file path
config_file_path = os.path.join(cu
2024-01-21 16:50:40,555 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nimport json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(cu", 'max_tokens': 1024}}
2024-01-21 16:50:40,556 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:50:40,557 - DEBUG - send_request_headers.complete
2024-01-21 16:50:40,557 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:50:40,557 - DEBUG - send_request_body.complete
2024-01-21 16:50:40,557 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:50:40,677 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:50:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'44'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'b6dcb40d64163504abaff6d9754e8387'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84931e140fd5135b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:50:40,679 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:50:40,679 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:50:40,680 - DEBUG - receive_response_body.complete
2024-01-21 16:50:40,680 - DEBUG - response_closed.started
2024-01-21 16:50:40,681 - DEBUG - response_closed.complete
2024-01-21 16:50:40,681 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:50:40,683 - INFO - Received response from OpenAI: 
2024-01-21 16:50:40,683 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

rrent_dir, 'config.json')

# Read configuration from the JSON file
with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

# Retrieve the GitHub access token from environment variables
github_token = os.getenv('GITHUB_PAT')

# Endpoint URL
url = 'http://127.0.0.1:5000/generate-uml'

# Headers
headers = {
    'Content-Type': 'application/json'
}

# Update the GitHub access token and local directory in the config data
config_data['gitHubAccessToken'] = github_token
config_data['local_dir'] = os.path.join(current_dir, '../..', 'output')

# Log the JSON data being sent in the request
logging.info(f'Sending JSON data to {url}:')
logging.info(json.dumps(config_data, indent=2))

try:
    # Make the POST request
    response = requests.post(url, headers=headers, json=config_data)

    # Log the response from the server
    logging.info(f'Response from server ({url}):')
    logging.info(f'Status Code: {response.status_code}')
    logging.info(f'Response Text: {response.text}')

    #
2024-01-21 16:50:40,685 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nrrent_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    #", 'max_tokens': 1024}}
2024-01-21 16:50:40,687 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:50:40,687 - DEBUG - send_request_headers.complete
2024-01-21 16:50:40,687 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:50:40,687 - DEBUG - send_request_body.complete
2024-01-21 16:50:40,688 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:50:43,802 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:50:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3016'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'7eea969b531370094c6c49d552569adb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84931e14c8b1135b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:50:43,803 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:50:43,803 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:50:43,803 - DEBUG - receive_response_body.complete
2024-01-21 16:50:43,803 - DEBUG - response_closed.started
2024-01-21 16:50:43,804 - DEBUG - response_closed.complete
2024-01-21 16:50:43,804 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:50:43,805 - INFO - Received response from OpenAI:  Check for errors in the response
    if response.status_code == 200:
        logging.info('Generated UML diagrams successfully!')
    else:
        logging.error('An error occurred while generating UML diagrams.')

except requests.exceptions.RequestException as e:
    logging.error(f'An error occurred while making a request to {url}. Message: {e}')

```

@startuml
Class ConfigReader {
    - current_dir: str
    - config_file_path: str
    - config_data: dict
    - github_token: str
    - url: str
    - headers: dict
    - response: Response
    + read_config()
    + update_config()
    + make_request()
}

Class GitHubAPI {
    - access_token: str
    - local_dir: str
    + get_access_token()
    + update_local_dir()
}

Class Logger {
    + log_message()
}

ConfigReader --> Logger
GitHubAPI --> Logger

ConfigReader --> GitHubAPI
ConfigReader --> Logger: send log message
ConfigReader --> Response
ConfigReader --> Logger: send log message

GitHubAPI --> ConfigReader: retrieve access token
GitHubAPI --> ConfigReader: update local directory
GitHubAPI --> Logger: send log message

Logger --> ConfigReader: receive log message
Logger --> GitHubAPI: receive log message
Logger --> Response: receive log message
@enduml
2024-01-21 16:50:43,805 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

 Print the response from the server
    print(response.text)

    # Save the response to a file in the output directory
    output_dir = os.path.join(current_dir, '../..', 'output')
    os.makedirs(output_dir, exist_ok=True)
    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:
        json.dump(response.json(), output_file, indent=2)

except Exception as e:
    # Log any exceptions that occur
    logging.error(f'Error occurred: {str(e)}')
2024-01-21 16:50:43,806 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')", 'max_tokens': 1024}}
2024-01-21 16:50:43,807 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:50:43,808 - DEBUG - send_request_headers.complete
2024-01-21 16:50:43,808 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:50:43,808 - DEBUG - send_request_body.complete
2024-01-21 16:50:43,808 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:50:45,346 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:50:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1474'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'1bef1dd62ae1f3353612125e0a5fe43f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84931e2848fe135b-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:50:45,348 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:50:45,350 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:50:45,350 - DEBUG - receive_response_body.complete
2024-01-21 16:50:45,351 - DEBUG - response_closed.started
2024-01-21 16:50:45,351 - DEBUG - response_closed.complete
2024-01-21 16:50:45,351 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:50:45,353 - INFO - Received response from OpenAI: 




@startuml

class PrintResponse {
    - response : object

    + PrintResponse()
    + printResponse(response : object)
}

class Output {
    - output_dir : string

    + Output()
    + createDir(path : string)
    + saveFile(path : string, data : object)
}

class Logging {
    + logException(error : string)
}

PrintResponse --> Output
Output --> Logging

PrintResponse : + printResponse(response : object)
Output : + createDir(path : string)
Output : + saveFile(path : string, data : object)
Logging : + logException(error : string)

@enduml

2024-01-21 16:50:45,353 - INFO - UML code generated for src/scripts/execute_generate_uml.py: @startuml
title execute_generate_uml.py

@enduml
2024-01-21 16:50:45,353 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 16:50:45,355 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 16:50:45,355 - INFO - Generated file paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 16:50:45,356 - INFO - Final output paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 16:50:45,356 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 16:50:45,356 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 16:50:45,356 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 16:50:45,356 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 16:50:45,356 - INFO - Cleaning up temporary directory
2024-01-21 16:50:45,536 - INFO - 127.0.0.1 - - [21/Jan/2024 16:50:45] "POST /generate-uml HTTP/1.1" 200 -
2024-01-21 16:55:33,960 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 16:55:33,961 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 16:55:33,976 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-21 16:55:33,976 - INFO - [33mPress CTRL+C to quit[0m
2024-01-21 16:55:33,977 - INFO -  * Restarting with stat
2024-01-21 16:55:34,254 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 16:55:34,255 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 16:55:34,263 - WARNING -  * Debugger is active!
2024-01-21 16:55:34,270 - INFO -  * Debugger PIN: 139-904-016
2024-01-21 16:55:38,188 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-21 16:55:38,188 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-21 16:55:38,188 - INFO - Received local_dir: ./output
2024-01-21 16:55:38,188 - INFO - Received gitHubAccessToken: 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
2024-01-21 16:55:38,189 - INFO - Cleaning up temporary directory
2024-01-21 16:55:38,189 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 16:55:38,191 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-21 16:55:38,191 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpb17kgv03'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-21 16:55:41,944 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpb17kgv03'])'s unused stdout: 
2024-01-21 16:55:41,946 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 16:55:41,946 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpb17kgv03, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 16:55:41,952 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpb17kgv03, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 16:55:41,975 - DEBUG - Type of included_files: <class 'dict'>
2024-01-21 16:55:41,976 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 16:55:41,976 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-21 16:55:41,976 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 16:55:41,976 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-21 16:55:41,976 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-21 16:55:41,976 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-21 16:55:41,977 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-21 16:55:41,992 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-21 16:55:42,078 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1105a7a10>
2024-01-21 16:55:42,078 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110299b50> server_hostname='api.openai.com' timeout=5.0
2024-01-21 16:55:42,119 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x111812550>
2024-01-21 16:55:42,119 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:55:42,120 - DEBUG - send_request_headers.complete
2024-01-21 16:55:42,120 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:55:42,120 - DEBUG - send_request_body.complete
2024-01-21 16:55:42,120 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:55:49,595 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:55:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'7391'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'0213aa9bed6c93c5fff078fbc37a850c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3fj_JJ6uU45TGyKNEnZ1fBTAxfeJST6idNww6dl35qs-1705877749-1-ATXuMEYgLmv/96z2CYRC2OEOCxlN7hPLCqcokhK2DtrI9bjSakAIVBcQ6/r9kJuvL11jYwx+j5D4AS+f6aumfcs=; path=/; expires=Sun, 21-Jan-24 23:25:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=2PvuImOcjaCCTvpPPc0YlksbruuF6MsaWQ3X5OAmJvU-1705877749656-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84932570c898675e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:55:49,598 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:55:49,598 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:55:49,599 - DEBUG - receive_response_body.complete
2024-01-21 16:55:49,599 - DEBUG - response_closed.started
2024-01-21 16:55:49,600 - DEBUG - response_closed.complete
2024-01-21 16:55:49,600 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:55:49,603 - INFO - Received response from OpenAI:  or if it's a hidden file
        if not code or file_path.startswith('.'):
            continue
        # Add file path to list
        file_paths.append(file_path)
        # Generate code using the OpenAI API
        generated_code += api.generate(code)
    # Write the generated code to a file
    output_file = os.path.join(output_directory, 'generated_code.py')
    with open(output_file, 'w') as f:
        f.write(generated_code)
    logging.info(f"Generated code written to file: {output_file}")  # Log the output file path

# Define the input files and output directory
input_files = {
    'input/sample1.py': '# This is a sample input file\nprint("Hello world!")',
    'input/sample2.py': '# This is another sample input file\nprint("Hello from OpenAI!")'
}
output_dir = 'output'

# Call the function to generate code
generate_content(input_files, output_dir)


@startuml

class OpenAIAPI {
  - api_key: String
  + generate(code: String): String
}

class logging.handlers.RotatingLogFile {
  - maxBytes: Integer
  - backupCount: Integer
  + emit(record: LogRecord): Void
}

class logging.Logger {
  - handlers: List[log.handlers]
  - level: Integer
  + addHandler(handler: Handler): Void
  + setLevel(level: Integer): Void
  + info(msg: String): Void
  + debug(msg: String): Void
}

class code_to_uml {
  # api: OpenAIAPI
  # log_directory: String
  # log_filename: String
  # log_handler: RotatingLogFile
  # log_formatter: Formatter
  # logger: Logger
  - generate_content(files: Dictionary, output_directory: String): Void
}

code_to_uml --> OpenAIAPI
code_to_uml --> logging.handlers.RotatingLogFile
code_to_uml --> logging.Logger

note right of code_to_uml: Imports

note right of code_to_uml: Instance creation

note left: Configure logging

note left: Define input files and output directory

code_to_uml: - input_files: Dictionary
code_to_uml: - output_dir: String

OpenAIAPI --> "api.generate(code)"

logging.handlers.RotatingLogFile --> "handler emit(record)"

logging.Logger --> "addHandler(handler)"
logging.Logger --> "setLevel(level)"
logging.Logger --> "logger.info(msg)"
logging.Logger --> "logger.debug(msg)"

code_to_uml --> "generate_content(files, output_directory)"

note right: Function call

note right: Write generated code to output file

generate_content --> "generated_code" : Initialization

note right: Initialize generated_code and file_paths

"generated_code" --> "+code: String"
"file_paths" --> "+paths: List"

generate_content --> "files" : Traversing

note right: Traverse dictionary of input files

note right: Skip if file is empty or hidden

note right: Add file path to file_paths

note right: Generate code using OpenAI API and append to generated_code

note right: Write generated code to output file

generate_content --> "+output_file: String"

note right: Log output file path

note right: Main code execution

@enduml
2024-01-21 16:55:49,604 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-21 16:55:49,606 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-21 16:55:49,607 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:55:49,608 - DEBUG - send_request_headers.complete
2024-01-21 16:55:49,608 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:55:49,608 - DEBUG - send_request_body.complete
2024-01-21 16:55:49,608 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:55:51,513 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:55:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1829'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'b9af82d4b43f4a95776d5129be4bf651'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493259f897c675e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:55:51,514 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:55:51,515 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:55:51,516 - DEBUG - receive_response_body.complete
2024-01-21 16:55:51,516 - DEBUG - response_closed.started
2024-01-21 16:55:51,517 - DEBUG - response_closed.complete
2024-01-21 16:55:51,517 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:55:51,518 - INFO - Received response from OpenAI: _paths})
    
@startuml

start

if not code.strip() then
  :Skip empty file;
  :continue;
else
  :Logging information about skipping empty file: ${file_path};
endif

:Logging information about processing file: {file_path};
:Generating UML code for {file_path};
:Logging generated UML code;
if not generated_code_for_file OR "UML generation failed" in generated_code_for_file then
  :Logging error;
  :Raise value error;
else
  :Append generated code for file to overall generated code;
  :Save generated code to separate .puml file;
  :Add file path to list of file paths;
endif

:Logging generated file paths: ${file_paths};

stop

@enduml
2024-01-21 16:55:51,518 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-21 16:55:51,519 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-21 16:55:51,520 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:55:51,520 - DEBUG - send_request_headers.complete
2024-01-21 16:55:51,520 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:55:51,520 - DEBUG - send_request_body.complete
2024-01-21 16:55:51,521 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:55:53,841 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:55:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2257'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'44a9656f221c8b3af56d1a70bbc5aa1d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849325ab8b96675e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:55:53,845 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:55:53,845 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:55:53,846 - DEBUG - receive_response_body.complete
2024-01-21 16:55:53,846 - DEBUG - response_closed.started
2024-01-21 16:55:53,846 - DEBUG - response_closed.complete
2024-01-21 16:55:53,846 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:55:53,848 - INFO - Received response from OpenAI: 


----------------------------------------------------------------

@startuml

class CodeGenerator {
    - language : str
    - template : str
    - data : dict
    - output_dir : str

    + __init__(language: str, template: str, data: dict, output_dir: str)
    + generate_code() : list[str]
    + save_code(code: str, path: str) : None
    + create_output_dir() : None
}

CodeGenerator --> _language : str
CodeGenerator --> _template : str
CodeGenerator --> _data : dict
CodeGenerator --> _output_dir : str
CodeGenerator : __init__(language: str, template: str, data: dict, output_dir: str)
CodeGenerator : generate_code() : list[str]
CodeGenerator : save_code(code: str, path: str) : None
CodeGenerator : create_output_dir() : None

@enduml
2024-01-21 16:55:53,848 - INFO - UML code generated for src/routes/code_to_uml.py: @startuml
title code_to_uml.py
or if it's a hidden file
        if not code or file_path.startswith('.'):
            continue
        # Add file path to list
        file_paths.append(file_path)
        # Generate code using the OpenAI API
        generated_code += api.generate(code)
    # Write the generated code to a file
    output_file = os.path.join(output_directory, 'generated_code.py')
    with open(output_file, 'w') as f:
        f.write(generated_code)
    logging.info(f"Generated code written to file: {output_file}")  # Log the output file path

# Define the input files and output directory
input_files = {
    'input/sample1.py': '# This is a sample input file\nprint("Hello world!")',
    'input/sample2.py': '# This is another sample input file\nprint("Hello from OpenAI!")'
}
output_dir = 'output'

# Call the function to generate code
generate_content(input_files, output_dir)


@startuml

class OpenAIAPI {
  - api_key: String
  + generate(code: String): String
}

class logging.handlers.RotatingLogFile {
  - maxBytes: Integer
  - backupCount: Integer
  + emit(record: LogRecord): Void
}

class logging.Logger {
  - handlers: List[log.handlers]
  - level: Integer
  + addHandler(handler: Handler): Void
  + setLevel(level: Integer): Void
  + info(msg: String): Void
  + debug(msg: String): Void
}

class code_to_uml {
  # api: OpenAIAPI
  # log_directory: String
  # log_filename: String
  # log_handler: RotatingLogFile
  # log_formatter: Formatter
  # logger: Logger
  - generate_content(files: Dictionary, output_directory: String): Void
}

code_to_uml --> OpenAIAPI
code_to_uml --> logging.handlers.RotatingLogFile
code_to_uml --> logging.Logger

note right of code_to_uml: Imports

note right of code_to_uml: Instance creation

note left: Configure logging

note left: Define input files and output directory

code_to_uml: - input_files: Dictionary
code_to_uml: - output_dir: String

OpenAIAPI --> "api.generate(code)"

logging.handlers.RotatingLogFile --> "handler emit(record)"

logging.Logger --> "addHandler(handler)"
logging.Logger --> "setLevel(level)"
logging.Logger --> "logger.info(msg)"
logging.Logger --> "logger.debug(msg)"

code_to_uml --> "generate_content(files, output_directory)"

note right: Function call

note right: Write generated code to output file

generate_content --> "generated_code" : Initialization

note right: Initialize generated_code and file_paths

"generated_code" --> "+code: String"
"file_paths" --> "+paths: List"

generate_content --> "files" : Traversing

note right: Traverse dictionary of input files

note right: Skip if file is empty or hidden

note right: Add file path to file_paths

note right: Generate code using OpenAI API and append to generated_code

note right: Write generated code to output file

generate_content --> "+output_file: String"

note right: Log output file path

note right: Main code execution

@enduml
2024-01-21 16:55:53,849 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 16:55:53,849 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 16:55:53,850 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-21 16:55:53,850 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-21 16:55:53,852 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-21 16:55:53,854 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:55:53,854 - DEBUG - send_request_headers.complete
2024-01-21 16:55:53,855 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:55:53,855 - DEBUG - send_request_body.complete
2024-01-21 16:55:53,855 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:55:58,115 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:55:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4180'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'70efc7fc36abedcdd5cb8636d39b1f48'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849325ba2e75675e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:55:58,116 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:55:58,116 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:55:58,117 - DEBUG - receive_response_body.complete
2024-01-21 16:55:58,117 - DEBUG - response_closed.started
2024-01-21 16:55:58,117 - DEBUG - response_closed.complete
2024-01-21 16:55:58,117 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:55:58,120 - INFO - Received response from OpenAI:  # Return the path to the cloned repo
        return temp_dir
    except git.GitCommandError as e:
        logger.error(f"Error cloning repository: {repo_url} - {e}")
        return None


def get_repo_file(repo_dir, file_name):
    # Construct the path to the file within the repo
    repo_file_path = os.path.join(repo_dir, file_name)
    try:
        with open(repo_file_path, 'r') as f:
            data = json.loads(f.read())
            logger.info(f"Successfully retrieved data from {file_name} in repository")
            return data
    except FileNotFoundError:
        logger.error(f"Could not find {file_name} in the repository")
        return None


@startuml

import git
import json
import os
import logging
from logging import handlers

hide empty members
skinparam node {

BackgroundColor White
BorderColor Black
}

rectangle MainClass {
- log_directory : String
- log_filename : String
- log_handler : RotatingFileHandler
- log_formatter : Formatter
- logger : Logger
- clone_repo(repo_url, temp_dir, access_token) : String
- get_repo_file(repo_dir, file_name) : Object
}

rectangle git.Repo {
}

rectangle Logging {
- log_directory : String
- log_handler : RotatingFileHandler
}

rectangle handlers.RotatingFileHandler {
- log_formatter : Formatter
- log_filename : String
}

rectangle Formatter {
}

rectangle Logger {
- log_handler : RotatingFileHandler
- log_level : Level
}

rectangle git.GitCommandError {
}

rectangle FileNotFoundError {
}

MainClass o- Logging
MainClass -- git.Repo
MainClass - handlers.RotatingFileHandler
MainClass o-- Formatter
MainClass o-- Logger
MainClass -- git.GitCommandError
MainClass -- FileNotFoundError

@enduml
2024-01-21 16:55:58,120 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-21 16:55:58,121 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-21 16:55:58,122 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:55:58,122 - DEBUG - send_request_headers.complete
2024-01-21 16:55:58,122 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:55:58,123 - DEBUG - send_request_body.complete
2024-01-21 16:55:58,123 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:56:01,053 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:56:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2830'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'e4649e7716a2244a6a35b92f1bd0ac6e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849325d4cab7675e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:56:01,055 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:56:01,055 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:56:01,056 - DEBUG - receive_response_body.complete
2024-01-21 16:56:01,056 - DEBUG - response_closed.started
2024-01-21 16:56:01,056 - DEBUG - response_closed.complete
2024-01-21 16:56:01,057 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:56:01,058 - INFO - Received response from OpenAI:  if any(file.fnmatch(pattern) for pattern in include_list):  # Check if file matches any patterns in the include list
                  if not any(file.fnmatch(pattern) for pattern in ignore_list):  # Check if file matches any patterns in the ignore list, if not add to included_files dict
                     included_files[file.path] = file.data_stream.read().decode("utf-8")             
    except Exception as e:
       

@startuml

class Main {
    -logger: Logger
    -config: Dictionary
    -ignore_list: List
    -include_list: List

    +retrieve_code(repo, branch_name): void
}

class Repo {
    +tree(): Tree
}

class Tree {
    +fnmatch(pattern): boolean
}

class Logger {
    +error(msg: String): void
    +info(msg: String): void
}

class ConfigLoader {
    +load_config(): void
}

Main ..> Logger
Main ..> ConfigLoader
Main ..> Repo

Main -> Repo: +retrieve_code(repo, branch_name)
Repo ..> Tree
Repo -> Tree: +tree()
Tree -> Tree: +fnmatch(pattern)
Logger --> Main: +error(msg)
Logger --> Main: +info(msg)
ConfigLoader ..> Config: +load_config()
Config -> Main: -config
Main -> Config: +retrieve_code(repo, branch_name)

@enduml

2024-01-21 16:56:01,058 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-21 16:56:01,060 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-21 16:56:01,062 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:56:01,062 - DEBUG - send_request_headers.complete
2024-01-21 16:56:01,062 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:56:01,062 - DEBUG - send_request_body.complete
2024-01-21 16:56:01,063 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:56:04,921 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:56:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3791'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'cba6f4e60073595c92a3cb4b65f4deed'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849325e72e90675e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:56:04,923 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:56:04,924 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:56:04,925 - DEBUG - receive_response_body.complete
2024-01-21 16:56:04,925 - DEBUG - response_closed.started
2024-01-21 16:56:04,925 - DEBUG - response_closed.complete
2024-01-21 16:56:04,926 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:56:04,928 - INFO - Received response from OpenAI: 

@startuml
class CodeRetriever {

}

class File {
    - path : String
    - abspath : String
}

class Logger {
    - info() : void
    - warning() : void
    - error() : void
}

File <|-- CodeRetriever
Logger <|-- CodeRetriever

CodeRetriever o--> File
CodeRetriever o--> Logger

CodeRetriever : +included_files : Map<String, String>
CodeRetriever : #include_list : List<String>
CodeRetriever : #ignore_list : List<String>

CodeRetriever : retrieve_code() : Map<String, String>

CodeRetriever .up.> File : uses
CodeRetriever .up.> Logger : uses

CodeRetriever --> "if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list)" as check
CodeRetriever --> "try:" as try
CodeRetriever --> "except Exception as e:" as exception

check --> try : true
check --> try : false
try --> "with open(file.abspath, 'r') as f:" as open
try --> "except FileNotFoundError:" as file_not_found

open --> "included_files[file.path] = f.read()" as add_file
open --> "logger.info(f"Included file: {file.path}")" as log

file_not_found --> "print(f"Ignoring missing file: {file.path}")" as print
file_not_found --> "logger.warning(f"Ignoring missing file: {file.path}")" as log_warning
exception --> "logger.error(f"Failed to retrieve code: {str(e)})"" as log_error

@enduml
2024-01-21 16:56:04,928 - INFO - UML code generated for src/routes/retrieve_code.py: @startuml
title retrieve_code.py
# Return the path to the cloned repo
        return temp_dir
    except git.GitCommandError as e:
        logger.error(f"Error cloning repository: {repo_url} - {e}")
        return None


def get_repo_file(repo_dir, file_name):
    # Construct the path to the file within the repo
    repo_file_path = os.path.join(repo_dir, file_name)
    try:
        with open(repo_file_path, 'r') as f:
            data = json.loads(f.read())
            logger.info(f"Successfully retrieved data from {file_name} in repository")
            return data
    except FileNotFoundError:
        logger.error(f"Could not find {file_name} in the repository")
        return None


@startuml

import git
import json
import os
import logging
from logging import handlers

hide empty members
skinparam node {

BackgroundColor White
BorderColor Black
}

rectangle MainClass {
- log_directory : String
- log_filename : String
- log_handler : RotatingFileHandler
- log_formatter : Formatter
- logger : Logger
- clone_repo(repo_url, temp_dir, access_token) : String
- get_repo_file(repo_dir, file_name) : Object
}

rectangle git.Repo {
}

rectangle Logging {
- log_directory : String
- log_handler : RotatingFileHandler
}

rectangle handlers.RotatingFileHandler {
- log_formatter : Formatter
- log_filename : String
}

rectangle Formatter {
}

rectangle Logger {
- log_handler : RotatingFileHandler
- log_level : Level
}

rectangle git.GitCommandError {
}

rectangle FileNotFoundError {
}

MainClass o- Logging
MainClass -- git.Repo
MainClass - handlers.RotatingFileHandler
MainClass o-- Formatter
MainClass o-- Logger
MainClass -- git.GitCommandError
MainClass -- FileNotFoundError

@enduml
2024-01-21 16:56:04,929 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 16:56:04,930 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 16:56:04,930 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-21 16:56:04,930 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-21 16:56:04,932 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-21 16:56:04,933 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:56:04,934 - DEBUG - send_request_headers.complete
2024-01-21 16:56:04,934 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:56:04,934 - DEBUG - send_request_body.complete
2024-01-21 16:56:04,935 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:56:08,096 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:56:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3093'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'0a75114ba1fc8a9bbde1332a1ce46906'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849325ff5e8f675e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:56:08,097 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:56:08,098 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:56:08,099 - DEBUG - receive_response_body.complete
2024-01-21 16:56:08,099 - DEBUG - response_closed.started
2024-01-21 16:56:08,100 - DEBUG - response_closed.complete
2024-01-21 16:56:08,100 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:56:08,102 - INFO - Received response from OpenAI: t.Repo.clone_from(git_repo_url, output_directory)  # Clone the git repository, specifying the output directory
    code_dir = retrieve_code(output_directory)  # Get the code directory path
    uml_content = generate_content(code_dir)  # Generate the UML content from the code directory
    with tempfile.TemporaryDirectory() as temp_dir:  # Create a temporary directory to store the generated UML files
        uml_filename = os.path.join(temp_dir, 'uml.puml')
        with open(uml_filename, 'w') as uml_file:  # Write the UML content to a .puml file
            uml_file.write(uml_content)
        subprocess.call(['plantuml', uml_filename])  # Use the PlantUML library to convert the .puml file to a UML diagram
        shutil.move(os.path.join(temp_dir, 'uml.png'), os.path.join(output_directory, 'uml.png'))  # Move the generated UML diagram to the output directory
        
 
@startuml
class uml_from_repo.py {
 - log_directory: str
 - log_filename: str
 - log_handler: handlers.RotatingFileHandler
 - log_formatter: logging.Formatter
 - logger: logging.logger

 + process_request(data): void
}

@startuml
package routes.retrieve_code {
    class clone_repo {
        __ git_repo_url: str
    }

    class retrieve_code {
        __ output_directory: str
        + retrieve_code(output_directory): str
    }
}

@startuml
package routes.code_to_uml {
    class generate_content {
        __ code_dir: str
        + generate_content(code_dir): str
    }
}

clone_repo --> retrieve_code
retrieve_code --> generate_content
generate_content --> process_request

@enduml
2024-01-21 16:56:08,102 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-21 16:56:08,104 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-21 16:56:08,105 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:56:08,106 - DEBUG - send_request_headers.complete
2024-01-21 16:56:08,106 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:56:08,106 - DEBUG - send_request_body.complete
2024-01-21 16:56:08,106 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:56:10,716 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:56:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2525'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'618c95282d02cbd1f4aa5fb133ce5c92'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493261328f3675e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:56:10,717 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:56:10,718 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:56:10,719 - DEBUG - receive_response_body.complete
2024-01-21 16:56:10,719 - DEBUG - response_closed.started
2024-01-21 16:56:10,719 - DEBUG - response_closed.complete
2024-01-21 16:56:10,720 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:56:10,721 - INFO - Received response from OpenAI: )
        
        # Generate the UML diagrams
        diagrams = generate_uml(repo, temp_dir, config)

Note: For the sake of simplicity, the following diagram only includes the relevant classes and does not include attributes, constructor methods, or other necessary methods.

@startuml

class Data
Data : gitHubAccessToken

class Logger
Logger : logger.error()
Logger : logger.info()

class Tempfile
Tempfile : tempfile.mkdtemp()

class Exception
Exception : str(e)

class Json
Json : json.load()

class UMLGenerator
UMLGenerator: generate_uml()

class Repository
Repository : clone_repo()

class Config
Config : config

class UMLDiagram
UMLDiagram : diagrams

Data --> Repository
Data --> Config
Data --> UMLGenerator
Logger --> Data
Tempfile --> Data
Exception --> Logger
Json --> Config
UMLDiagram --> Repository
UMLDiagram --> Tempfile
UMLDiagram --> Config
UMLDiagram --> UMLGenerator

@enduml 
2024-01-21 16:56:10,722 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-21 16:56:10,724 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-21 16:56:10,725 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:56:10,725 - DEBUG - send_request_headers.complete
2024-01-21 16:56:10,726 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:56:10,726 - DEBUG - send_request_body.complete
2024-01-21 16:56:10,726 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:56:10,890 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:56:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'73'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'd26620e4b6b19f8776cc3eed27747aa3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849326238836675e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:56:10,890 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:56:10,891 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:56:10,891 - DEBUG - receive_response_body.complete
2024-01-21 16:56:10,891 - DEBUG - response_closed.started
2024-01-21 16:56:10,891 - DEBUG - response_closed.complete
2024-01-21 16:56:10,891 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:56:10,892 - INFO - Received response from OpenAI: 
2024-01-21 16:56:10,892 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-21 16:56:10,893 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-21 16:56:10,893 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:56:10,893 - DEBUG - send_request_headers.complete
2024-01-21 16:56:10,893 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:56:10,893 - DEBUG - send_request_body.complete
2024-01-21 16:56:10,894 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:56:13,843 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:56:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2862'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'b8a7dcbe03b3af1c1e3746e5b38a539c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849326249996675e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:56:13,845 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:56:13,845 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:56:13,846 - DEBUG - receive_response_body.complete
2024-01-21 16:56:13,846 - DEBUG - response_closed.started
2024-01-21 16:56:13,846 - DEBUG - response_closed.complete
2024-01-21 16:56:13,847 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:56:13,848 - INFO - Received response from OpenAI:  @startuml

class t()

t(included_files, output_directory) {
  +included_files
  +output_directory
  +logger: Logger

  .. Get included files ..
  +get_included_files()

  .. Generate UML diagrams and save to output directory ..
  #generate_diagrams()

  .. Clean up temporary directory after generation ..
  +clean_up()

  .. Constructor ..
  +t(included_files, output_directory)

  .. Get final output paths ..
  +get_final_output_paths()

  .. Save UML diagram paths to log ..
  +log_output_paths()

  .. Return success message and details ..
  +return_success()

  .. Return error message and code ..
  +return_error()

}

class logger() {
  +info()
  +error()
}

class git_repo_url()

class temp_dir()

class final_output_paths()

t --> git_repo_url
t --> temp_dir
t --> final_output_paths

t --> logger
logger --> info()
logger --> error()

t +-> get_included_files()
t +-> generate_diagrams()
t +-> clean_up()
t +-> get_final_output_paths()
t +-> log_output_paths()
t +-> return_success()
t +-> return_error()

return_success() --> git_repo_url
return_success() --> final_output_paths

return_error() --> error

@enduml
2024-01-21 16:56:13,848 - INFO - UML code generated for src/routes/uml_from_repo.py: @startuml
title uml_from_repo.py
t.Repo.clone_from(git_repo_url, output_directory)  # Clone the git repository, specifying the output directory
    code_dir = retrieve_code(output_directory)  # Get the code directory path
    uml_content = generate_content(code_dir)  # Generate the UML content from the code directory
    with tempfile.TemporaryDirectory() as temp_dir:  # Create a temporary directory to store the generated UML files
        uml_filename = os.path.join(temp_dir, 'uml.puml')
        with open(uml_filename, 'w') as uml_file:  # Write the UML content to a .puml file
            uml_file.write(uml_content)
        subprocess.call(['plantuml', uml_filename])  # Use the PlantUML library to convert the .puml file to a UML diagram
        shutil.move(os.path.join(temp_dir, 'uml.png'), os.path.join(output_directory, 'uml.png'))  # Move the generated UML diagram to the output directory
        
 
@startuml
class uml_from_repo.py {
 - log_directory: str
 - log_filename: str
 - log_handler: handlers.RotatingFileHandler
 - log_formatter: logging.Formatter
 - logger: logging.logger

 + process_request(data): void
}

@startuml
package routes.retrieve_code {
    class clone_repo {
        __ git_repo_url: str
    }

    class retrieve_code {
        __ output_directory: str
        + retrieve_code(output_directory): str
    }
}

@startuml
package routes.code_to_uml {
    class generate_content {
        __ code_dir: str
        + generate_content(code_dir): str
    }
}

clone_repo --> retrieve_code
retrieve_code --> generate_content
generate_content --> process_request

@enduml
2024-01-21 16:56:13,849 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 16:56:13,849 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 16:56:13,850 - INFO - Skipping empty file: src/scripts/__init__.py
2024-01-21 16:56:13,850 - INFO - Processing file: src/scripts/execute_generate_uml.py
2024-01-21 16:56:13,850 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import json
import os
import requests
import logging
from logging import handlers
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure logging to write to a file
log_directory = '../../logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'execute_generate_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


# Configure logging
logging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))
# Configuration file path
config_file_path = os.path.join(cu
2024-01-21 16:56:13,852 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nimport json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(cu", 'max_tokens': 1024}}
2024-01-21 16:56:13,853 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:56:13,854 - DEBUG - send_request_headers.complete
2024-01-21 16:56:13,854 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:56:13,855 - DEBUG - send_request_body.complete
2024-01-21 16:56:13,855 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:56:18,314 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:56:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4391'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'93a26dc728d1ffbe5537abd72f39c738'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849326371d09675e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:56:18,315 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:56:18,315 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:56:18,316 - DEBUG - receive_response_body.complete
2024-01-21 16:56:18,317 - DEBUG - response_closed.started
2024-01-21 16:56:18,317 - DEBUG - response_closed.complete
2024-01-21 16:56:18,318 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:56:18,319 - INFO - Received response from OpenAI: urrent_dir, 'config.json')

# Open and read configuration file
with open(config_file_path, 'r') as f:
    config = json.load(f)

# Retrieve data from a specific endpoint using the API
endpoint = config['API_ENDPOINT']  # Endpoint URL from config file
headers = {'Authorization': 'Bearer ' + config['API_KEY']}  # API key from config file
params = {'param': 'value'}  # Parameters to pass to endpoint
response = requests.get(endpoint, headers=headers, params=params)

# Check for successful response
if response.status_code == 200:
    # Convert response to JSON format
    data = response.json()
    # Generate UML diagrams from API response
    # Code for UML generation
else:
    logger.error('Failed to retrieve data from API')

@startuml
left to right direction
skinparam packageStyle rectangle

' Import statements
import json
import os
import requests
import logging
import handlers   from logging
from dotenv import load_dotenv

' Load environment variables from .env file
load_dotenv()

' Create directory for log files
create os.makedirs(log_directory, exist_ok=True)

' Configure log handler
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)

' Format log messages
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

' Set log format and level
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

' Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))

' Configuration file path
config_file_path = os.path.join(current_dir, 'config.json')

' Open and read configuration file
file f = open(config_file_path, 'r')
json config = f.read()

' Retrieve data from endpoint using API
endpoint = config['API_ENDPOINT']
headers = {'Authorization': 'Bearer ' + config['API_KEY']}
params = {'param': 'value'}
request response = requests.get(endpoint, headers=headers, params=params)

' Check for successful response
if response.status_code == 200 then (true)
    ' Convert response to JSON format
    json data = response.json()
    ' UML diagram generation code
else (false)
    logger.error('Failed to retrieve data from API')
@enduml
2024-01-21 16:56:18,320 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

rrent_dir, 'config.json')

# Read configuration from the JSON file
with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

# Retrieve the GitHub access token from environment variables
github_token = os.getenv('GITHUB_PAT')

# Endpoint URL
url = 'http://127.0.0.1:5000/generate-uml'

# Headers
headers = {
    'Content-Type': 'application/json'
}

# Update the GitHub access token and local directory in the config data
config_data['gitHubAccessToken'] = github_token
config_data['local_dir'] = os.path.join(current_dir, '../..', 'output')

# Log the JSON data being sent in the request
logging.info(f'Sending JSON data to {url}:')
logging.info(json.dumps(config_data, indent=2))

try:
    # Make the POST request
    response = requests.post(url, headers=headers, json=config_data)

    # Log the response from the server
    logging.info(f'Response from server ({url}):')
    logging.info(f'Status Code: {response.status_code}')
    logging.info(f'Response Text: {response.text}')

    #
2024-01-21 16:56:18,322 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nrrent_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    #", 'max_tokens': 1024}}
2024-01-21 16:56:18,323 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:56:18,323 - DEBUG - send_request_headers.complete
2024-01-21 16:56:18,323 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:56:18,323 - DEBUG - send_request_body.complete
2024-01-21 16:56:18,323 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:56:20,881 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:56:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2445'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'1f98c31902e3229f3c4d6f69d2ae1085'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849326530d6f675e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:56:20,881 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:56:20,881 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:56:20,882 - DEBUG - receive_response_body.complete
2024-01-21 16:56:20,882 - DEBUG - response_closed.started
2024-01-21 16:56:20,882 - DEBUG - response_closed.complete
2024-01-21 16:56:20,882 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:56:20,882 - INFO - Received response from OpenAI:  Check for successful response
    if response.status_code == 200:
        # Save the UML diagram as a PNG file
        with open('uml_diagram.png', 'wb') as image_file:
            image_file.write(response.content)
except Exception as e:
    # Log any errors that occur
    logging.error(f'Error: {e}')

@startuml

class Main {
    - current_dir: str
    - config_file_path: str
    - github_token: str
    - url: str
    - headers: dict
    - config_data: dict
    + __init__(current_dir)
    # read_config()
    + __main__()
    + save_uml_diagram()
}

class Config {
    - gitHubAccessToken: str
    - local_dir: str
    + update_config(github_token, local_dir)
}

class Requests {
    - response: Response
    + post(url, headers, json_data)
}

class Response {
    - status_code: int
    - text: str
}

class Logs {
    + info(message)
    + error(message)
}

Main *-- Config
Main *-- Requests
Main *-- Logs
Config *-- Requests
Requests *-- Response
Logs <|-- Main

@enduml
2024-01-21 16:56:20,883 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

 Print the response from the server
    print(response.text)

    # Save the response to a file in the output directory
    output_dir = os.path.join(current_dir, '../..', 'output')
    os.makedirs(output_dir, exist_ok=True)
    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:
        json.dump(response.json(), output_file, indent=2)

except Exception as e:
    # Log any exceptions that occur
    logging.error(f'Error occurred: {str(e)}')
2024-01-21 16:56:20,883 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')", 'max_tokens': 1024}}
2024-01-21 16:56:20,884 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:56:20,884 - DEBUG - send_request_headers.complete
2024-01-21 16:56:20,884 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:56:20,884 - DEBUG - send_request_body.complete
2024-01-21 16:56:20,884 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:56:25,688 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:56:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4704'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'da5aaff451b3e95850ee7d3e94d9ba4e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849326631c26675e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:56:25,690 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:56:25,691 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:56:25,691 - DEBUG - receive_response_body.complete
2024-01-21 16:56:25,692 - DEBUG - response_closed.started
2024-01-21 16:56:25,692 - DEBUG - response_closed.complete
2024-01-21 16:56:25,692 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:56:25,694 - INFO - Received response from OpenAI: 

@startuml
class Request {
    +url: string
    +method: string
    +headers: map<string, string>
    +body: any
    +params: map<string, string>
    +timeout: int
    #send(): Response
}

class Response {
    -_content: bytes
    -status_code: int
    -headers: map<string, string>
    -json(): any
    -text(): str
}

class Json {
    #dump(data: any, file: file, indent: int): None
}

class Os:
    #path 
    #join(*paths: strings): str
    #makedirs(name: str, mode: int): None

class Open {
    #__init__(file: str, mode: str = 'r', buffering: int = -1, encoding: str = None, errors: str = None, newline: None, closefd: bool = True, opener: None = None): None
    #__enter__(): file
    #__exit__(exc_type, exc_value, traceback): None
}

class RequestManager {
    +make_request(request: Request): Response/Exception
}

class Exception {
    #message: str
    #code: int
    +__init__(msg: str, code: int): None
    +__str__(): str
}

class OutputManager {
    +save_json_to_file(data: any, file_path: str): None
}

class Logging {
    #log(msg: str): None
}

Request --> RequestManager
RequestManager --> Response: make_request(request)
Response --> Json:
OutputManager --> Json: save_json_to_file(data, file_path)
Os --> Os: path_join(*paths)
Os --> Os: mkdirs(name, mode)
Open --> Open:
OutputManager --> Open: save_json_to_file(data, file_path)
Exception --> Logging: __init__(msg, code)
Logging --> Logging: log(msg)
@enduml
2024-01-21 16:56:25,694 - INFO - UML code generated for src/scripts/execute_generate_uml.py: @startuml
title execute_generate_uml.py
urrent_dir, 'config.json')

# Open and read configuration file
with open(config_file_path, 'r') as f:
    config = json.load(f)

# Retrieve data from a specific endpoint using the API
endpoint = config['API_ENDPOINT']  # Endpoint URL from config file
headers = {'Authorization': 'Bearer ' + config['API_KEY']}  # API key from config file
params = {'param': 'value'}  # Parameters to pass to endpoint
response = requests.get(endpoint, headers=headers, params=params)

# Check for successful response
if response.status_code == 200:
    # Convert response to JSON format
    data = response.json()
    # Generate UML diagrams from API response
    # Code for UML generation
else:
    logger.error('Failed to retrieve data from API')

@startuml
left to right direction
skinparam packageStyle rectangle

' Import statements
import json
import os
import requests
import logging
import handlers   from logging
from dotenv import load_dotenv

' Load environment variables from .env file
load_dotenv()

' Create directory for log files
create os.makedirs(log_directory, exist_ok=True)

' Configure log handler
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)

' Format log messages
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

' Set log format and level
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

' Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))

' Configuration file path
config_file_path = os.path.join(current_dir, 'config.json')

' Open and read configuration file
file f = open(config_file_path, 'r')
json config = f.read()

' Retrieve data from endpoint using API
endpoint = config['API_ENDPOINT']
headers = {'Authorization': 'Bearer ' + config['API_KEY']}
params = {'param': 'value'}
request response = requests.get(endpoint, headers=headers, params=params)

' Check for successful response
if response.status_code == 200 then (true)
    ' Convert response to JSON format
    json data = response.json()
    ' UML diagram generation code
else (false)
    logger.error('Failed to retrieve data from API')
@enduml
2024-01-21 16:56:25,695 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 16:56:25,696 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 16:56:25,696 - INFO - Generated file paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 16:56:25,696 - INFO - Final output paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 16:56:25,697 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 16:56:25,697 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 16:56:25,697 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 16:56:25,697 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 16:56:25,697 - INFO - Cleaning up temporary directory
2024-01-21 16:56:25,879 - INFO - 127.0.0.1 - - [21/Jan/2024 16:56:25] "POST /generate-uml HTTP/1.1" 200 -
2024-01-21 16:57:16,074 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 16:57:16,075 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 16:57:16,084 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-21 16:57:16,085 - INFO - [33mPress CTRL+C to quit[0m
2024-01-21 16:57:16,085 - INFO -  * Restarting with stat
2024-01-21 16:57:16,355 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 16:57:16,356 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 16:57:16,365 - WARNING -  * Debugger is active!
2024-01-21 16:57:16,370 - INFO -  * Debugger PIN: 139-904-016
2024-01-21 16:57:20,596 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-21 16:57:20,597 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-21 16:57:20,597 - INFO - Received local_dir: ./output
2024-01-21 16:57:20,597 - INFO - Received gitHubAccessToken: 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
2024-01-21 16:57:20,598 - INFO - Cleaning up temporary directory
2024-01-21 16:57:20,598 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 16:57:20,600 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-21 16:57:20,600 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpuykxamp_'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-21 16:57:24,114 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpuykxamp_'])'s unused stdout: 
2024-01-21 16:57:24,116 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 16:57:24,116 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpuykxamp_, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 16:57:24,122 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpuykxamp_, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 16:57:24,145 - DEBUG - Type of included_files: <class 'dict'>
2024-01-21 17:02:52,761 - INFO -  * Restarting with stat
