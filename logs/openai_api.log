2024-01-21 16:57:24,145 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 16:57:24,146 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-21 16:57:24,146 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 16:57:24,147 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-21 16:57:24,147 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-21 16:57:24,147 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-21 16:57:24,149 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-21 16:57:24,161 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-21 16:57:24,259 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104d9b710>
2024-01-21 16:57:24,259 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104b99b50> server_hostname='api.openai.com' timeout=5.0
2024-01-21 16:57:24,287 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104e118d0>
2024-01-21 16:57:24,287 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:57:24,288 - DEBUG - send_request_headers.complete
2024-01-21 16:57:24,288 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:57:24,288 - DEBUG - send_request_body.complete
2024-01-21 16:57:24,288 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:57:30,796 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:57:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'6438'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'efdf7ea2a26f7455c571d8d6d03e55b5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=f7JNQ1G7vXwd9baqBkilaJvkiwONL2MLHIyxLukJSDw-1705877850-1-AWiZpkre+ShjZZEjqdJxt6NMpK+QW/ERN8W1R2Fjs5RC6qmct5jVf1hbPTWCnJiSb2PnPegyZOSDDTVAUAWsCFk=; path=/; expires=Sun, 21-Jan-24 23:27:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=yaWO_8eNRiWuvvosixb_ebTzY.9gFPmTjzAZDDxglfE-1705877850856-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849327ef5f7512e5-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:57:30,800 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:57:30,800 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:57:30,801 - DEBUG - receive_response_body.complete
2024-01-21 16:57:30,801 - DEBUG - response_closed.started
2024-01-21 16:57:30,801 - DEBUG - response_closed.complete
2024-01-21 16:57:30,802 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:57:30,805 - INFO - Received response from OpenAI: 
        if not code:
            logging.warn(f"Skipping empty file: {file_path}")
            continue
        # Skip if the file is in the output directory
        if os.path.abspath(file_path).startswith(os.path.abspath(output_directory)):
            logging.warn(f"Skipping output file: {file_path}")
            continue
        # Merge the code together
        generated_code += code + "\n"
        # Add the file path to the list
        file_paths.append(file_path)

    # Generate the content using the OpenAI API
    generated_content = api.generate(generated_code)
    logging.info(f"Generated content: {generated_content}")

    # Write the generated content to each file
    for file_path, code in zip(file_paths, generated_content.split("\n")):
        with open(file_path, 'w') as f:
            f.write(code)

# Define entrypoint
if __name__ == "__main__":
    # Specify the files to process
    files = {
        "main.py": "print('Hello from main.py')",
        "utils.py": "def multiply(x, y):\n    return x * y"
    }

    # Specify the output directory
    output_directory = "./output"

    # Generate the content using the files and output directory
    generate_content(files, output_directory)

# UML diagrams:

@startuml
class OpenAIAPI {
 - access_token : str
 + __init__(self)
 + generate(code: str) : str
}

class api {
 - api : OpenAIAPI
 + __init__(self)
 + generate_content(files: dict, output_directory: str) : None
}

class logging {
 + info(msg: str) : None
 + warn(msg: str) : None
 + setLevel(level: int) : None
}

class handlers.RotatingFileHandler {
 - filename : str
 - maxBytes : int
 - backupCount : int
 + __init__(self, filename: str, maxBytes: int, backupCount: int)
 + setFormatter(formatter: logging.Formatter) : None
}

class logging.Formatter {
 - fmt : str
 + __init__(self, fmt: str)
 + format(record: logging.LogRecord) : str
}

class logging.Logger {
 - handlers : List
 + __init__(self)
 + addHandler(handler: logging.Handler) : None
 + setLevel(level: int) : None
}

FileLogger "main.py" {
 - code : str
 + __init__(self, code: str)
 + write(code: str) : None
}

FileLogger "utils.py" {
 - code : str
 + __init__(self, code: str)
 + write(code: str) : None
}

OpenAIAPI --> api : creates
api --> logging : configure
api --> handlers.RotatingFileHandler : create
handlers.RotatingFileHandler --> logging.Formatter : format
logging --> logging.Logger : configure
logging --> FileLogger "main.py" : write code
logging --> FileLogger "utils.py" : write code
FileLogger "main.py" --> files
FileLogger "utils.py" --> files
@enduml
2024-01-21 16:57:30,806 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-21 16:57:30,808 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-21 16:57:30,809 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:57:30,809 - DEBUG - send_request_headers.complete
2024-01-21 16:57:30,809 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:57:30,810 - DEBUG - send_request_body.complete
2024-01-21 16:57:30,810 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:57:32,617 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:57:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1701'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'801b308a297076d8f7697b1c91384716'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849328180bac12e5-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:57:32,619 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:57:32,619 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:57:32,620 - DEBUG - receive_response_body.complete
2024-01-21 16:57:32,621 - DEBUG - response_closed.started
2024-01-21 16:57:32,621 - DEBUG - response_closed.complete
2024-01-21 16:57:32,622 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:57:32,623 - INFO - Received response from OpenAI: _paths}")


@startuml

class Logging {
    -message : string
    +log() : void
}

class UMLGenerator {
    -code : string
    -generated_code : string
    -file_paths : list
    -output_directory : string
    +skip_empty_file(file_path) : void
    +process_file(file_path) : void
    +generate_from_code(code) : string
    +save_generated_output(generated_code, output_path) : string
}

class Main {
    +main() : void
}

class File {
    -file_path : string
    -generated_code_for_file : string
    +get_file_path() : string
}

Main --> Logging
Main --> UMLGenerator
Main --> File
UMLGenerator o--> Logging
File --> Logging
UMLGenerator --> File
File --> UMLGenerator 

@enduml
2024-01-21 16:57:32,623 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-21 16:57:32,625 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-21 16:57:32,626 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:57:32,627 - DEBUG - send_request_headers.complete
2024-01-21 16:57:32,627 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:57:32,628 - DEBUG - send_request_body.complete
2024-01-21 16:57:32,628 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:57:35,240 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:57:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2465'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'0135281e0a0270af8dfb3cabf9b159ab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84932823688712e5-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:57:35,242 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:57:35,243 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:57:35,244 - DEBUG - receive_response_body.complete
2024-01-21 16:57:35,244 - DEBUG - response_closed.started
2024-01-21 16:57:35,245 - DEBUG - response_closed.complete
2024-01-21 16:57:35,245 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:57:35,247 - INFO - Received response from OpenAI: 

@cli.command()
@click.argument("file_path", type=click.Path(exists=True))
def count_lines(file_path):
    """Count the number of lines in a given file."""
    # Open the file
    with open(file_path) as f:
        # Read all lines and count them
        lines = f.readlines()
        num_lines = len(lines)
    # Print the result
    print(f"{file_path} has {num_lines} lines.")



PlantUML format:

package "CLI Package" #LightBlue {
    class CLI {
        - default_config
        - load_config
        + add_path
        + generate_code
    }
    class Config {
        # file_paths: list
        # generated_code: str
        + __init__(config_file)
        + get_paths()
        + get_generated_code()
    }
    class File {
        {field} - _paths: list
        {field} - _generated_code: str
        {method} + __init__(file_paths, generated_code)
        {method} + count_lines(self, file_path)
    }
    CLI "1" *-- "1" Config
    Config <|-- File
    CLI <|-- File
}

Note: This UML diagram only shows the main functions and relationships for the CLI tool. Additional classes and methods may exist for other functions not shown in the diagram.
2024-01-21 16:57:35,248 - INFO - UML code generated for src/routes/code_to_uml.py: @startuml
title code_to_uml.py
if not code:
            logging.warn(f"Skipping empty file: {file_path}")
            continue
        # Skip if the file is in the output directory
        if os.path.abspath(file_path).startswith(os.path.abspath(output_directory)):
            logging.warn(f"Skipping output file: {file_path}")
            continue
        # Merge the code together
        generated_code += code + "\n"
        # Add the file path to the list
        file_paths.append(file_path)

    # Generate the content using the OpenAI API
    generated_content = api.generate(generated_code)
    logging.info(f"Generated content: {generated_content}")

    # Write the generated content to each file
    for file_path, code in zip(file_paths, generated_content.split("\n")):
        with open(file_path, 'w') as f:
            f.write(code)

# Define entrypoint
if __name__ == "__main__":
    # Specify the files to process
    files = {
        "main.py": "print('Hello from main.py')",
        "utils.py": "def multiply(x, y):\n    return x * y"
    }

    # Specify the output directory
    output_directory = "./output"

    # Generate the content using the files and output directory
    generate_content(files, output_directory)

# UML diagrams:

@startuml
class OpenAIAPI {
 - access_token : str
 + __init__(self)
 + generate(code: str) : str
}

class api {
 - api : OpenAIAPI
 + __init__(self)
 + generate_content(files: dict, output_directory: str) : None
}

class logging {
 + info(msg: str) : None
 + warn(msg: str) : None
 + setLevel(level: int) : None
}

class handlers.RotatingFileHandler {
 - filename : str
 - maxBytes : int
 - backupCount : int
 + __init__(self, filename: str, maxBytes: int, backupCount: int)
 + setFormatter(formatter: logging.Formatter) : None
}

class logging.Formatter {
 - fmt : str
 + __init__(self, fmt: str)
 + format(record: logging.LogRecord) : str
}

class logging.Logger {
 - handlers : List
 + __init__(self)
 + addHandler(handler: logging.Handler) : None
 + setLevel(level: int) : None
}

FileLogger "main.py" {
 - code : str
 + __init__(self, code: str)
 + write(code: str) : None
}

FileLogger "utils.py" {
 - code : str
 + __init__(self, code: str)
 + write(code: str) : None
}

OpenAIAPI --> api : creates
api --> logging : configure
api --> handlers.RotatingFileHandler : create
handlers.RotatingFileHandler --> logging.Formatter : format
logging --> logging.Logger : configure
logging --> FileLogger "main.py" : write code
logging --> FileLogger "utils.py" : write code
FileLogger "main.py" --> files
FileLogger "utils.py" --> files
@enduml
2024-01-21 16:57:35,248 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 16:57:35,249 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 16:57:35,249 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-21 16:57:35,250 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-21 16:57:35,252 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-21 16:57:35,253 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:57:35,253 - DEBUG - send_request_headers.complete
2024-01-21 16:57:35,253 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:57:35,254 - DEBUG - send_request_body.complete
2024-01-21 16:57:35,254 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:57:38,613 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:57:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3268'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'fdc22b19588f3225bdb5376b4afbc815'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84932833dbcd12e5-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:57:38,614 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:57:38,615 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:57:38,615 - DEBUG - receive_response_body.complete
2024-01-21 16:57:38,616 - DEBUG - response_closed.started
2024-01-21 16:57:38,616 - DEBUG - response_closed.complete
2024-01-21 16:57:38,616 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:57:38,619 - INFO - Received response from OpenAI:  # Convert the repo to JSON format
        repo_json = json.dumps({'name': repo.remotes.origin.url, 'path': repo.working_dir, 'commit': repo.active_branch.commit.hexsha}, indent=4)
        logger.debug(f"Repository details in JSON format: {repo_json}")
        return repo_json
    except Exception as err:
        logger.error(f"Failed to clone repository: {repo_url}, Error: {err}")


def main():
    repo_url = 'https://github.com/username/repo'
    temp_dir = '/tmp/repo'
    access_token = '<access_token>'
    repo_details = clone_repo(repo_url, temp_dir, access_token)
    print(repo_details)


@startuml
left to right direction
skinparam packageStyle rectangle
actor User

rectangle "Git Importer" {
    User -> GitImporter : import repo
    GitImporter -> Git : cloneRepo(repo_url, temp_dir, access_token)
    Git -> Git : modifyURL(repo_url, access_token)
    Git -> Git : cloneRepo(repo_url, temp_dir)
    Git -> Git : getRepoDetails()
    Git -> JsonConverter : convertToJson()
    JsonConverter -> Json : dumps()
    Git -> Logger : log(repo_url)
    Logger -> Logger : configure()
    User <- GitImporter : repo_details
}

package Git {
    class Git {
        cloneRepo(repo_url, temp_dir, access_token)
        modifyURL(repo_url, access_token)
        getRepoDetails()
    }
}
package Logging {
    class Logger {
        configure()
        log()
    }
}
package Json {
    class Json {
        dumps()
    }
}
@enduml
2024-01-21 16:57:38,619 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-21 16:57:38,620 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-21 16:57:38,622 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:57:38,622 - DEBUG - send_request_headers.complete
2024-01-21 16:57:38,622 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:57:38,622 - DEBUG - send_request_body.complete
2024-01-21 16:57:38,623 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:57:43,406 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:57:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4720'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'cd44b5ed65d37806c4540cba91e80b41'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84932848edf612e5-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:57:43,407 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:57:43,407 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:57:43,408 - DEBUG - receive_response_body.complete
2024-01-21 16:57:43,408 - DEBUG - response_closed.started
2024-01-21 16:57:43,408 - DEBUG - response_closed.complete
2024-01-21 16:57:43,409 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:57:43,410 - INFO - Received response from OpenAI:  if file.path not in ignore_list and (not include_list or file.path in include_list):
                 included_files[file.path] = file.data_stream.read().decode("utf-8")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code from repository: {str(e)}")
        raise ValueError(f"Failed to retrieve code from repository: {str(e)}")

@startuml

class Main {
    - logger
    - config_file_path: string
    - ignore_list: list
    - include_list: list
    
    + retrieve_code(repo, branch_name): dict
}

class Exception

Main --> Exception : except

Main -> Console : print

note right: Diagnostic print statement

Main -> Logger : logger
Logger -->|info| Main: info

Main -> Repo: repo
Repo -->|git| Main : git
note right: fetch()
Main -> Repo : repo
Repo -->|git| Main : git
note right: checkout()

Main -> Logger : logger
Logger -->|info| Main: info

Main -> File: config.json
File --> Main : r

Main -> JSON : json
JSON --> Main : r

Main -> Config : config
Config --> Main : r

Main --> Config : get

note right: ignore_list = config.get('ignore', [])

Main --> Config : get

note right: include_list = config.get('include', [])

Main -> Dictionary : included_files
Dictionary --> Main : r

Main -> Repo : repo
Repo --> Main : repo

note right: file in repo.tree()
Main --> File : file : Path

note right: file.path not in ignore_list

Main --> Include_List : include_list : boolean

note right: not include_list or file.path in include_list

File --> Dictionary : file.path
Dictionary --> File : included_files

Dictionary -> File : file.data_stream.read()
File --> Dictionary : data

Dictionary -> String : file.path : string
String --> Dictionary : file.path

note right: decode("utf-8")

Main --> Dictionary : r

Main --> Exception : except

Main --> Logger : logger
Logger -->|error| Main: error

Exception --> Main : r
Logger -->|error| Exception: error

note right: str(e)

} @enduml
2024-01-21 16:57:43,411 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-21 16:57:43,412 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-21 16:57:43,413 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:57:43,414 - DEBUG - send_request_headers.complete
2024-01-21 16:57:43,414 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:57:43,414 - DEBUG - send_request_body.complete
2024-01-21 16:57:43,415 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:57:45,305 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:57:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1786'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'722f836f1df54b1a6bf9bb742fbe0a5c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84932866dc4612e5-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:57:45,306 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:57:45,307 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:57:45,308 - DEBUG - receive_response_body.complete
2024-01-21 16:57:45,309 - DEBUG - response_closed.started
2024-01-21 16:57:45,309 - DEBUG - response_closed.complete
2024-01-21 16:57:45,309 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:57:45,311 - INFO - Received response from OpenAI: 

@startuml

class CodeRetriever {
    - include_list: String[]
    - ignore_list: String[]
    - file: File
    - included_files: HashMap<String, String>
    
    + included_files: HashMap<String, String>
    + CodeRetriever(include_list: String[], ignore_list: String[])
    + retrieve_code(): HashMap<String, String>
}

class File {
    - path: String
    - abspath: String
    
    + File(path: String, abspath: String)
    + endswith(ext: String): boolean
}

class Logger {
    - logger: Object
    
    + info(message: String)
    + warning(message: String)
    + error(message: String)
}

class FileNotFoundError {
    - message: String
}

CodeRetriever --> File
CodeRetriever --> Logger
CodeRetriever --> FileNotFoundError

@enduml 
2024-01-21 16:57:45,311 - INFO - UML code generated for src/routes/retrieve_code.py: @startuml
title retrieve_code.py
# Convert the repo to JSON format
        repo_json = json.dumps({'name': repo.remotes.origin.url, 'path': repo.working_dir, 'commit': repo.active_branch.commit.hexsha}, indent=4)
        logger.debug(f"Repository details in JSON format: {repo_json}")
        return repo_json
    except Exception as err:
        logger.error(f"Failed to clone repository: {repo_url}, Error: {err}")


def main():
    repo_url = 'https://github.com/username/repo'
    temp_dir = '/tmp/repo'
    access_token = '<access_token>'
    repo_details = clone_repo(repo_url, temp_dir, access_token)
    print(repo_details)


@startuml
left to right direction
skinparam packageStyle rectangle
actor User

rectangle "Git Importer" {
    User -> GitImporter : import repo
    GitImporter -> Git : cloneRepo(repo_url, temp_dir, access_token)
    Git -> Git : modifyURL(repo_url, access_token)
    Git -> Git : cloneRepo(repo_url, temp_dir)
    Git -> Git : getRepoDetails()
    Git -> JsonConverter : convertToJson()
    JsonConverter -> Json : dumps()
    Git -> Logger : log(repo_url)
    Logger -> Logger : configure()
    User <- GitImporter : repo_details
}

package Git {
    class Git {
        cloneRepo(repo_url, temp_dir, access_token)
        modifyURL(repo_url, access_token)
        getRepoDetails()
    }
}
package Logging {
    class Logger {
        configure()
        log()
    }
}
package Json {
    class Json {
        dumps()
    }
}
@enduml
2024-01-21 16:57:45,311 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 16:57:45,312 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 16:57:45,313 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-21 16:57:45,313 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-21 16:57:45,315 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-21 16:57:45,316 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:57:45,316 - DEBUG - send_request_headers.complete
2024-01-21 16:57:45,317 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:57:45,317 - DEBUG - send_request_body.complete
2024-01-21 16:57:45,317 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:57:45,442 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:57:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'42'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'31be84c49c992bf3a7f8d940ba05996c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84932872cb8312e5-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:57:45,442 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:57:45,442 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:57:45,443 - DEBUG - receive_response_body.complete
2024-01-21 16:57:45,443 - DEBUG - response_closed.started
2024-01-21 16:57:45,443 - DEBUG - response_closed.complete
2024-01-21 16:57:45,443 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:57:45,444 - INFO - Received response from OpenAI: 
2024-01-21 16:57:45,444 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-21 16:57:45,445 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-21 16:57:45,446 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:57:45,446 - DEBUG - send_request_headers.complete
2024-01-21 16:57:45,446 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:57:45,446 - DEBUG - send_request_body.complete
2024-01-21 16:57:45,446 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:57:49,491 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:57:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3970'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'7fc34883fe1c9826aae5b4a03be972f5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84932873ac6f12e5-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:57:49,493 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:57:49,493 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:57:49,494 - DEBUG - receive_response_body.complete
2024-01-21 16:57:49,495 - DEBUG - response_closed.started
2024-01-21 16:57:49,495 - DEBUG - response_closed.complete
2024-01-21 16:57:49,495 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:57:49,497 - INFO - Received response from OpenAI: )
            
        # Generate UML diagrams
        uml_generator = UMLGenerator(repo, config)
        uml_generator.generate(output_directory)

@startuml

class Data {
    - githubAccessToken: string
    - branchName: string

    + getData(key: string): string
}

class Logger {
    + error(message: string)
    + info(message: string)
}

class TempFile {
    - tempDir: string

    + createTempFile(): string
    + removeTempFile(tempDir: string)
}

class Config {
    - config: json

    + getConfig(file: string): json
}

class UMLGenerator {
    - repo: Repository
    - config: Config
    - outputDirectory: string

    + generateUMLoutput()
}

class Repository {
    - gitRepoUrl: string
    - githubAccessToken: string
    - branchName: string

    + cloneRepo(gitRepoUrl: string, tempDir: string, githubAccessToken: string)
}

Data --> Logger
TempFile --> Logger
Config --> Logger
UMLGenerator --> Logger

UMLGenerator --> Repository
UMLGenerator --> Config
UMLGenerator --> TempFile

Repository --> Data

Data --> UMLGenerator : getGitHubAccessToken()
Data --> UMLGenerator : getBranchName()

UMLGenerator --> Logger : error()
UMLGenerator --> TempFile : createTempFile()
UMLGenerator --> TempFile : removeTempFile()

UMLGenerator --> Repository : cloneRepo()
UMLGenerator --> Config : getConfig()

UMLGenerator --> UMLGenerator : generateUMLoutput()

@enduml
2024-01-21 16:57:49,497 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-21 16:57:49,499 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-21 16:57:49,500 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:57:49,501 - DEBUG - send_request_headers.complete
2024-01-21 16:57:49,501 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:57:49,502 - DEBUG - send_request_body.complete
2024-01-21 16:57:49,502 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:57:49,641 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:57:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'78'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'5fd8fbd592180aa54fc33c7315b3bfb8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493288cec0112e5-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:57:49,642 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:57:49,643 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:57:49,643 - DEBUG - receive_response_body.complete
2024-01-21 16:57:49,643 - DEBUG - response_closed.started
2024-01-21 16:57:49,643 - DEBUG - response_closed.complete
2024-01-21 16:57:49,644 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:57:49,645 - INFO - Received response from OpenAI: ts
2024-01-21 16:57:49,645 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-21 16:57:49,647 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-21 16:57:49,648 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:57:49,648 - DEBUG - send_request_headers.complete
2024-01-21 16:57:49,648 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:57:49,649 - DEBUG - send_request_body.complete
2024-01-21 16:57:49,649 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:57:51,492 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:57:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1668'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'3e910b9f160abec3c7918c62781fcbe5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493288dcced12e5-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:57:51,494 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:57:51,495 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:57:51,495 - DEBUG - receive_response_body.complete
2024-01-21 16:57:51,496 - DEBUG - response_closed.started
2024-01-21 16:57:51,496 - DEBUG - response_closed.complete
2024-01-21 16:57:51,497 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:57:51,498 - INFO - Received response from OpenAI:  ---------- Class: t  ----------

    t
    +included_files: List
    +output_directory: string
    ----------------
    +log_output()
    +generate_uml(): dict

  ---------- t.generate_uml()  ----------

        t.generate_uml()
    --------------------
    +included_files: List
    +output_directory: string
    ----------------
    +generate_uml(): dict

  ---------- t.log_output()  ----------

        t.log_output()
    --------------------
    +included_files: List
    +output_directory: string
    ----------------
    +log_output()

---------- Class: logger ----------

    logger
    ----------------
    -log_level: int
    ----------------
    +info(message: String)
    +error(message: String)
    ----------------
2024-01-21 16:57:51,499 - INFO - UML code generated for src/routes/uml_from_repo.py: @startuml
title uml_from_repo.py

@enduml
2024-01-21 16:57:51,499 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 16:57:51,499 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 16:57:51,500 - INFO - Skipping empty file: src/scripts/__init__.py
2024-01-21 16:57:51,500 - INFO - Processing file: src/scripts/execute_generate_uml.py
2024-01-21 16:57:51,500 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import json
import os
import requests
import logging
from logging import handlers
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure logging to write to a file
log_directory = '../../logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'execute_generate_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


# Configure logging
logging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))
# Configuration file path
config_file_path = os.path.join(cu
2024-01-21 16:57:51,502 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nimport json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(cu", 'max_tokens': 1024}}
2024-01-21 16:57:51,503 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:57:51,504 - DEBUG - send_request_headers.complete
2024-01-21 16:57:51,504 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:57:51,504 - DEBUG - send_request_body.complete
2024-01-21 16:57:51,505 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:57:55,799 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:57:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4187'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'5ce27ee356edaf1664a82935120dce14'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849328998a3a12e5-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:57:55,800 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:57:55,800 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:57:55,800 - DEBUG - receive_response_body.complete
2024-01-21 16:57:55,800 - DEBUG - response_closed.started
2024-01-21 16:57:55,800 - DEBUG - response_closed.complete
2024-01-21 16:57:55,801 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:57:55,802 - INFO - Received response from OpenAI: rrent_dir, 'config.json')




 @startuml

class imports
-json
-os
-requests
-logging
+handlers
from dotenv
+load_dotenv

rectangle "Environment Variables" #yellow

rectangle "Logging Configuration" #yellow
-log_directory
-log_filename
-log_handler
+RotatingFileHandler
-log_formatter
+Formatter
-logger
+basicConfig

rectangle "Current Directory" #yellow

rectangle "Configuration File" #yellow
-config_file_path

imports .up.|> json
imports .up.|> os
imports .up.|> requests
imports .up.|> logging

handlers ..o-left. handlers : implements
handlers .up.|> handlers : import

load_dotenv .up.|> dotenv
logging ..o-left. logging : implements

farm "Execute Generate UML" [[#red]] {

.

  if <b>os.path.exists(current_dir)</b> then
    -->[yes] Load environment variables from .env file
    -->[yes] Create log directory
    -->[yes] Initialize log file handlers
    -->[yes] Configure log formatter
    -->[yes] Set logging level
    -->[yes] Load configuration file
    -->[yes] Generate UML diagram
    --> Finalize logging
    ->[yes] Display success message
  else
    -->[no] Display error message "Directory does not exist"
  endif
}

constants

if log_directory > 0 then
  log_directory = 0
endif

if log_filename > 0 then
  log_filename = 0
endif

if config_file_path > 0 then
  config_file_path = 0
endif

@enduml
2024-01-21 16:57:55,802 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

rrent_dir, 'config.json')

# Read configuration from the JSON file
with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

# Retrieve the GitHub access token from environment variables
github_token = os.getenv('GITHUB_PAT')

# Endpoint URL
url = 'http://127.0.0.1:5000/generate-uml'

# Headers
headers = {
    'Content-Type': 'application/json'
}

# Update the GitHub access token and local directory in the config data
config_data['gitHubAccessToken'] = github_token
config_data['local_dir'] = os.path.join(current_dir, '../..', 'output')

# Log the JSON data being sent in the request
logging.info(f'Sending JSON data to {url}:')
logging.info(json.dumps(config_data, indent=2))

try:
    # Make the POST request
    response = requests.post(url, headers=headers, json=config_data)

    # Log the response from the server
    logging.info(f'Response from server ({url}):')
    logging.info(f'Status Code: {response.status_code}')
    logging.info(f'Response Text: {response.text}')

    #
2024-01-21 16:57:55,803 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nrrent_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    #", 'max_tokens': 1024}}
2024-01-21 16:57:55,804 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:57:55,804 - DEBUG - send_request_headers.complete
2024-01-21 16:57:55,804 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:57:55,805 - DEBUG - send_request_body.complete
2024-01-21 16:57:55,805 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:57:59,153 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:57:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3274'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'0eb6e5fcaf3ea92584b8020e556ba080'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849328b44af312e5-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:57:59,155 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:57:59,156 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:57:59,157 - DEBUG - receive_response_body.complete
2024-01-21 16:57:59,158 - DEBUG - response_closed.started
2024-01-21 16:57:59,158 - DEBUG - response_closed.complete
2024-01-21 16:57:59,158 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:57:59,160 - INFO - Received response from OpenAI:  Check if the request was successful
    if response.status_code == 200:
        logging.info('UML diagrams successfully generated!')
    else:
        logging.error('UML diagrams failed to generate.')
        
PlantUML: 
@startuml
class Configuration {
  - config_file_path: String
  - current_dir: String
  - github_token: String
  + config_data: String
  + url: String
  + headers: JSON
  + logging: Logger
  + response: Response
  + status_code: Integer
  + text: String
  + generateUML()
  + logData()
}

class JSON {
  - config_file_path: String
  + config_data: String
  + load()
}

class Environment {
  + github_token: String
}

class GitHub {
  + endpoint: URL
  + access_token: Environment.github_token
}

class Request {
  - url: String
  + headers: JSON
  + config_data: JSON.config_data
  + status_code: Integer
  + text: String
  + makePostRequest()
}

class Response {
  + status_code: Integer
  + text: String
}

class Logger {
  - logging: Libary
  + info()
  + error()
}

JSON "1" *-- "1" Configuration
Environment "1" *-- "1" Configuration
Response "1" *-- "1" Request
GitHub "1" *-- "1" Request
Configuration "1" *-- "1" Request
Configuration "1" *-- "1" Logger
@enduml
2024-01-21 16:57:59,160 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

 Print the response from the server
    print(response.text)

    # Save the response to a file in the output directory
    output_dir = os.path.join(current_dir, '../..', 'output')
    os.makedirs(output_dir, exist_ok=True)
    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:
        json.dump(response.json(), output_file, indent=2)

except Exception as e:
    # Log any exceptions that occur
    logging.error(f'Error occurred: {str(e)}')
2024-01-21 16:57:59,162 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')", 'max_tokens': 1024}}
2024-01-21 16:57:59,163 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 16:57:59,163 - DEBUG - send_request_headers.complete
2024-01-21 16:57:59,164 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 16:57:59,164 - DEBUG - send_request_body.complete
2024-01-21 16:57:59,164 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 16:58:00,745 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 22:58:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1524'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'1efee81f9feee16cac8a577e0b6fdcc6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849328c94be512e5-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 16:58:00,746 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 16:58:00,748 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 16:58:00,749 - DEBUG - receive_response_body.complete
2024-01-21 16:58:00,749 - DEBUG - response_closed.started
2024-01-21 16:58:00,749 - DEBUG - response_closed.complete
2024-01-21 16:58:00,749 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 16:58:00,751 - INFO - Received response from OpenAI: 

@startuml

class Server {
 - _text: String
 + getResponse(): String
}

class Response {}

class File {
 - _name: String
 + open(): void
}

class OutputDirectory {
 - _path: String
 + createDirectory(): void
}

class OutputFile {
 - _data: JSON
 + writeData(): void
}

class Exception {}

class Logging {
 + logError(): void
}

class Client {
 + print(response: Response): void
 + saveResponse(response: Response, output: OutputDirectory, file: OutputFile): void
}

Client --> Server
Client --> Response
Client --> File
Client --> OutputDirectory
Client --> OutputFile

Server <--  Response: getResponse()
File <-- OutputDirectory: open()
OutputFile <-- Response: writeData()
Exception <-- Client: saveResponse()
Logging <-- Exception: logError()

@enduml
2024-01-21 16:58:00,751 - INFO - UML code generated for src/scripts/execute_generate_uml.py: @startuml
title execute_generate_uml.py
rrent_dir, 'config.json')




 @startuml

class imports
-json
-os
-requests
-logging
+handlers
from dotenv
+load_dotenv

rectangle "Environment Variables" #yellow

rectangle "Logging Configuration" #yellow
-log_directory
-log_filename
-log_handler
+RotatingFileHandler
-log_formatter
+Formatter
-logger
+basicConfig

rectangle "Current Directory" #yellow

rectangle "Configuration File" #yellow
-config_file_path

imports .up.|> json
imports .up.|> os
imports .up.|> requests
imports .up.|> logging

handlers ..o-left. handlers : implements
handlers .up.|> handlers : import

load_dotenv .up.|> dotenv
logging ..o-left. logging : implements

farm "Execute Generate UML" [[#red]] {

.

  if <b>os.path.exists(current_dir)</b> then
    -->[yes] Load environment variables from .env file
    -->[yes] Create log directory
    -->[yes] Initialize log file handlers
    -->[yes] Configure log formatter
    -->[yes] Set logging level
    -->[yes] Load configuration file
    -->[yes] Generate UML diagram
    --> Finalize logging
    ->[yes] Display success message
  else
    -->[no] Display error message "Directory does not exist"
  endif
}

constants

if log_directory > 0 then
  log_directory = 0
endif

if log_filename > 0 then
  log_filename = 0
endif

if config_file_path > 0 then
  config_file_path = 0
endif

@enduml
2024-01-21 16:58:00,751 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 16:58:00,752 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 16:58:00,752 - INFO - Generated file paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 16:58:00,753 - INFO - Final output paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 16:58:00,753 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 16:58:00,753 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 16:58:00,753 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 16:58:00,754 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 16:58:00,754 - INFO - Cleaning up temporary directory
2024-01-21 16:58:00,942 - INFO - 127.0.0.1 - - [21/Jan/2024 16:58:00] "POST /generate-uml HTTP/1.1" 200 -
2024-01-21 17:02:52,705 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/openai_api.py', reloading
2024-01-21 17:02:53,058 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 17:02:53,059 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 17:02:53,068 - WARNING -  * Debugger is active!
2024-01-21 17:02:53,075 - INFO -  * Debugger PIN: 139-904-016
2024-01-21 17:03:10,216 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 17:03:10,217 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 17:03:10,228 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-21 17:03:10,228 - INFO - [33mPress CTRL+C to quit[0m
2024-01-21 17:03:10,229 - INFO -  * Restarting with stat
2024-01-21 17:03:10,487 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 17:03:10,488 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 17:03:10,496 - WARNING -  * Debugger is active!
2024-01-21 17:03:10,501 - INFO -  * Debugger PIN: 139-904-016
2024-01-21 17:03:13,579 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-21 17:03:13,579 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-21 17:03:13,579 - INFO - Received local_dir: ./output
2024-01-21 17:03:13,579 - INFO - Received gitHubAccessToken: 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
2024-01-21 17:03:13,580 - INFO - Cleaning up temporary directory
2024-01-21 17:03:13,580 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 17:03:13,583 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-21 17:03:13,583 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp1c7syjzt'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-21 17:03:18,635 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp1c7syjzt'])'s unused stdout: 
2024-01-21 17:03:18,637 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 17:03:18,637 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp1c7syjzt, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 17:03:18,643 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp1c7syjzt, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 17:03:18,670 - DEBUG - Type of included_files: <class 'dict'>
2024-01-21 17:03:18,670 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 17:03:18,671 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-21 17:03:18,671 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 17:03:18,671 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-21 17:03:18,671 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-21 17:03:18,671 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-21 17:03:18,672 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-21 17:03:18,687 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-21 17:03:18,767 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10988aad0>
2024-01-21 17:03:18,767 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105499b50> server_hostname='api.openai.com' timeout=5.0
2024-01-21 17:03:18,794 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1098886d0>
2024-01-21 17:03:18,794 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:03:18,794 - DEBUG - send_request_headers.complete
2024-01-21 17:03:18,794 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:03:18,794 - DEBUG - send_request_body.complete
2024-01-21 17:03:18,795 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:03:24,695 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:03:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5806'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'2cf26f202cf2ced370874f0169fb0f44'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ykz7GqsdSwjHaZuAZgjtIsBDtn0x1gP4JmeuqSJHgro-1705878204-1-Af/KOWqUc3kWDwtiqDXOm9m42C1Mu+nAg9dksaRzg/UFzOJfsT6MlFnrNPYxr2XLLNp678tEPg79O9pUI9BbQ0g=; path=/; expires=Sun, 21-Jan-24 23:33:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=AmzWVf4MdwJLVikGQsj1RaT4PeevhtAmdC5FhHNck3Y-1705878204753-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933096fa472434-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:03:24,698 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:03:24,698 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:03:24,699 - DEBUG - receive_response_body.complete
2024-01-21 17:03:24,699 - DEBUG - response_closed.started
2024-01-21 17:03:24,700 - DEBUG - response_closed.complete
2024-01-21 17:03:24,700 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:03:24,703 - INFO - Received response from OpenAI: 
        if not code:
            continue
        file_paths.append(file_path)  # Add file path to list
        generated_code += api.generate_code(code)  # Call OpenAI API to generate code based on input code
    # Write generated code to a file in the output directory
    with open(os.path.join(output_directory, 'generated_code.py'), 'w') as f:
        f.write(generated_code)
    logging.debug("Generated code written to file")  # Log debug message
    return file_paths 

```

@startuml
class OpenAIAPI
class logging
class handlers
class RotatingFileHandler
class Formatter
class os

class code_to_uml {
    - api: OpenAIAPI
    - log_directory: string
    - log_filename: string
    - log_handler: RotatingFileHandler
    - log_formatter: Formatter
    - logger: logging
    + generate_content(files, output_directory): list
}

code_to_uml --> OpenAIAPI
code_to_uml --> logging
code_to_uml --> handlers
code_to_uml --> Formatter
code_to_uml --> os
code_to_uml --> RotatingFileHandler

OpenAIAPI --> logging
logging --> handlers
handlers --> RotatingFileHandler
handlers --> Formatter

code_to_uml --> "log_directory"
code_to_uml --> "log_filename"
code_to_uml --> "log_handler"
code_to_uml --> "log_formatter"
code_to_uml --> "logger"

code_to_uml : +generate_content(files, output_directory)
OpenAIAPI : +generate_code(code)
code_to_uml : -generated_code : string
code_to_uml : generate_content(files, output_directory): list

files : dictionary
file_path : string
code : string

output_directory : string
generated_code : string
logger : logging

generate_content(files, output_directory) --> "log_directory"
generate_content(files, output_directory) --> "log_filename"
generate_content(files, output_directory) --> "log_handler"
generate_content(files, output_directory) --> "log_formatter"

files --> "file_path"
files --> "code"

file_path --> generate_content(files, output_directory)
code --> generate_content(files, output_directory)

"generated_code" --> "output_directory" : write to file

@enduml 
2024-01-21 17:03:24,704 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-21 17:03:24,706 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-21 17:03:24,707 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:03:24,708 - DEBUG - send_request_headers.complete
2024-01-21 17:03:24,708 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:03:24,708 - DEBUG - send_request_body.complete
2024-01-21 17:03:24,708 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:03:28,712 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:03:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3905'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'e5126981acb1d742d62cd552e98645fb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849330bbefd52434-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:03:28,714 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:03:28,715 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:03:28,717 - DEBUG - receive_response_body.complete
2024-01-21 17:03:28,717 - DEBUG - response_closed.started
2024-01-21 17:03:28,717 - DEBUG - response_closed.complete
2024-01-21 17:03:28,718 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:03:28,720 - INFO - Received response from OpenAI: _paths})

@startuml

class Main {
    - file_path: string
    - code: string
    - generated_code: string
    - generated_code_for_file: string
    - final_output_path: string
    - file_paths: list
    - output_directory: string
    - api: API
    - logging: Logging
    + process_file(file_path: string)
}

class API {
    - save_generated_output(generated_code_for_file: string, output_path: string): string
    + generate_from_code(code: string): string
}

class Logging {
    - log(message: string)
    + info(message: string)
    + error(message: string)
}

Main -- Logging
Main -- API
Main -- generated_code
Main -- generated_code_for_file
Main -- file_paths
Main -- file_path
Main -- code

Main: process_file()
if-not-code-true
Logging: info()
continue
Logging: info()
API: generate_from_code()
Logging: info()
if-not-generated-code
Logging: error()
raise-value-error
generated_code += generated_code_for_file
Main: process_file()
Logging: info()
file_name = os.path.basename(file_path) + .puml
final_output_path = API: save_generated_output()
file_paths.append()
Logging: info()
Main: process_file()
Logging: info()
file_name = os.path.basename(file_path) + .puml
final_output_path = API: save_generated_output()
file_paths.append()
Logging: info()
Main -> Logging: Generated file paths: file_paths
2024-01-21 17:03:28,720 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-21 17:03:28,722 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-21 17:03:28,724 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:03:28,725 - DEBUG - send_request_headers.complete
2024-01-21 17:03:28,725 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:03:28,725 - DEBUG - send_request_body.complete
2024-01-21 17:03:28,725 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:03:31,070 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:03:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2276'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'6d47376170922e9c6732338ac6c2c42c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849330d50e6f2434-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:03:31,072 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:03:31,073 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:03:31,073 - DEBUG - receive_response_body.complete
2024-01-21 17:03:31,074 - DEBUG - response_closed.started
2024-01-21 17:03:31,074 - DEBUG - response_closed.complete
2024-01-21 17:03:31,075 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:03:31,077 - INFO - Received response from OpenAI: 
}

@enduml
```

@startuml
class Generator {
    + file_paths: list
    + generated_code: string

    + Generator()
    + add_file_path(path: string)
    + generate_code()
}

Generator --*_paths

class CodeGenerator {
    + generate(generated_code)
}

Generator <-- CodeGenerator

class InputParser {
    + file_names: list
    + file_types: list

    + InputParser()
    + parse_input(paths: string)
}

Generator ..> InputParser

class FileListGenerator {
    + file_names: list
    + file_paths: list

    + FileListGenerator()
    + generate_file_paths()
}

Generator ..> FileListGenerator

class CodeWriter {
    + file_paths: list
    + code_snippets: list

    + CodeWriter()
    + write_code(file_paths, code_snippets)
}

Generator ..> CodeWriter

class utils {
    + get_file_names(path: string)
    + get_file_type(path: string)

    utils ..> FileListGenerator
}

class main {
    + main()
}

main ..> Generator
@enduml
2024-01-21 17:03:31,077 - INFO - UML code generated for src/routes/code_to_uml.py: @startuml
title code_to_uml.py
if not code:
            continue
        file_paths.append(file_path)  # Add file path to list
        generated_code += api.generate_code(code)  # Call OpenAI API to generate code based on input code
    # Write generated code to a file in the output directory
    with open(os.path.join(output_directory, 'generated_code.py'), 'w') as f:
        f.write(generated_code)
    logging.debug("Generated code written to file")  # Log debug message
    return file_paths 

```

@startuml
class OpenAIAPI
class logging
class handlers
class RotatingFileHandler
class Formatter
class os

class code_to_uml {
    - api: OpenAIAPI
    - log_directory: string
    - log_filename: string
    - log_handler: RotatingFileHandler
    - log_formatter: Formatter
    - logger: logging
    + generate_content(files, output_directory): list
}

code_to_uml --> OpenAIAPI
code_to_uml --> logging
code_to_uml --> handlers
code_to_uml --> Formatter
code_to_uml --> os
code_to_uml --> RotatingFileHandler

OpenAIAPI --> logging
logging --> handlers
handlers --> RotatingFileHandler
handlers --> Formatter

code_to_uml --> "log_directory"
code_to_uml --> "log_filename"
code_to_uml --> "log_handler"
code_to_uml --> "log_formatter"
code_to_uml --> "logger"

code_to_uml : +generate_content(files, output_directory)
OpenAIAPI : +generate_code(code)
code_to_uml : -generated_code : string
code_to_uml : generate_content(files, output_directory): list

files : dictionary
file_path : string
code : string

output_directory : string
generated_code : string
logger : logging

generate_content(files, output_directory) --> "log_directory"
generate_content(files, output_directory) --> "log_filename"
generate_content(files, output_directory) --> "log_handler"
generate_content(files, output_directory) --> "log_formatter"

files --> "file_path"
files --> "code"

file_path --> generate_content(files, output_directory)
code --> generate_content(files, output_directory)

"generated_code" --> "output_directory" : write to file

@enduml_paths})

@startuml

class Main {
    - file_path: string
    - code: string
    - generated_code: string
    - generated_code_for_file: string
    - final_output_path: string
    - file_paths: list
    - output_directory: string
    - api: API
    - logging: Logging
    + process_file(file_path: string)
}

class API {
    - save_generated_output(generated_code_for_file: string, output_path: string): string
    + generate_from_code(code: string): string
}

class Logging {
    - log(message: string)
    + info(message: string)
    + error(message: string)
}

Main -- Logging
Main -- API
Main -- generated_code
Main -- generated_code_for_file
Main -- file_paths
Main -- file_path
Main -- code

Main: process_file()
if-not-code-true
Logging: info()
continue
Logging: info()
API: generate_from_code()
Logging: info()
if-not-generated-code
Logging: error()
raise-value-error
generated_code += generated_code_for_file
Main: process_file()
Logging: info()
file_name = os.path.basename(file_path) + .puml
final_output_path = API: save_generated_output()
file_paths.append()
Logging: info()
Main: process_file()
Logging: info()
file_name = os.path.basename(file_path) + .puml
final_output_path = API: save_generated_output()
file_paths.append()
Logging: info()
Main -> Logging: Generated file paths: file_paths}

@enduml
2024-01-21 17:03:31,077 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:03:31,078 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:03:31,079 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-21 17:03:31,079 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-21 17:03:31,081 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-21 17:03:31,083 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:03:31,083 - DEBUG - send_request_headers.complete
2024-01-21 17:03:31,083 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:03:31,084 - DEBUG - send_request_body.complete
2024-01-21 17:03:31,084 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:03:39,972 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:03:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'8777'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'e88aec97ddfa91dc31e3e44310085e96'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849330e3c8132434-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:03:39,974 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:03:39,975 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:03:39,976 - DEBUG - receive_response_body.complete
2024-01-21 17:03:39,976 - DEBUG - response_closed.started
2024-01-21 17:03:39,977 - DEBUG - response_closed.complete
2024-01-21 17:03:39,977 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:03:39,980 - INFO - Received response from OpenAI: 
        # Get the latest commit for the repository
        commits = list(repo.iter_commits())
        latest_commit = commits[0]
        logger.info(f"Latest commit for repository {repo_url}: {latest_commit}")
        return latest_commit
    except git.exc.GitCommandError as e:
        logger.error(f"Error cloning repository: {repo_url}: {e}")
        return None


def get_commit_info(commit):
    # Get the commit message and author
    message = commit.message
    author = commit.author.name
    # Get the changed files
    files = commit.stats.files
    changed_files = [f"{change_type} - {file_name}" for file_name, change_type in files.items()]
    return message, author, changed_files


def main():
    # Read config file
    with open('config.json') as f:
        config = json.load(f)
    
    # Clone the specified repository
    latest_commit = clone_repo(config['repo_url'], config['temp_dir'], config['access_token'])
    
    # If cloning was successful, get the commit info
    if latest_commit:
        message, author, changed_files = get_commit_info(latest_commit)
        logger.info(f"Commit message: {message}")
        logger.info(f"Committer: {author}")
        for file in changed_files:
            logger.info(f"Changed file: {file}")


@startuml

Class git

Class json

Class os

Class logging {
+handlers: logging.handlers
+formatter: logging.formatter
"logger": logging.logger
}

Class handlers

Class file_logging {
-"log_directory": string
-"log_filename": string
-"log_handler": RotatingFileHandler
-log_formatter: string
-log_level: int
+"set_level(level)": void
-"get_level()": int
+"add_handler(handler)": void
+"remove_handler(handler)": void
-"set_formatter(formatter)": void
+"set_filename(filename)": void
+"flush()": void
+"close()": void
+"handle(record)": void
+"emit(record)": void
+"format(record": void
+"handleError(record)": void 
}

Class repo {
-temp_dir: string
-access_token: string
-repo_url: string
+clone_repo(repo_url, temp_dir, access_token): latest_commit
#"get_latest_commit(repo)": latest_commit
-"get_commit_info(commit)": message, author, changed_files 
+"set_repo_url(repo_url)": void
+"get_repo_url()": string
+"set_temp_dir(temp_dir)": void
+"get_temp_dir()": string
+"set_access_token(access_token)": void 
+"get_access_token()": string
}

Class latest_commit {
-"commits": list
-"latest_commit": current_commit
+"get_latest_commit(repo)": current_commit
#"set_commits(commit)" 
}

git <|-- repo
json <|-- repo
os <|-- file_logging
repo "1" *-- "1" handlers
handlers <|-- file_logging 
logging -- handlers 
handlers <|-- logging
Class handlers <<(S,#FFAAAA)>> 
Class logging <<(F,Yellow)>> 
Class git <<(C,#FFAAAA)>> 
Class os <<(R,#FFAAAA)>> 
Class file_logging <<(R,LightBlue)>> 
Class json <<(F,Lime)>> 
Class repo <<(F,#FFAAAA)>> 
Class latest_commit <<(C,#FFAAAA)>>

main() -> logging: set_level
logging -> handlers : add_handler
handlers -> file_logging: set_filename
file_logging -> repo: set_temp_dir
repo -> git: clone_repo
repo -> json: load_config
git -> logging: log [success]
handlers --> logging: record
logging -- main: success

@enduml
2024-01-21 17:03:39,981 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-21 17:03:39,983 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-21 17:03:39,985 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:03:39,985 - DEBUG - send_request_headers.complete
2024-01-21 17:03:39,985 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:03:39,985 - DEBUG - send_request_body.complete
2024-01-21 17:03:39,986 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:03:46,289 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:03:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'6173'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'0a534d7615c388657e0e2288c21fe249'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493311baf582434-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:03:46,291 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:03:46,291 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:03:46,292 - DEBUG - receive_response_body.complete
2024-01-21 17:03:46,292 - DEBUG - response_closed.started
2024-01-21 17:03:46,292 - DEBUG - response_closed.complete
2024-01-21 17:03:46,293 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:03:46,295 - INFO - Received response from OpenAI:  # Check if file path matches any patterns in include list
            if any(fnmatch.fnmatch(file.path, pattern) for pattern in include_list):
                # Check if file path matches any patterns in ignore list, if not add it to the included files dictionary
                if not any(fnmatch.fnmatch(file.path, pattern) for pattern in ignore_list):
                    included_files[file.path] = file.data_stream.read().decode("utf-8")
        return included_files

        
@startuml
class ReturnClass {
    - repo : object
    - e : Exception
    + retrieve_code(repo : object, branch_name : string) : dict

    # logger : object

    + __init__(repo : object)
    + clone_repo() : repo
    
}

class Logger {
    - message : string
    - level : string
    + debug(message : string) : void
    + info(message : string) : void
    + error(message : string) : void
}

ReturnClass "1" --right--> "*" Logger : has a

class Exception {
    + __init__(message : string)
    + __str__() : string
}

Logger "1" --right--> "*" Exception : logs

Exception --|> BaseException

class ValueError {
    + __init__(message : string)
    + __str__() : string
}

ValueError --|> Exception

class Config {
    + config_file_path : string
    + include_list : list
    + ignore_list : list
    + retrieve_config() : dict
}

Config <|-down-- ReturnClass : retrieves

class JSON {
    + load(file_path : string) : dict
    + get(key : string) : object
}

JSON "1" --right--> "1" Config : has a

class os {
    + path : string
    + abspath(file_path : string) : string
    + join(*paths : string) : string
    + dirname(directory_path : string) : string
}

os "1" --right--> "*" Config : has a

class FStream {
    - data : string
    + read() : string
}

class TreeNode {
    + path : string
    + data_stream : FStream
}

TreeNode "1" -- "*" ReturnClass : returns

class PatternMatching {
    + fnmatch(path : string, pattern : string) : boolean
    + any(*patterns : string) : boolean
}

PatternMatching "1" --right--> "1" TreeNode : checks

class Exception "1" --down--> "1" ___ ReturnClass : raises

ReturnClass --> "1" JSON : uses
ReturnClass --> "1" os : uses
ReturnClass --> PatternMatching : uses
@enduml
2024-01-21 17:03:46,295 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-21 17:03:46,297 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-21 17:03:46,298 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:03:46,299 - DEBUG - send_request_headers.complete
2024-01-21 17:03:46,299 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:03:46,299 - DEBUG - send_request_body.complete
2024-01-21 17:03:46,299 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:03:48,770 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:03:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2380'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'f89d775ae76bc39ec5555885a0ace658'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933142d93f2434-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:03:48,772 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:03:48,773 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:03:48,773 - DEBUG - receive_response_body.complete
2024-01-21 17:03:48,774 - DEBUG - response_closed.started
2024-01-21 17:03:48,774 - DEBUG - response_closed.complete
2024-01-21 17:03:48,775 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:03:48,776 - INFO - Received response from OpenAI: 

@startuml

class CodeRetriever {
    - include_list : List
    - ignore_list : List
    + logger : Logger

    + retrieve_code(files : List) : Dictionary
}

class Logger {
	+ info(message : String)
    + warning(message : String)
    + error(message : String)
}

CodeRetriever o-- Logger

class File {
    - path : String
    - abspath : String
}

class FileNotFoundError {
    + str
}

CodeRetriever ..> File

class IncludedFile {
    - path : String
    - content : String
}

CodeRetriever ..> IncludedFile

class ValueError {
    + str
}

CodeRetriever ..> ValueError

CodeRetriever ..> File

Logger ..> CodeRetriever
File ..> CodeRetriever
File ..> FileNotFoundError
IncludedFile ..> CodeRetriever
ValueError ..> CodeRetriever

note right of ValueError:.add extends

@enduml
2024-01-21 17:03:48,777 - INFO - UML code generated for src/routes/retrieve_code.py: @startuml
title retrieve_code.py
# Get the latest commit for the repository
        commits = list(repo.iter_commits())
        latest_commit = commits[0]
        logger.info(f"Latest commit for repository {repo_url}: {latest_commit}")
        return latest_commit
    except git.exc.GitCommandError as e:
        logger.error(f"Error cloning repository: {repo_url}: {e}")
        return None


def get_commit_info(commit):
    # Get the commit message and author
    message = commit.message
    author = commit.author.name
    # Get the changed files
    files = commit.stats.files
    changed_files = [f"{change_type} - {file_name}" for file_name, change_type in files.items()]
    return message, author, changed_files


def main():
    # Read config file
    with open('config.json') as f:
        config = json.load(f)
    
    # Clone the specified repository
    latest_commit = clone_repo(config['repo_url'], config['temp_dir'], config['access_token'])
    
    # If cloning was successful, get the commit info
    if latest_commit:
        message, author, changed_files = get_commit_info(latest_commit)
        logger.info(f"Commit message: {message}")
        logger.info(f"Committer: {author}")
        for file in changed_files:
            logger.info(f"Changed file: {file}")


@startuml

Class git

Class json

Class os

Class logging {
+handlers: logging.handlers
+formatter: logging.formatter
"logger": logging.logger
}

Class handlers

Class file_logging {
-"log_directory": string
-"log_filename": string
-"log_handler": RotatingFileHandler
-log_formatter: string
-log_level: int
+"set_level(level)": void
-"get_level()": int
+"add_handler(handler)": void
+"remove_handler(handler)": void
-"set_formatter(formatter)": void
+"set_filename(filename)": void
+"flush()": void
+"close()": void
+"handle(record)": void
+"emit(record)": void
+"format(record": void
+"handleError(record)": void 
}

Class repo {
-temp_dir: string
-access_token: string
-repo_url: string
+clone_repo(repo_url, temp_dir, access_token): latest_commit
#"get_latest_commit(repo)": latest_commit
-"get_commit_info(commit)": message, author, changed_files 
+"set_repo_url(repo_url)": void
+"get_repo_url()": string
+"set_temp_dir(temp_dir)": void
+"get_temp_dir()": string
+"set_access_token(access_token)": void 
+"get_access_token()": string
}

Class latest_commit {
-"commits": list
-"latest_commit": current_commit
+"get_latest_commit(repo)": current_commit
#"set_commits(commit)" 
}

git <|-- repo
json <|-- repo
os <|-- file_logging
repo "1" *-- "1" handlers
handlers <|-- file_logging 
logging -- handlers 
handlers <|-- logging
Class handlers <<(S,#FFAAAA)>> 
Class logging <<(F,Yellow)>> 
Class git <<(C,#FFAAAA)>> 
Class os <<(R,#FFAAAA)>> 
Class file_logging <<(R,LightBlue)>> 
Class json <<(F,Lime)>> 
Class repo <<(F,#FFAAAA)>> 
Class latest_commit <<(C,#FFAAAA)>>

main() -> logging: set_level
logging -> handlers : add_handler
handlers -> file_logging: set_filename
file_logging -> repo: set_temp_dir
repo -> git: clone_repo
repo -> json: load_config
git -> logging: log [success]
handlers --> logging: record
logging -- main: success

@enduml# Check if file path matches any patterns in include list
            if any(fnmatch.fnmatch(file.path, pattern) for pattern in include_list):
                # Check if file path matches any patterns in ignore list, if not add it to the included files dictionary
                if not any(fnmatch.fnmatch(file.path, pattern) for pattern in ignore_list):
                    included_files[file.path] = file.data_stream.read().decode("utf-8")
        return included_files

        
@startuml
class ReturnClass {
    - repo : object
    - e : Exception
    + retrieve_code(repo : object, branch_name : string) : dict

    # logger : object

    + __init__(repo : object)
    + clone_repo() : repo
    
}

class Logger {
    - message : string
    - level : string
    + debug(message : string) : void
    + info(message : string) : void
    + error(message : string) : void
}

ReturnClass "1" --right--> "*" Logger : has a

class Exception {
    + __init__(message : string)
    + __str__() : string
}

Logger "1" --right--> "*" Exception : logs

Exception --|> BaseException

class ValueError {
    + __init__(message : string)
    + __str__() : string
}

ValueError --|> Exception

class Config {
    + config_file_path : string
    + include_list : list
    + ignore_list : list
    + retrieve_config() : dict
}

Config <|-down-- ReturnClass : retrieves

class JSON {
    + load(file_path : string) : dict
    + get(key : string) : object
}

JSON "1" --right--> "1" Config : has a

class os {
    + path : string
    + abspath(file_path : string) : string
    + join(*paths : string) : string
    + dirname(directory_path : string) : string
}

os "1" --right--> "*" Config : has a

class FStream {
    - data : string
    + read() : string
}

class TreeNode {
    + path : string
    + data_stream : FStream
}

TreeNode "1" -- "*" ReturnClass : returns

class PatternMatching {
    + fnmatch(path : string, pattern : string) : boolean
    + any(*patterns : string) : boolean
}

PatternMatching "1" --right--> "1" TreeNode : checks

class Exception "1" --down--> "1" ___ ReturnClass : raises

ReturnClass --> "1" JSON : uses
ReturnClass --> "1" os : uses
ReturnClass --> PatternMatching : uses
@enduml@startuml

class CodeRetriever {
    - include_list : List
    - ignore_list : List
    + logger : Logger

    + retrieve_code(files : List) : Dictionary
}

class Logger {
	+ info(message : String)
    + warning(message : String)
    + error(message : String)
}

CodeRetriever o-- Logger

class File {
    - path : String
    - abspath : String
}

class FileNotFoundError {
    + str
}

CodeRetriever ..> File

class IncludedFile {
    - path : String
    - content : String
}

CodeRetriever ..> IncludedFile

class ValueError {
    + str
}

CodeRetriever ..> ValueError

CodeRetriever ..> File

Logger ..> CodeRetriever
File ..> CodeRetriever
File ..> FileNotFoundError
IncludedFile ..> CodeRetriever
ValueError ..> CodeRetriever

note right of ValueError:.add extends

@enduml
2024-01-21 17:03:48,778 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:03:48,778 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:03:48,779 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-21 17:03:48,779 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-21 17:03:48,781 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-21 17:03:48,782 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:03:48,783 - DEBUG - send_request_headers.complete
2024-01-21 17:03:48,783 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:03:48,783 - DEBUG - send_request_body.complete
2024-01-21 17:03:48,783 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:03:48,948 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:03:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'74'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'cd3006be71dd4432f2bff46d118ba0e9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849331526c8c2434-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:03:48,949 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:03:48,949 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:03:48,949 - DEBUG - receive_response_body.complete
2024-01-21 17:03:48,949 - DEBUG - response_closed.started
2024-01-21 17:03:48,949 - DEBUG - response_closed.complete
2024-01-21 17:03:48,950 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:03:48,950 - INFO - Received response from OpenAI: 
2024-01-21 17:03:48,950 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-21 17:03:48,951 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-21 17:03:48,952 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:03:48,952 - DEBUG - send_request_headers.complete
2024-01-21 17:03:48,952 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:03:48,952 - DEBUG - send_request_body.complete
2024-01-21 17:03:48,952 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:03:52,957 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:03:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3807'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'4c8bcba7ab20fca06da20d7d3155969d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849331541ee02434-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:03:52,957 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:03:52,957 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:03:52,958 - DEBUG - receive_response_body.complete
2024-01-21 17:03:52,958 - DEBUG - response_closed.started
2024-01-21 17:03:52,958 - DEBUG - response_closed.complete
2024-01-21 17:03:52,958 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:03:52,959 - INFO - Received response from OpenAI: )

        # Generate the UML
        codegen = CodeGenerator(config)
        codegen.generate_uml(repo, branch_name, output_directory)

''' @startuml
class data {
    <<data>>
    - gitHubAccessToken
    - branchName
    + get()
}
class logger {
    - error()
    - info()
}

class tempfile {
    <<utility>>
    + mkdtemp()
}
class shutil {
    <<utility>>
    + rmtree()
}

class repo {
    <<entity>>
    + clone_repo()
}

class config {
    <<data>>
    + generate_uml()
}

class CodeGenerator {
    <<entity>>
    - config: config
    + generate_uml()
}

class data {
    <<data>>
}

class logger {
    <<utility>>
}

class tempfile {
    <<utility>>
}

class shutil {
    <<utility>>
}

class repo {
    <<entity>>
}

class config {
    <<entity>>
}

class CodeGenerator {
    <<entity>>
}

thub_access_token *-- data : <<uses>>
branch_name -- data : <<uses>>
git_repo_url -- data : <<uses>>
output_directory -- data : <<uses>>
github_access_token -- data : <<uses>>
logger -- data : <<uses>>

CodeGenerator o-- config : <<uses>>
repo --> tempfile : <<uses>>
CodeGenerator --> repo : <<uses>>
CodeGenerator --> config : <<uses>>
CodeGenerator --> logger : <<uses>>
CodeGenerator --> tempfile : <<uses>>
CodeGenerator --> shutil : <<uses>>

tempfile ..> shutil : <<uses>>

@enduml '''
2024-01-21 17:03:52,960 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-21 17:03:52,961 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-21 17:03:52,962 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:03:52,962 - DEBUG - send_request_headers.complete
2024-01-21 17:03:52,962 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:03:52,962 - DEBUG - send_request_body.complete
2024-01-21 17:03:52,963 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:03:56,549 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:03:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3482'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'4349bfa9f0b2ac9a9c3a663b17fe87a2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493316c8ca22434-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:03:56,550 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:03:56,550 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:03:56,551 - DEBUG - receive_response_body.complete
2024-01-21 17:03:56,551 - DEBUG - response_closed.started
2024-01-21 17:03:56,551 - DEBUG - response_closed.complete
2024-01-21 17:03:56,551 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:03:56,553 - INFO - Received response from OpenAI: t_diagrams(repo, temp_dir, included_files, output_directory )


@startuml

class Repo {
- tree : Tree
----
+ traverse() : void
+ get_tree() : Tree
}

class Tree {
-----
+ traverse() : void
}

class Item {
- type : String
- path : String
-----
+ get_type() : String
+ get_path() : String
}

class Config {
- include : List
-----
+ get_include() : List
+ get_pattern() : String
}

class Logger {
-----
+ debug(message : String) : void
+ info(message : String) : void
}

class File {
- path : String
- content : String
-----
+ get_path() : String
+ get_content() : String
}

class TraverseDirectories {
-----
+ traverse_directories(repo : Repo, temp_dir : File, config : Config) : File
}

class GenerateContentDiagram {
-----
+ generate_content_diagrams(repo : Repo, temp_dir : File, included_files : File, output_directory : String) : File
}

Repo <-- TraverseDirectories : uses
Repo <-- GenerateContentDiagram : uses
Repo <-- Item : contains
Repo <-- Tree : contains
Item <-- TraverseDirectories : accesses
Item <-- GenerateContentDiagram : accesses
Config <-- TraverseDirectories : accesses
Logger <-- TraverseDirectories : uses
Logger <-- GenerateContentDiagram : uses
File <-- TraverseDirectories : returns
File <-- GenerateContentDiagram : returns

@enduml
2024-01-21 17:03:56,553 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-21 17:03:56,555 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-21 17:03:56,556 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:03:56,556 - DEBUG - send_request_headers.complete
2024-01-21 17:03:56,556 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:03:56,557 - DEBUG - send_request_body.complete
2024-01-21 17:03:56,557 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:04:00,454 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:04:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3698'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'e112a99517ee342a60d2e009a6143a89'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933182f8882434-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:04:00,455 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:04:00,456 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:04:00,457 - DEBUG - receive_response_body.complete
2024-01-21 17:04:00,458 - DEBUG - response_closed.started
2024-01-21 17:04:00,458 - DEBUG - response_closed.complete
2024-01-21 17:04:00,459 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:04:00,460 - INFO - Received response from OpenAI:  @enduml

@startuml

class UMLGenerator {
+ included_files : list
+ output_directory : str
+ final_output_paths : list

# temp_dir : str
# git_repo_url : str

<<constructor>>
+ UMLGenerator(included_files : list, output_directory : str)

+ generateUML() : dict

# _get_git_repo_url() : str
# _get_temp_dir() : str
# _generate_diagrams() : dict
# _log_output_paths(final_output_paths : list) : None

}

UMLGenerator --> included_files : has_files
UMLGenerator --> output_directory : save_to
UMLGenerator --> final_output_paths : generate_diagrams()

UMLGenerator --> temp_dir : create
UMLGenerator --> git_repo_url : get_repo_url()

UMLGenerator ..> logger : logging
UMLGenerator ..> shutil : remove_temp_dir()

class logger {
+ info(message : str) : None
+ error(message : str) : None
}

class shutil {
+ rmtree(directory : str) : None
}

class main {
+ included_files : list
+ output_directory : str

<<constructor>>
+ main(included_files : list, output_directory : str)

+ run() : dict

_for_loop(output_paths : list) : None

}

main --> included_files : has_files
main --> output_directory : save_to
main ..> UMLGenerator : generateUML()
main ..> _for_loop()

logger --> main : logs_info/error()

shutil --> main : temp_dir_operations()
shutil --> UMLGenerator : temp_dir_operations()

main ..> logger : logs_info/error()
@enduml
2024-01-21 17:04:00,461 - INFO - UML code generated for src/routes/uml_from_repo.py: @startuml
title uml_from_repo.py
)

        # Generate the UML
        codegen = CodeGenerator(config)
        codegen.generate_uml(repo, branch_name, output_directory)

''' @startuml
class data {
    <<data>>
    - gitHubAccessToken
    - branchName
    + get()
}
class logger {
    - error()
    - info()
}

class tempfile {
    <<utility>>
    + mkdtemp()
}
class shutil {
    <<utility>>
    + rmtree()
}

class repo {
    <<entity>>
    + clone_repo()
}

class config {
    <<data>>
    + generate_uml()
}

class CodeGenerator {
    <<entity>>
    - config: config
    + generate_uml()
}

class data {
    <<data>>
}

class logger {
    <<utility>>
}

class tempfile {
    <<utility>>
}

class shutil {
    <<utility>>
}

class repo {
    <<entity>>
}

class config {
    <<entity>>
}

class CodeGenerator {
    <<entity>>
}

thub_access_token *-- data : <<uses>>
branch_name -- data : <<uses>>
git_repo_url -- data : <<uses>>
output_directory -- data : <<uses>>
github_access_token -- data : <<uses>>
logger -- data : <<uses>>

CodeGenerator o-- config : <<uses>>
repo --> tempfile : <<uses>>
CodeGenerator --> repo : <<uses>>
CodeGenerator --> config : <<uses>>
CodeGenerator --> logger : <<uses>>
CodeGenerator --> tempfile : <<uses>>
CodeGenerator --> shutil : <<uses>>

tempfile ..> shutil : <<uses>>

@enduml '''t_diagrams(repo, temp_dir, included_files, output_directory )


@startuml

class Repo {
- tree : Tree
----
+ traverse() : void
+ get_tree() : Tree
}

class Tree {
-----
+ traverse() : void
}

class Item {
- type : String
- path : String
-----
+ get_type() : String
+ get_path() : String
}

class Config {
- include : List
-----
+ get_include() : List
+ get_pattern() : String
}

class Logger {
-----
+ debug(message : String) : void
+ info(message : String) : void
}

class File {
- path : String
- content : String
-----
+ get_path() : String
+ get_content() : String
}

class TraverseDirectories {
-----
+ traverse_directories(repo : Repo, temp_dir : File, config : Config) : File
}

class GenerateContentDiagram {
-----
+ generate_content_diagrams(repo : Repo, temp_dir : File, included_files : File, output_directory : String) : File
}

Repo <-- TraverseDirectories : uses
Repo <-- GenerateContentDiagram : uses
Repo <-- Item : contains
Repo <-- Tree : contains
Item <-- TraverseDirectories : accesses
Item <-- GenerateContentDiagram : accesses
Config <-- TraverseDirectories : accesses
Logger <-- TraverseDirectories : uses
Logger <-- GenerateContentDiagram : uses
File <-- TraverseDirectories : returns
File <-- GenerateContentDiagram : returns

@enduml@enduml

@startuml

class UMLGenerator {
+ included_files : list
+ output_directory : str
+ final_output_paths : list

# temp_dir : str
# git_repo_url : str

<<constructor>>
+ UMLGenerator(included_files : list, output_directory : str)

+ generateUML() : dict

# _get_git_repo_url() : str
# _get_temp_dir() : str
# _generate_diagrams() : dict
# _log_output_paths(final_output_paths : list) : None

}

UMLGenerator --> included_files : has_files
UMLGenerator --> output_directory : save_to
UMLGenerator --> final_output_paths : generate_diagrams()

UMLGenerator --> temp_dir : create
UMLGenerator --> git_repo_url : get_repo_url()

UMLGenerator ..> logger : logging
UMLGenerator ..> shutil : remove_temp_dir()

class logger {
+ info(message : str) : None
+ error(message : str) : None
}

class shutil {
+ rmtree(directory : str) : None
}

class main {
+ included_files : list
+ output_directory : str

<<constructor>>
+ main(included_files : list, output_directory : str)

+ run() : dict

_for_loop(output_paths : list) : None

}

main --> included_files : has_files
main --> output_directory : save_to
main ..> UMLGenerator : generateUML()
main ..> _for_loop()

logger --> main : logs_info/error()

shutil --> main : temp_dir_operations()
shutil --> UMLGenerator : temp_dir_operations()

main ..> logger : logs_info/error()
@enduml
2024-01-21 17:04:00,462 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:04:00,463 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:04:00,463 - INFO - Skipping empty file: src/scripts/__init__.py
2024-01-21 17:04:00,463 - INFO - Processing file: src/scripts/execute_generate_uml.py
2024-01-21 17:04:00,464 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import json
import os
import requests
import logging
from logging import handlers
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure logging to write to a file
log_directory = '../../logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'execute_generate_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


# Configure logging
logging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))
# Configuration file path
config_file_path = os.path.join(cu
2024-01-21 17:04:00,465 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nimport json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(cu", 'max_tokens': 1024}}
2024-01-21 17:04:00,467 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:04:00,467 - DEBUG - send_request_headers.complete
2024-01-21 17:04:00,467 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:04:00,467 - DEBUG - send_request_body.complete
2024-01-21 17:04:00,468 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:04:03,201 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:04:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2553'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'540a58cf00bc4563d8f04e98e66b6f0c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493319b6e9f2434-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:04:03,203 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:04:03,204 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:04:03,205 - DEBUG - receive_response_body.complete
2024-01-21 17:04:03,205 - DEBUG - response_closed.started
2024-01-21 17:04:03,205 - DEBUG - response_closed.complete
2024-01-21 17:04:03,206 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:04:03,207 - INFO - Received response from OpenAI: rrent_dir, 'config.json')

# Read configuration file
with open(config_file_path, 'r') as config_file:
    config = json.load(config_file)

# Get endpoint from configuration file
endpoint = config['endpoint']


@startuml
class json <<Service>> {
- endpoint : string
- config : dict
- current_dir : string
- config_file_path : string
-- GetEndpoint(): endpoint
}
class logger <<Utility>> {
- log_directory : string
- log_filename : string
- log_handler : handlers.RotatingFileHandler
- log_formatter : logging.Formatter
-- write_to_log(log_message: string): void
}

class config_file <<Data>> {
- endpoint : string
}

class dotenv <<Utility>> {

}
class requests <<Utility>> {

}

class os <<Utility>> {

}

json --|> config_file : reads 
logger --|> log_handler : writes
config_file --|> dotenv : loads
json --|> dotenv : loads
json --|> requests : makes API calls
dotenv --|> os : gets variables from file
requests .> endpoint : uses
@enduml
2024-01-21 17:04:03,208 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

rrent_dir, 'config.json')

# Read configuration from the JSON file
with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

# Retrieve the GitHub access token from environment variables
github_token = os.getenv('GITHUB_PAT')

# Endpoint URL
url = 'http://127.0.0.1:5000/generate-uml'

# Headers
headers = {
    'Content-Type': 'application/json'
}

# Update the GitHub access token and local directory in the config data
config_data['gitHubAccessToken'] = github_token
config_data['local_dir'] = os.path.join(current_dir, '../..', 'output')

# Log the JSON data being sent in the request
logging.info(f'Sending JSON data to {url}:')
logging.info(json.dumps(config_data, indent=2))

try:
    # Make the POST request
    response = requests.post(url, headers=headers, json=config_data)

    # Log the response from the server
    logging.info(f'Response from server ({url}):')
    logging.info(f'Status Code: {response.status_code}')
    logging.info(f'Response Text: {response.text}')

    #
2024-01-21 17:04:03,210 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nrrent_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    #", 'max_tokens': 1024}}
2024-01-21 17:04:03,211 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:04:03,212 - DEBUG - send_request_headers.complete
2024-01-21 17:04:03,212 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:04:03,212 - DEBUG - send_request_body.complete
2024-01-21 17:04:03,212 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:04:05,904 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:04:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2604'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'072d1cbc804bfef1820bdbd03778154c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849331ac9c342434-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:04:05,906 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:04:05,911 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:04:05,912 - DEBUG - receive_response_body.complete
2024-01-21 17:04:05,912 - DEBUG - response_closed.started
2024-01-21 17:04:05,912 - DEBUG - response_closed.complete
2024-01-21 17:04:05,913 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:04:05,914 - INFO - Received response from OpenAI:  Check if the response was successful
    if response.status_code == 200:
        # Save the UML image file
        image_data = json.loads(response.text)
        with open(image_data['file_name'], 'wb') as f:
            f.write(base64.b64decode(image_data['file_content']))
except Exception as e:
    # Log any errors encountered
    logging.error(f'Encountered an error while making the request: {e}')



@startuml

class UMLGenerator {
    - current_dir: str
    - config_file_path: str
    - config_data: dict
    - github_token: str
    - url: str
    - headers: dict
    - image_data: dict

    + __init__(current_dir, config_file_path)
    + read_config()
    + get_github_token()
    + send_request()
    + handle_response()
}

class ConfigData {
    - gitHubAccessToken: str
    - local_dir: str

    + __init__(github_token, local_dir)
    + update(token, dir)
}

UMLGenerator --> ConfigData: owns

@enduml
2024-01-21 17:04:05,914 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

 Print the response from the server
    print(response.text)

    # Save the response to a file in the output directory
    output_dir = os.path.join(current_dir, '../..', 'output')
    os.makedirs(output_dir, exist_ok=True)
    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:
        json.dump(response.json(), output_file, indent=2)

except Exception as e:
    # Log any exceptions that occur
    logging.error(f'Error occurred: {str(e)}')
2024-01-21 17:04:05,916 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')", 'max_tokens': 1024}}
2024-01-21 17:04:05,917 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:04:05,918 - DEBUG - send_request_headers.complete
2024-01-21 17:04:05,918 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:04:05,918 - DEBUG - send_request_body.complete
2024-01-21 17:04:05,918 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:04:07,916 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:04:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1868'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'dbf7bf3423745ae36d0e71bacc75c00c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849331bd78712434-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:04:07,918 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:04:07,918 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:04:07,919 - DEBUG - receive_response_body.complete
2024-01-21 17:04:07,920 - DEBUG - response_closed.started
2024-01-21 17:04:07,921 - DEBUG - response_closed.complete
2024-01-21 17:04:07,921 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:04:07,922 - INFO - Received response from OpenAI: 

@startuml

class HttpRequest {
    - response: HttpResponse
    + text: str
    + json(): dict
}

class HttpResponse {
    - headers: dict
    - status_code: int
    + text: str
    + json(): dict
}

class FileManager {
    - current_dir: str
    - output_dir: str
    + save_to_file(data: dict): void
}

note right of HttpRequest
response: HttpResponse
end note

HttpRequest --> HttpResponse : makeRequest()
HttpResponse --> HttpRequest : response
HttpRequest --> FileManager : save_to_file()
FileManager --> FileManager : create_output_dir()
note right of FileManager
output_dir: str
data: dict
end note

@enduml
2024-01-21 17:04:07,923 - INFO - UML code generated for src/scripts/execute_generate_uml.py: @startuml
title execute_generate_uml.py
rrent_dir, 'config.json')

# Read configuration file
with open(config_file_path, 'r') as config_file:
    config = json.load(config_file)

# Get endpoint from configuration file
endpoint = config['endpoint']


@startuml
class json <<Service>> {
- endpoint : string
- config : dict
- current_dir : string
- config_file_path : string
-- GetEndpoint(): endpoint
}
class logger <<Utility>> {
- log_directory : string
- log_filename : string
- log_handler : handlers.RotatingFileHandler
- log_formatter : logging.Formatter
-- write_to_log(log_message: string): void
}

class config_file <<Data>> {
- endpoint : string
}

class dotenv <<Utility>> {

}
class requests <<Utility>> {

}

class os <<Utility>> {

}

json --|> config_file : reads 
logger --|> log_handler : writes
config_file --|> dotenv : loads
json --|> dotenv : loads
json --|> requests : makes API calls
dotenv --|> os : gets variables from file
requests .> endpoint : uses
@endumlCheck if the response was successful
    if response.status_code == 200:
        # Save the UML image file
        image_data = json.loads(response.text)
        with open(image_data['file_name'], 'wb') as f:
            f.write(base64.b64decode(image_data['file_content']))
except Exception as e:
    # Log any errors encountered
    logging.error(f'Encountered an error while making the request: {e}')



@startuml

class UMLGenerator {
    - current_dir: str
    - config_file_path: str
    - config_data: dict
    - github_token: str
    - url: str
    - headers: dict
    - image_data: dict

    + __init__(current_dir, config_file_path)
    + read_config()
    + get_github_token()
    + send_request()
    + handle_response()
}

class ConfigData {
    - gitHubAccessToken: str
    - local_dir: str

    + __init__(github_token, local_dir)
    + update(token, dir)
}

UMLGenerator --> ConfigData: owns

@enduml@startuml

class HttpRequest {
    - response: HttpResponse
    + text: str
    + json(): dict
}

class HttpResponse {
    - headers: dict
    - status_code: int
    + text: str
    + json(): dict
}

class FileManager {
    - current_dir: str
    - output_dir: str
    + save_to_file(data: dict): void
}

note right of HttpRequest
response: HttpResponse
end note

HttpRequest --> HttpResponse : makeRequest()
HttpResponse --> HttpRequest : response
HttpRequest --> FileManager : save_to_file()
FileManager --> FileManager : create_output_dir()
note right of FileManager
output_dir: str
data: dict
end note

@enduml
2024-01-21 17:04:07,923 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:04:07,924 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:04:07,924 - INFO - Generated file paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 17:04:07,924 - INFO - Final output paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 17:04:07,925 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:04:07,925 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:04:07,925 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:04:07,925 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:04:07,925 - INFO - Cleaning up temporary directory
2024-01-21 17:04:08,105 - INFO - 127.0.0.1 - - [21/Jan/2024 17:04:08] "POST /generate-uml HTTP/1.1" 200 -
2024-01-21 17:11:40,520 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/openai_api.py', reloading
2024-01-21 17:11:40,593 - INFO -  * Restarting with stat
2024-01-21 17:11:40,871 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 17:11:40,872 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 17:11:40,880 - WARNING -  * Debugger is active!
2024-01-21 17:11:40,886 - INFO -  * Debugger PIN: 139-904-016
2024-01-21 17:11:51,395 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 17:11:51,395 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 17:11:51,405 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-21 17:11:51,405 - INFO - [33mPress CTRL+C to quit[0m
2024-01-21 17:11:51,406 - INFO -  * Restarting with stat
2024-01-21 17:11:51,687 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 17:11:51,688 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 17:11:51,697 - WARNING -  * Debugger is active!
2024-01-21 17:11:51,702 - INFO -  * Debugger PIN: 139-904-016
2024-01-21 17:11:54,273 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-21 17:11:54,273 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-21 17:11:54,273 - INFO - Received local_dir: ./output
2024-01-21 17:11:54,273 - INFO - Received gitHubAccessToken: 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
2024-01-21 17:11:54,274 - INFO - Cleaning up temporary directory
2024-01-21 17:11:54,274 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 17:11:54,276 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-21 17:11:54,277 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp5lq2f_ly'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-21 17:11:58,041 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp5lq2f_ly'])'s unused stdout: 
2024-01-21 17:11:58,043 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 17:11:58,043 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp5lq2f_ly, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 17:11:58,049 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp5lq2f_ly, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 17:11:58,071 - DEBUG - Type of included_files: <class 'dict'>
2024-01-21 17:11:58,072 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 17:11:58,072 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-21 17:11:58,072 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 17:11:58,072 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-21 17:11:58,072 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-21 17:11:58,073 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-21 17:11:58,074 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-21 17:11:58,086 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-21 17:11:58,217 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x108b11150>
2024-01-21 17:11:58,217 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108499b50> server_hostname='api.openai.com' timeout=5.0
2024-01-21 17:11:58,246 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x108b117d0>
2024-01-21 17:11:58,246 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:11:58,247 - DEBUG - send_request_headers.complete
2024-01-21 17:11:58,247 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:11:58,247 - DEBUG - send_request_body.complete
2024-01-21 17:11:58,247 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:12:01,135 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:12:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2807'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'2970097c5d4fda8091288a278c92047d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PWhhuisE7vFMEANQCuAyH0nXW1AqNmqn91iehMH_HWA-1705878721-1-AZn/irGQQ633tbgAcqCPz4/3HFIuaQpvSa4rwNYw0DZeOQm7lGsna8TA5/sXwSOMsEE7yoVIiCMdxxq2ord9/RE=; path=/; expires=Sun, 21-Jan-24 23:42:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=0qS5KtAbNSJie2F7Y0jkTx9thKsG.gYvI6KYvYf.WW8-1705878721174-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933d457f6353bb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:12:01,138 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:12:01,138 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:12:01,139 - DEBUG - receive_response_body.complete
2024-01-21 17:12:01,139 - DEBUG - response_closed.started
2024-01-21 17:12:01,140 - DEBUG - response_closed.complete
2024-01-21 17:12:01,140 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:12:01,143 - INFO - Received response from OpenAI: 
        if code == "":
            continue
        file_paths.append(file_path)  # Add the file path to file_paths
        # Use the OpenAI API to generate code based on the input code
        generated_code += api.generate_code(code)
    # Write the generated code to a file in the output directory
    with open(os.path.join(output_directory, 'generated_code.py'), 'w') as f:
        f.write(generated_code)
    # Return the list of processed file paths
    return file_paths

uml_diagram:

@startuml

class OpenAIAPI {
    - api_key
    # config_api()
    + generate_code()
}

class logging {
    - log_directory
    - log_filename
    - log_handler
    - log_formatter
    + logger
    + generate_content()
}

class handlers.RotatingFileHandler {
    - maxBytes
    - backupCount
}

class File {
    - file_path
    - code
}

class os {
    + makedirs()
    + path.join()
}

OpenAIAPI ..> api_key
OpenAIAPI o-- File
logging o-- File 
File o-- os
File ..> OpenAIAPI 
File ..> logging 
File ..> os
logging o-- handlers.RotatingFileHandler

@enduml 
2024-01-21 17:12:01,144 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-21 17:12:01,146 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-21 17:12:01,147 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:12:01,147 - DEBUG - send_request_headers.complete
2024-01-21 17:12:01,148 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:12:01,148 - DEBUG - send_request_body.complete
2024-01-21 17:12:01,148 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:12:05,541 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:12:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4244'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'6fe72c2cf115524400354b1a4ea110b5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933d579b5f53bb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:12:05,542 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:12:05,543 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:12:05,544 - DEBUG - receive_response_body.complete
2024-01-21 17:12:05,544 - DEBUG - response_closed.started
2024-01-21 17:12:05,544 - DEBUG - response_closed.complete
2024-01-21 17:12:05,545 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:12:05,545 - INFO - Received response from OpenAI: _paths}



```
@startuml
class UMLGenerator {
- code: String
- file_paths: List<String>
- output_directory: String
- api: API

+ generate_uml(code: String): void
+ save_generated_output(generated_code: String, output_path: String): String
}

class API {
- generated_code_for_file: String

+ generate_from_code(code: String): String
}

class Logger {
- log_message: String

+ info(message: String): void
+ error(message: String): void
}

class Main {
- file_paths: List<String>
- output_directory: String

+ main(args: String[]): void
}

Main -- UMLGenerator
Main -- Logger
UMLGenerator -- API
UMLGenerator -- Logger
API -- Logger

if (code.strip()) then (false)
    Logger.info("Skipping empty file: {file_path}")
else
    Logger.info("Processing file: {file_path}")
    UMLGenerator.generate_uml(code)
    Logger.info("UML code generated for {file_path}: {generated_code_for_file}")
    
    if (generated_code_for_file || "UML generation failed" in generated_code_for_file) then (true)
        Logger.error("Failed to generate UML diagram for {file_path}")
        raise ValueError("Failed to generate UML diagram for {file_path}")
    else
        UMLGenerator.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.add(final_output_path)
endif

note right: Save the UML code for each file to a separate .puml file
file_name = f"{os.path.basename(file_path)}.puml"
final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
file_paths.append(final_output_path)  # Append the file path to the list

Logger.info("Generated file paths: {file_paths}")
@enduml
```
2024-01-21 17:12:05,546 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-21 17:12:05,547 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-21 17:12:05,547 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:12:05,548 - DEBUG - send_request_headers.complete
2024-01-21 17:12:05,548 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:12:05,548 - DEBUG - send_request_body.complete
2024-01-21 17:12:05,548 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:12:07,796 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:12:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2155'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'5d62979a3cfe1aca9098a7a1c3369f06'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933d7319ff53bb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:12:07,798 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:12:07,799 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:12:07,800 - DEBUG - receive_response_body.complete
2024-01-21 17:12:07,801 - DEBUG - response_closed.started
2024-01-21 17:12:07,801 - DEBUG - response_closed.complete
2024-01-21 17:12:07,802 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:12:07,803 - INFO - Received response from OpenAI: 

@staticmethod
def _generate_code(filepath):
    """
    Private static method that generates code based on a given file path

    param filepath: the path to the file
    return: the generated code

class CodeGenerator


@startuml
class CodeGenerator {
    - generator_options : dict  // private attribute containing generator options
    + generate(file_list): tuple(list, str)  // public method for generating code
    - _generate_code(filepath) // private static method for generating code
}

class CodeGenerator {
    - file_list : list  // private attribute containing list of file paths
    + generate_code()  // public method for generating code
}

CodeGenerator --> _generate_code
CodeGenerator --> generate

generate_code --> file_list
_generate_code --> filepath

@enduml
2024-01-21 17:12:07,803 - INFO - UML code generated for src/routes/code_to_uml.py: @startuml
title code_to_uml.py
if code == "":
            continue
        file_paths.append(file_path)  # Add the file path to file_paths
        # Use the OpenAI API to generate code based on the input code
        generated_code += api.generate_code(code)
    # Write the generated code to a file in the output directory
    with open(os.path.join(output_directory, 'generated_code.py'), 'w') as f:
        f.write(generated_code)
    # Return the list of processed file paths
    return file_paths

uml_diagram:

@startuml

class OpenAIAPI {
    - api_key
    # config_api()
    + generate_code()
}

class logging {
    - log_directory
    - log_filename
    - log_handler
    - log_formatter
    + logger
    + generate_content()
}

class handlers.RotatingFileHandler {
    - maxBytes
    - backupCount
}

class File {
    - file_path
    - code
}

class os {
    + makedirs()
    + path.join()
}

OpenAIAPI ..> api_key
OpenAIAPI o-- File
logging o-- File 
File o-- os
File ..> OpenAIAPI 
File ..> logging 
File ..> os
logging o-- handlers.RotatingFileHandler

@enduml_paths}



```
@startuml
class UMLGenerator {
- code: String
- file_paths: List<String>
- output_directory: String
- api: API

+ generate_uml(code: String): void
+ save_generated_output(generated_code: String, output_path: String): String
}

class API {
- generated_code_for_file: String

+ generate_from_code(code: String): String
}

class Logger {
- log_message: String

+ info(message: String): void
+ error(message: String): void
}

class Main {
- file_paths: List<String>
- output_directory: String

+ main(args: String[]): void
}

Main -- UMLGenerator
Main -- Logger
UMLGenerator -- API
UMLGenerator -- Logger
API -- Logger

if (code.strip()) then (false)
    Logger.info("Skipping empty file: {file_path}")
else
    Logger.info("Processing file: {file_path}")
    UMLGenerator.generate_uml(code)
    Logger.info("UML code generated for {file_path}: {generated_code_for_file}")
    
    if (generated_code_for_file || "UML generation failed" in generated_code_for_file) then (true)
        Logger.error("Failed to generate UML diagram for {file_path}")
        raise ValueError("Failed to generate UML diagram for {file_path}")
    else
        UMLGenerator.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.add(final_output_path)
endif

note right: Save the UML code for each file to a separate .puml file
file_name = f"{os.path.basename(file_path)}.puml"
final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
file_paths.append(final_output_path)  # Append the file path to the list

Logger.info("Generated file paths: {file_paths}")
@enduml
2024-01-21 17:12:07,804 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:12:07,805 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:12:07,805 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-21 17:12:07,805 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-21 17:12:07,807 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-21 17:12:07,808 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:12:07,809 - DEBUG - send_request_headers.complete
2024-01-21 17:12:07,809 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:12:07,809 - DEBUG - send_request_body.complete
2024-01-21 17:12:07,809 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:12:10,090 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:12:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2182'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'28bdc148492f3f23569b692eb602b0ea'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933d813cc253bb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:12:10,090 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:12:10,091 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:12:10,091 - DEBUG - receive_response_body.complete
2024-01-21 17:12:10,091 - DEBUG - response_closed.started
2024-01-21 17:12:10,091 - DEBUG - response_closed.complete
2024-01-21 17:12:10,091 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:12:10,092 - INFO - Received response from OpenAI: 
        # Check if the repository has any submodules and initialize them if present
        logger.info("Checking for submodules...")
        if repo.submodules:
            repo.submodules.foreach(lambda sub: sub.update(init=True, recursive=True))
            logger.info("Initialized submodules")
        
        return repo
        
    except Exception as e:
        logger.error(f"Failed to clone repository: {repo_url} - Error: {str(e)}")
        raise e


def get_file_content(file_path):
    with open(file_path, 'r') as f:
        return f.read()



@startuml

class Git
class Json
class Os
class Logging
class RotatingFileHandler
class Handlers
class CloneRepo
class Repo
class Submodules
class File
class FileWriter
class Error

Git .. Json 
Json .. Os 
Os .. Handlers 
Handlers .. CloneRepo 
CloneRepo .. Repo 
Repo .. Submodules
Handlers .. FileWriter 
FileWriter .. File 
FileSystem .. File 
Error .. CloneRepo 
CloneRepo .. FileWriter

@enduml
2024-01-21 17:12:10,093 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-21 17:12:10,094 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-21 17:12:10,094 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:12:10,094 - DEBUG - send_request_headers.complete
2024-01-21 17:12:10,094 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:12:10,094 - DEBUG - send_request_body.complete
2024-01-21 17:12:10,095 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:12:13,404 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:12:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3219'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'580394d63b161f1dc758cd4f4ebfd1a2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933d8f8efb53bb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:12:13,405 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:12:13,405 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:12:13,406 - DEBUG - receive_response_body.complete
2024-01-21 17:12:13,406 - DEBUG - response_closed.started
2024-01-21 17:12:13,406 - DEBUG - response_closed.complete
2024-01-21 17:12:13,406 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:12:13,407 - INFO - Received response from OpenAI: 	if file.path.endswith(".py") and file.path not in ignore_list:
		  # Read the code from the file and store it in the dictionary
                	with open(file.path, 'r') as f:
                    		included_files[file.path] = f.read()
        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code from repository: {str(e)}")
        raise ValueError(f"Failed to retrieve code from repository: {str(e)}")

@startuml

class CodeRetriever {
    -repo : Repository
    -branch_name : string
    -logger : Logger
    
    +retrieve_code(repo, branch_name) : dict
}

class Repository {
    -url : string
    -local_path : string
    -git : Git
    
    +__init__(url, local_path)
    +git_fetch()
    +git_checkout(branch_name)
    +tree() : list
}

class Git {
    -repo : Repository
    
    +__init__(repo)
    +fetch()
    +checkout(branch_name)
}

class Logger {
    #logger_instance : Logger
    
    +__init__()
    +info(message)
    +error(message)
}

class File {
    -path : string
    -code : string
    
    +__init__(path, code)
    +get_path() : string
    +get_code() : string
}

CodeRetriever --> Repository
CodeRetriever --> Logger
Repository --> Git
Repository --> File

@enduml
2024-01-21 17:12:13,407 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-21 17:12:13,408 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-21 17:12:13,409 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:12:13,410 - DEBUG - send_request_headers.complete
2024-01-21 17:12:13,410 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:12:13,411 - DEBUG - send_request_body.complete
2024-01-21 17:12:13,412 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:12:18,684 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:12:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5184'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'a9e471f9a861d5a2866f0920b3a38cbf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933da44bdf53bb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:12:18,686 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:12:18,686 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:12:18,687 - DEBUG - receive_response_body.complete
2024-01-21 17:12:18,687 - DEBUG - response_closed.started
2024-01-21 17:12:18,687 - DEBUG - response_closed.complete
2024-01-21 17:12:18,688 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:12:18,689 - INFO - Received response from OpenAI: 

Unfortunately, the given code is incomplete and lacks context, making it difficult to fully understand the purpose and functionality. Additionally, .puml format is usually used for creating sequence diagrams, while I believe a class diagram would be more suitable for this scenario. However, I will try my best to create some UML diagrams based on the given code.

Class Diagram:

@startuml
class FileUtil {
    - include_list: List<string>
    - ignore_list: List<string>
    + any: bool
    + logger: Logger
    + included_files: Dictionary<string, string>
    + getIncludedFiles(file: File): Dictionary<string, string>
    - retrieveCode(file: File): None
    - processFile(file: File): Dictionary<string, string>
    - isEndWithExt(ext: string): bool
    - isIgnoreFile(ignored_file: string): bool
}

class File {
    - path: string
    - abspath: string
}

@enduml

Sequence Diagram:

@startuml
actor User
boundary Logger
control FileUtil

User -> FileUtil: getIncludedFiles(file)
activate FileUtil
FileUtil -> FileUtil: any(file.path.endswith(ext) for ext in include_list)
activate FileUtil
FileUtil -> FileUtil: not any(ignored_file in file.path for ignored_file in ignore_list)
activate FileUtil

alt any
    FileUtil -> FileUtil: retrieveCode(file)
    activate FileUtil
    FileUtil -> Logger: info("Included file: <file.path>")
    activate Logger
    Logger -> Logger: print(f"Included file: {file.path}")
    activate Logger
    User <-- Logger
    deactivate Logger
    User <-- FileUtil
    deactivate FileUtil

else not any
    FileUtil -> Logger: warning("Ignoring missing file: <file.path>")
    activate Logger
    Logger -> Logger: print(f"Ignoring missing file: {file.path}")
    activate Logger
    User <-- Logger
    deactivate Logger
    FileUtil -> FileUtil: raise error(ValueError)
    activate FileUtil
    FileUtil -> FileUtil: raise error(LogError)
    activate FileUtil
    FileUtil -> Logger: error("Failed to retrieve code: <str(e)>")
    activate Logger
    Logger -> Logger: print(f"Failed to retrieve code: {str(e)}")
    activate Logger
    User <-- Logger
    deactivate Logger
    User <-- FileUtil
    deactivate FileUtil
end
deactivate FileUtil

@enduml
2024-01-21 17:12:18,690 - INFO - UML code generated for src/routes/retrieve_code.py: @startuml
title retrieve_code.py
# Check if the repository has any submodules and initialize them if present
        logger.info("Checking for submodules...")
        if repo.submodules:
            repo.submodules.foreach(lambda sub: sub.update(init=True, recursive=True))
            logger.info("Initialized submodules")
        
        return repo
        
    except Exception as e:
        logger.error(f"Failed to clone repository: {repo_url} - Error: {str(e)}")
        raise e


def get_file_content(file_path):
    with open(file_path, 'r') as f:
        return f.read()



@startuml

class Git
class Json
class Os
class Logging
class RotatingFileHandler
class Handlers
class CloneRepo
class Repo
class Submodules
class File
class FileWriter
class Error

Git .. Json 
Json .. Os 
Os .. Handlers 
Handlers .. CloneRepo 
CloneRepo .. Repo 
Repo .. Submodules
Handlers .. FileWriter 
FileWriter .. File 
FileSystem .. File 
Error .. CloneRepo 
CloneRepo .. FileWriter

@endumlif file.path.endswith(".py") and file.path not in ignore_list:
		  # Read the code from the file and store it in the dictionary
                	with open(file.path, 'r') as f:
                    		included_files[file.path] = f.read()
        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code from repository: {str(e)}")
        raise ValueError(f"Failed to retrieve code from repository: {str(e)}")

@startuml

class CodeRetriever {
    -repo : Repository
    -branch_name : string
    -logger : Logger
    
    +retrieve_code(repo, branch_name) : dict
}

class Repository {
    -url : string
    -local_path : string
    -git : Git
    
    +__init__(url, local_path)
    +git_fetch()
    +git_checkout(branch_name)
    +tree() : list
}

class Git {
    -repo : Repository
    
    +__init__(repo)
    +fetch()
    +checkout(branch_name)
}

class Logger {
    #logger_instance : Logger
    
    +__init__()
    +info(message)
    +error(message)
}

class File {
    -path : string
    -code : string
    
    +__init__(path, code)
    +get_path() : string
    +get_code() : string
}

CodeRetriever --> Repository
CodeRetriever --> Logger
Repository --> Git
Repository --> File

@endumlUnfortunately, the given code is incomplete and lacks context, making it difficult to fully understand the purpose and functionality. Additionally, .puml format is usually used for creating sequence diagrams, while I believe a class diagram would be more suitable for this scenario. However, I will try my best to create some UML diagrams based on the given code.

Class Diagram:

@startuml
class FileUtil {
    - include_list: List<string>
    - ignore_list: List<string>
    + any: bool
    + logger: Logger
    + included_files: Dictionary<string, string>
    + getIncludedFiles(file: File): Dictionary<string, string>
    - retrieveCode(file: File): None
    - processFile(file: File): Dictionary<string, string>
    - isEndWithExt(ext: string): bool
    - isIgnoreFile(ignored_file: string): bool
}

class File {
    - path: string
    - abspath: string
}

@enduml
2024-01-21 17:12:18,690 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:12:18,691 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:12:18,692 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-21 17:12:18,692 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-21 17:12:18,694 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-21 17:12:18,695 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:12:18,695 - DEBUG - send_request_headers.complete
2024-01-21 17:12:18,696 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:12:18,696 - DEBUG - send_request_body.complete
2024-01-21 17:12:18,696 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:12:26,819 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:12:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'8055'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'a97d60e494ba64cce1f244a9aa9be587'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933dc54bba53bb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:12:26,819 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:12:26,819 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:12:26,820 - DEBUG - receive_response_body.complete
2024-01-21 17:12:26,820 - DEBUG - response_closed.started
2024-01-21 17:12:26,820 - DEBUG - response_closed.complete
2024-01-21 17:12:26,820 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:12:26,821 - INFO - Received response from OpenAI: t_username = data.get('gitUsername') # Get the username for authentication
    git_password = data.get('gitPassword') # Get the password for authentication

# The class diagram for uml_from_repo.py

@startuml
namespace routes.retrieve_code {
class clone_repo {
    + url: String
    + directory: String
    + username: String
    + password: String
    + clone(): void
}

class retrieve_code {
    + directory: String
    + code_files: List<File>
    + get_code_files(): List<File>
}

class code_to_uml {
    + code_files: List<File>
    + output_directory: String
    + generate_content(): void
}
}

namespace routes {
class uml_from_repo {
    - log_directory: String
    - log_filename: String
    - log_handler: RotatingFileHandler
    - log_formatter: Formatter
    - logger: Logger
    + process_request(data: Dictionary): void
}
}

namespace logging {
class Logger {
    - name: String
    - level: Level
    + addHandler(handler: Handler): void
    + setLevel(level: Level): void
}

class RotatingFileHandler {
    - filename: String
    - mode: String
    - maxBytes: Integer
    - backupCount: Integer
    + doRollover(): void
    + emit(record: LogRecord): void
}

class Formatter {
    + format(record: LogRecord): String
}

enum Level {
    CRITICAL
    ERROR
    WARNING
    INFO
    DEBUG
}

}

namespace git {
class GitRepo {
    + url: String
    - username: String
    - password: String
    + clone(): GitRepo
    + pull(): void
    + change_branch(branch: String): void
    + checkout(commit: String): void
}

class Branch {
    - name: String
    + create(): Branch
    + delete(): void
    + exists(): Boolean
}

class Commit {
    - id: String
    - timestamp: String
    - author: String
    - message: String
    + get_diff(): String
}
}

namespace tempfile {
class TemporaryDirectory {
    + name: String
    + suffix: String
    + prefix: String
    - _prefix_pattern: String
    - _dir_created: Boolean
    + __init__(suffix: String, prefix: String, dir: String): void
    + __enter__(): TemporaryDirectory
    + __exit__(exc: exception, value: object, tb: object): void
    + cleanup(): void
}
}

namespace shutil {
class move {
    + src: String
    + dest: String
    + copy_function: Function
    + copy2_function: Function
    + ignore: List[String]
    + os.rename(src: String, dst: String): void
    + copytree(src: String, dst: String, symlinks: Boolean, ignore: Function[Directory, Files?]): void
}
}

namespace fnmatch {
class filter_files {
    + files: List[String]
    + pattern: String
    + match(files: List[String], pattern: String): void
}
}

namespace subprocess {
class call {
    + args: List[String]
    + shell: Boolean
    + timeout: Integer
    + check_output(): void
}
}

namespace json {
class dumps {
    + obj: Object
    + ensure_ascii: Boolean
    + check_circular: Boolean
    + allow_nan: Boolean
    + indent: Integer
    + sort_keys: Boolean
    + default(obj: Object): void
}
}
@enduml


2024-01-21 17:12:26,821 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-21 17:12:26,822 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-21 17:12:26,823 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:12:26,823 - DEBUG - send_request_headers.complete
2024-01-21 17:12:26,823 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:12:26,823 - DEBUG - send_request_body.complete
2024-01-21 17:12:26,823 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:12:32,973 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:12:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'6078'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'42f8ca4bbf0025d5c8145986483a1bdd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933df80efd53bb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:12:32,973 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:12:32,974 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:12:32,974 - DEBUG - receive_response_body.complete
2024-01-21 17:12:32,974 - DEBUG - response_closed.started
2024-01-21 17:12:32,974 - DEBUG - response_closed.complete
2024-01-21 17:12:32,974 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:12:32,975 - INFO - Received response from OpenAI: )

        # Generate and output the UML diagrams
        generate_uml_diagrams(repo, output_directory, branch_name, config)


@startuml
title GitHub UML Generator

class Data {
    -gitHubAccessToken: string
    -branchName: string
}

class Logger {
    +error(message: string)
    +info(message: string)
}

class TempFile {
    +mkdtemp(): string
}

class shutil {
    +rmtree(path: string)
}

class Config {
    -config: json
}

class Repo {
    +clone_repo(repo_url: string, temp_dir: string, access_token: string)
}

class UML {
    +generate_uml_diagrams(repo: Repo, output_dir: string, branch_name: string, config: Config)
}

class App {
    -git_repo_url: string
    -output_directory: string
    -github_access_token: string
    -branch_name: string
    -thub_access_token: string
    -logger: Logger
    -temp_dir: TempFile
    -shutil: shutil
    -config: Config
    -repo: Repo
    -uml: UML
    +main()
}

class Display {
    +show_error(error: string)
}

App --> Logger
App --> Data
App --> TempFile
App --> shutil
App --> Config
App --> Repo
App --> UML
App --> Display

Logger <-- App
Data <-- App
TempFile <-- App
shutil <-- App
Config <-- App
Repo <-- App
UML <-- App
Display <-- App

App : -git_repo_url
App : -output_directory
App : -github_access_token
App : -branch_name
App : -thub_access_token
App : -logger
App : -temp_dir
App : -shutil
App : -config
App : -repo
App : -uml
App : +main()

App --> Logger : -logger
Logger : -message
Display --> Logger : +error(error)

App --> Repo : -repo
Repo : +clone_repo(repo_url, temp_dir, access_token)

App --> UML : -uml
UML : +generate_uml_diagrams(repo, output_dir, branch_name, config)

App --> Config : -config
Config : -config
Config : +json.load(file)

App --> TempFile : -temp_dir
TempFile : +mkdtemp()

App --> shutil : -shutil
shutil : +rmtree(path)

Logger --> Display
TempFile --> App
shutil --> App
Config --> App
Repo --> App
UML --> App

@enduml

2024-01-21 17:12:32,975 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-21 17:12:32,975 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-21 17:12:32,976 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:12:32,976 - DEBUG - send_request_headers.complete
2024-01-21 17:12:32,976 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:12:32,976 - DEBUG - send_request_body.complete
2024-01-21 17:12:32,976 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:12:33,554 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:12:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'519'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'5347a014e2f02a34e340829665ac1e61'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933e1e7c0a53bb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:12:33,554 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:12:33,554 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:12:33,554 - DEBUG - receive_response_body.complete
2024-01-21 17:12:33,554 - DEBUG - response_closed.started
2024-01-21 17:12:33,554 - DEBUG - response_closed.complete
2024-01-21 17:12:33,555 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:12:33,555 - INFO - Received response from OpenAI: t(repo, included_files, output_directory)




@startuml

class Repository {
    temp_dir: string
    config: Config
    tree(): Tree
    traverse(): Iterator
}

class Tree {
    traverse(): Iterator
}

class Config {
    include: str
2024-01-21 17:12:33,555 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-21 17:12:33,556 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-21 17:12:33,557 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:12:33,557 - DEBUG - send_request_headers.complete
2024-01-21 17:12:33,557 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:12:33,557 - DEBUG - send_request_body.complete
2024-01-21 17:12:33,557 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:12:36,278 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:12:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2624'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'825edcc4ea39517a75390279ef46e2ff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933e2228d353bb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:12:36,278 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:12:36,279 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:12:36,279 - DEBUG - receive_response_body.complete
2024-01-21 17:12:36,279 - DEBUG - response_closed.started
2024-01-21 17:12:36,280 - DEBUG - response_closed.complete
2024-01-21 17:12:36,280 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:12:36,281 - INFO - Received response from OpenAI:  @startuml
  title UML for t(included_files, output_directory)
  
  class t {
    - final_output_paths: list
    - git_repo_url: string
    - temp_dir: string
    - logger: Logger
    
    + t(included_files, output_directory)
    - log_final_output_paths()
    - log_path(path)
    
    # generate_final_output_paths()
    + generate_final_output_paths()
    
    + run()
    
    + clean_up()
    
    + save_uml_diagrams()
  }
  
  class Logger {
    {static} # log(message: string)
  }
  
  t .. Logger
  
  class Exception {
    - error_msg: string
  }
  
  t .. Exception
  
  class File {
    - path: string
  }
  
  t --> File
  
  class Repository {
    - git_repo_url: string
  }
  
  t-o Repository
  
  class OutputPaths {
    - final_output_paths: list
  }
  
  t --> OutputPaths
  
  t ---> Exception
  Logger ---> Exception
  
  OutputPaths ..> File
  
  OutputPaths ..> Repository
  
  @enduml
2024-01-21 17:12:36,281 - INFO - UML code generated for src/routes/uml_from_repo.py: @startuml
title uml_from_repo.py
t_username = data.get('gitUsername') # Get the username for authentication
    git_password = data.get('gitPassword') # Get the password for authentication

# The class diagram for uml_from_repo.py

@startuml
namespace routes.retrieve_code {
class clone_repo {
    + url: String
    + directory: String
    + username: String
    + password: String
    + clone(): void
}

class retrieve_code {
    + directory: String
    + code_files: List<File>
    + get_code_files(): List<File>
}

class code_to_uml {
    + code_files: List<File>
    + output_directory: String
    + generate_content(): void
}
}

namespace routes {
class uml_from_repo {
    - log_directory: String
    - log_filename: String
    - log_handler: RotatingFileHandler
    - log_formatter: Formatter
    - logger: Logger
    + process_request(data: Dictionary): void
}
}

namespace logging {
class Logger {
    - name: String
    - level: Level
    + addHandler(handler: Handler): void
    + setLevel(level: Level): void
}

class RotatingFileHandler {
    - filename: String
    - mode: String
    - maxBytes: Integer
    - backupCount: Integer
    + doRollover(): void
    + emit(record: LogRecord): void
}

class Formatter {
    + format(record: LogRecord): String
}

enum Level {
    CRITICAL
    ERROR
    WARNING
    INFO
    DEBUG
}

}

namespace git {
class GitRepo {
    + url: String
    - username: String
    - password: String
    + clone(): GitRepo
    + pull(): void
    + change_branch(branch: String): void
    + checkout(commit: String): void
}

class Branch {
    - name: String
    + create(): Branch
    + delete(): void
    + exists(): Boolean
}

class Commit {
    - id: String
    - timestamp: String
    - author: String
    - message: String
    + get_diff(): String
}
}

namespace tempfile {
class TemporaryDirectory {
    + name: String
    + suffix: String
    + prefix: String
    - _prefix_pattern: String
    - _dir_created: Boolean
    + __init__(suffix: String, prefix: String, dir: String): void
    + __enter__(): TemporaryDirectory
    + __exit__(exc: exception, value: object, tb: object): void
    + cleanup(): void
}
}

namespace shutil {
class move {
    + src: String
    + dest: String
    + copy_function: Function
    + copy2_function: Function
    + ignore: List[String]
    + os.rename(src: String, dst: String): void
    + copytree(src: String, dst: String, symlinks: Boolean, ignore: Function[Directory, Files?]): void
}
}

namespace fnmatch {
class filter_files {
    + files: List[String]
    + pattern: String
    + match(files: List[String], pattern: String): void
}
}

namespace subprocess {
class call {
    + args: List[String]
    + shell: Boolean
    + timeout: Integer
    + check_output(): void
}
}

namespace json {
class dumps {
    + obj: Object
    + ensure_ascii: Boolean
    + check_circular: Boolean
    + allow_nan: Boolean
    + indent: Integer
    + sort_keys: Boolean
    + default(obj: Object): void
}
}
@enduml)

        # Generate and output the UML diagrams
        generate_uml_diagrams(repo, output_directory, branch_name, config)


@startuml
title GitHub UML Generator

class Data {
    -gitHubAccessToken: string
    -branchName: string
}

class Logger {
    +error(message: string)
    +info(message: string)
}

class TempFile {
    +mkdtemp(): string
}

class shutil {
    +rmtree(path: string)
}

class Config {
    -config: json
}

class Repo {
    +clone_repo(repo_url: string, temp_dir: string, access_token: string)
}

class UML {
    +generate_uml_diagrams(repo: Repo, output_dir: string, branch_name: string, config: Config)
}

class App {
    -git_repo_url: string
    -output_directory: string
    -github_access_token: string
    -branch_name: string
    -thub_access_token: string
    -logger: Logger
    -temp_dir: TempFile
    -shutil: shutil
    -config: Config
    -repo: Repo
    -uml: UML
    +main()
}

class Display {
    +show_error(error: string)
}

App --> Logger
App --> Data
App --> TempFile
App --> shutil
App --> Config
App --> Repo
App --> UML
App --> Display

Logger <-- App
Data <-- App
TempFile <-- App
shutil <-- App
Config <-- App
Repo <-- App
UML <-- App
Display <-- App

App : -git_repo_url
App : -output_directory
App : -github_access_token
App : -branch_name
App : -thub_access_token
App : -logger
App : -temp_dir
App : -shutil
App : -config
App : -repo
App : -uml
App : +main()

App --> Logger : -logger
Logger : -message
Display --> Logger : +error(error)

App --> Repo : -repo
Repo : +clone_repo(repo_url, temp_dir, access_token)

App --> UML : -uml
UML : +generate_uml_diagrams(repo, output_dir, branch_name, config)

App --> Config : -config
Config : -config
Config : +json.load(file)

App --> TempFile : -temp_dir
TempFile : +mkdtemp()

App --> shutil : -shutil
shutil : +rmtree(path)

Logger --> Display
TempFile --> App
shutil --> App
Config --> App
Repo --> App
UML --> App

@endumlt(repo, included_files, output_directory)




@startuml

class Repository {
    temp_dir: string
    config: Config
    tree(): Tree
    traverse(): Iterator
}

class Tree {
    traverse(): Iterator
}

class Config {
    include: str@startuml
  title UML for t(included_files, output_directory)
  
  class t {
    - final_output_paths: list
    - git_repo_url: string
    - temp_dir: string
    - logger: Logger
    
    + t(included_files, output_directory)
    - log_final_output_paths()
    - log_path(path)
    
    # generate_final_output_paths()
    + generate_final_output_paths()
    
    + run()
    
    + clean_up()
    
    + save_uml_diagrams()
  }
  
  class Logger {
    {static} # log(message: string)
  }
  
  t .. Logger
  
  class Exception {
    - error_msg: string
  }
  
  t .. Exception
  
  class File {
    - path: string
  }
  
  t --> File
  
  class Repository {
    - git_repo_url: string
  }
  
  t-o Repository
  
  class OutputPaths {
    - final_output_paths: list
  }
  
  t --> OutputPaths
  
  t ---> Exception
  Logger ---> Exception
  
  OutputPaths ..> File
  
  OutputPaths ..> Repository
  
  @enduml
@enduml
2024-01-21 17:12:36,282 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:12:36,282 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:12:36,282 - INFO - Skipping empty file: src/scripts/__init__.py
2024-01-21 17:12:36,283 - INFO - Processing file: src/scripts/execute_generate_uml.py
2024-01-21 17:12:36,283 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import json
import os
import requests
import logging
from logging import handlers
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure logging to write to a file
log_directory = '../../logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'execute_generate_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


# Configure logging
logging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))
# Configuration file path
config_file_path = os.path.join(cu
2024-01-21 17:12:36,284 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nimport json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(cu", 'max_tokens': 1024}}
2024-01-21 17:12:36,285 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:12:36,285 - DEBUG - send_request_headers.complete
2024-01-21 17:12:36,285 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:12:36,285 - DEBUG - send_request_body.complete
2024-01-21 17:12:36,286 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:12:42,263 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:12:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5881'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'3b51cb2fbffe448adeeafe1d3404eeeb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933e33394053bb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:12:42,264 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:12:42,264 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:12:42,264 - DEBUG - receive_response_body.complete
2024-01-21 17:12:42,264 - DEBUG - response_closed.started
2024-01-21 17:12:42,264 - DEBUG - response_closed.complete
2024-01-21 17:12:42,264 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:12:42,265 - INFO - Received response from OpenAI: rrent_dir, 'config.json')

# Get configuration from JSON file
with open(config_file_path, 'r') as config_file:
    config = json.loads(config_file.read())

# Define constants
OMDB_API_KEY = os.getenv('OMDB_API_KEY')
OMDB_API_BASE_URL = 'http://www.omdbapi.com/'


class Movie:
    '''
    A class representing a movie.
    Attributes:
        title (str): The title of the movie
        year (str): The year the movie was released
        genre (str): The genre of the movie
        plot (str): A brief overview of the movie's plot
    '''

    def __init__(self, title, year, genre, plot):
        self.title = title
        self.year = year
        self.genre = genre
        self.plot = plot

    def get_movie_info(self):
        '''
        Retrieves additional information about the movie from the OMDb API.
        Returns:
            movie_info (dict): Dictionary containing additional information about the movie
        '''
        movie_info = {}
        # Construct request URL with title, year, and api key
        url = '{}?t={}&y={}&apikey={}'.format(OMDB_API_BASE_URL, self.title, self.year, OMDB_API_KEY)
        # Make API request
        response = requests.get(url)
        # Convert response to JSON
        response_json = response.json()

        # Check if movie was found
        if response_json['Response'] == 'True':
            # Add additional information to the movie_info dictionary
            movie_info['Director'] = response_json['Director']
            movie_info['Runtime'] = response_json['Runtime']
            movie_info['imdbRating'] = response_json['imdbRating']
            movie_info['Metascore'] = response_json['Metascore']
        
        return movie_info


# Define functions
def read_config():
    '''
    Reads the configuration file and returns a dictionary.
    Returns:
        config (dict): Dictionary containing the configuration options
    '''
    with open(config_file_path, 'r') as config_file:
        config = json.loads(config_file.read())

    return config

def setup_logging():
    '''
    Configures logging for the application.
    '''
    # Create the directory if it doesn't exist
    os.makedirs(log_directory, exist_ok=True)  
    log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file w
2024-01-21 17:12:42,265 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

rrent_dir, 'config.json')

# Read configuration from the JSON file
with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

# Retrieve the GitHub access token from environment variables
github_token = os.getenv('GITHUB_PAT')

# Endpoint URL
url = 'http://127.0.0.1:5000/generate-uml'

# Headers
headers = {
    'Content-Type': 'application/json'
}

# Update the GitHub access token and local directory in the config data
config_data['gitHubAccessToken'] = github_token
config_data['local_dir'] = os.path.join(current_dir, '../..', 'output')

# Log the JSON data being sent in the request
logging.info(f'Sending JSON data to {url}:')
logging.info(json.dumps(config_data, indent=2))

try:
    # Make the POST request
    response = requests.post(url, headers=headers, json=config_data)

    # Log the response from the server
    logging.info(f'Response from server ({url}):')
    logging.info(f'Status Code: {response.status_code}')
    logging.info(f'Response Text: {response.text}')

    #
2024-01-21 17:12:42,266 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nrrent_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    #", 'max_tokens': 1024}}
2024-01-21 17:12:42,267 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:12:42,267 - DEBUG - send_request_headers.complete
2024-01-21 17:12:42,267 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:12:42,267 - DEBUG - send_request_body.complete
2024-01-21 17:12:42,267 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:12:45,740 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:12:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3402'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'bed483521af454e2c04b027d5cdebd02'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933e589b9753bb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:12:45,742 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:12:45,742 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:12:45,743 - DEBUG - receive_response_body.complete
2024-01-21 17:12:45,743 - DEBUG - response_closed.started
2024-01-21 17:12:45,744 - DEBUG - response_closed.complete
2024-01-21 17:12:45,744 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:12:45,746 - INFO - Received response from OpenAI:  Parse the response data as JSON
    response_data = response.json()

    # Check if the response was successful
    if response_data['success']:
        print('UML diagrams successfully generated!')
    else:
        print('Error generating UML diagrams.')
except requests.exceptions.RequestException as e:
    logging.error(f'Error making request to {url}: {e}')


@startuml
class Config:
    -config_file_path: string
    -current_dir: string
    -github_token: string
    -url: string
    -headers: map
    -config_data: map
    ..Getters and Setters..
    +readConfigFile(): void
    +getGitHubToken(): string
    +updateGitHubToken(): void
    +setLocalDir(): void

class Main:
    ..Properties..
    -config: Config
    ..Methods..
    +main(): void

class Request:
    -url: string
    -headers: map
    -config_data: map
    ..Getters and Setters..
    +makeRequest(): void
    +parseResponse(): void
    +checkResponseStatus(): void

Config -> Main: create
Main -> Request: makeRequest
Request -> Request: parseResponse
Request -> Request: checkResponseStatus
Request --> Main: return response success
Main --> Request: updateGitHubToken
Main --> Config: setLocalDir
Request <-- Main: update config data
Config <-- Main: updated config data
@enduml
2024-01-21 17:12:45,746 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

 Print the response from the server
    print(response.text)

    # Save the response to a file in the output directory
    output_dir = os.path.join(current_dir, '../..', 'output')
    os.makedirs(output_dir, exist_ok=True)
    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:
        json.dump(response.json(), output_file, indent=2)

except Exception as e:
    # Log any exceptions that occur
    logging.error(f'Error occurred: {str(e)}')
2024-01-21 17:12:45,748 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')", 'max_tokens': 1024}}
2024-01-21 17:12:45,749 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:12:45,750 - DEBUG - send_request_headers.complete
2024-01-21 17:12:45,750 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:12:45,750 - DEBUG - send_request_body.complete
2024-01-21 17:12:45,750 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:12:47,273 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:12:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1425'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'0c07f76be243e605e6082185af0d5fe5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84933e6e5a1153bb-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:12:47,275 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:12:47,278 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:12:47,279 - DEBUG - receive_response_body.complete
2024-01-21 17:12:47,280 - DEBUG - response_closed.started
2024-01-21 17:12:47,280 - DEBUG - response_closed.complete
2024-01-21 17:12:47,280 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:12:47,281 - INFO - Received response from OpenAI: 

@startuml

class Server {
    + response : string
    + getResponse() : string
}

class Output {
    + directory : string
    + makeDir() : void
    + saveFile() : void
}

class JSON {
    + json : string
    + convertToJson() : string
}

class ExceptionHandler {
    + exception : Exception
    + logException() : void
}


Server -- Output
Output -- JSON
Output -- ExceptionHandler

main {
    Server : print()
    Output : makeDir()
    Output : saveFile()
    ExceptionHandler : logException()
}

@enduml
2024-01-21 17:12:47,281 - INFO - UML code generated for src/scripts/execute_generate_uml.py: @startuml
title execute_generate_uml.py
rrent_dir, 'config.json')

# Get configuration from JSON file
with open(config_file_path, 'r') as config_file:
    config = json.loads(config_file.read())

# Define constants
OMDB_API_KEY = os.getenv('OMDB_API_KEY')
OMDB_API_BASE_URL = 'http://www.omdbapi.com/'


class Movie:
    '''
    A class representing a movie.
    Attributes:
        title (str): The title of the movie
        year (str): The year the movie was released
        genre (str): The genre of the movie
        plot (str): A brief overview of the movie's plot
    '''

    def __init__(self, title, year, genre, plot):
        self.title = title
        self.year = year
        self.genre = genre
        self.plot = plot

    def get_movie_info(self):
        '''
        Retrieves additional information about the movie from the OMDb API.
        Returns:
            movie_info (dict): Dictionary containing additional information about the movie
        '''
        movie_info = {}
        # Construct request URL with title, year, and api key
        url = '{}?t={}&y={}&apikey={}'.format(OMDB_API_BASE_URL, self.title, self.year, OMDB_API_KEY)
        # Make API request
        response = requests.get(url)
        # Convert response to JSON
        response_json = response.json()

        # Check if movie was found
        if response_json['Response'] == 'True':
            # Add additional information to the movie_info dictionary
            movie_info['Director'] = response_json['Director']
            movie_info['Runtime'] = response_json['Runtime']
            movie_info['imdbRating'] = response_json['imdbRating']
            movie_info['Metascore'] = response_json['Metascore']
        
        return movie_info


# Define functions
def read_config():
    '''
    Reads the configuration file and returns a dictionary.
    Returns:
        config (dict): Dictionary containing the configuration options
    '''
    with open(config_file_path, 'r') as config_file:
        config = json.loads(config_file.read())

    return config

def setup_logging():
    '''
    Configures logging for the application.
    '''
    # Create the directory if it doesn't exist
    os.makedirs(log_directory, exist_ok=True)  
    log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file wParse the response data as JSON
    response_data = response.json()

    # Check if the response was successful
    if response_data['success']:
        print('UML diagrams successfully generated!')
    else:
        print('Error generating UML diagrams.')
except requests.exceptions.RequestException as e:
    logging.error(f'Error making request to {url}: {e}')


@startuml
class Config:
    -config_file_path: string
    -current_dir: string
    -github_token: string
    -url: string
    -headers: map
    -config_data: map
    ..Getters and Setters..
    +readConfigFile(): void
    +getGitHubToken(): string
    +updateGitHubToken(): void
    +setLocalDir(): void

class Main:
    ..Properties..
    -config: Config
    ..Methods..
    +main(): void

class Request:
    -url: string
    -headers: map
    -config_data: map
    ..Getters and Setters..
    +makeRequest(): void
    +parseResponse(): void
    +checkResponseStatus(): void

Config -> Main: create
Main -> Request: makeRequest
Request -> Request: parseResponse
Request -> Request: checkResponseStatus
Request --> Main: return response success
Main --> Request: updateGitHubToken
Main --> Config: setLocalDir
Request <-- Main: update config data
Config <-- Main: updated config data
@enduml@startuml

class Server {
    + response : string
    + getResponse() : string
}

class Output {
    + directory : string
    + makeDir() : void
    + saveFile() : void
}

class JSON {
    + json : string
    + convertToJson() : string
}

class ExceptionHandler {
    + exception : Exception
    + logException() : void
}


Server -- Output
Output -- JSON
Output -- ExceptionHandler

main {
    Server : print()
    Output : makeDir()
    Output : saveFile()
    ExceptionHandler : logException()
}

@enduml
2024-01-21 17:12:47,282 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:12:47,282 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:12:47,282 - INFO - Generated file paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 17:12:47,283 - INFO - Final output paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 17:12:47,283 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:12:47,283 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:12:47,283 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:12:47,283 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:12:47,283 - INFO - Cleaning up temporary directory
2024-01-21 17:12:47,463 - INFO - 127.0.0.1 - - [21/Jan/2024 17:12:47] "POST /generate-uml HTTP/1.1" 200 -
2024-01-21 17:14:19,519 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 17:14:19,520 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 17:14:19,531 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-21 17:14:19,531 - INFO - [33mPress CTRL+C to quit[0m
2024-01-21 17:14:19,531 - INFO -  * Restarting with stat
2024-01-21 17:14:19,794 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 17:14:19,794 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 17:14:19,802 - WARNING -  * Debugger is active!
2024-01-21 17:14:19,810 - INFO -  * Debugger PIN: 139-904-016
2024-01-21 17:14:34,077 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-21 17:14:34,077 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-21 17:14:34,077 - INFO - Received local_dir: ./output
2024-01-21 17:14:34,078 - INFO - Received gitHubAccessToken: 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
2024-01-21 17:14:34,078 - INFO - Cleaning up temporary directory
2024-01-21 17:14:34,079 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 17:14:34,081 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-21 17:14:34,082 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpw6xzm5o4'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-21 17:14:43,504 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpw6xzm5o4'])'s unused stdout: 
2024-01-21 17:14:43,506 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 17:14:43,506 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpw6xzm5o4, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 17:14:43,512 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpw6xzm5o4, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 17:14:43,537 - DEBUG - Type of included_files: <class 'dict'>
2024-01-21 17:14:43,537 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 17:14:43,537 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-21 17:14:43,537 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 17:14:43,537 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-21 17:14:43,538 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-21 17:14:43,538 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-21 17:14:43,539 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-21 17:14:43,553 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-21 17:14:43,642 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106ecff90>
2024-01-21 17:14:43,642 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106ce9b50> server_hostname='api.openai.com' timeout=5.0
2024-01-21 17:14:43,684 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106de1490>
2024-01-21 17:14:43,684 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:14:43,684 - DEBUG - send_request_headers.complete
2024-01-21 17:14:43,685 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:14:43,685 - DEBUG - send_request_body.complete
2024-01-21 17:14:43,685 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:14:49,642 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:14:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5772'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'af011e00cb8933023f745543133dcb32'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=DfgOo6NPlkcQRaqlRj1wK_1hUU4A16Tzg9Ony0_3DsU-1705878889-1-AXvbaVJczJOmSIbxYGsOvjb/RSYcPbcpAyBk+lrTrH5ZAR1TxMTESkd1I57zeG1s82EAWey9PyYoC3WqDPsirDQ=; path=/; expires=Sun, 21-Jan-24 23:44:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=qERrt1cPC_hYSyUWbKjKUegQuxKD4f19fC4ah0hhaZA-1705878889601-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493414f6f9b4533-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:14:49,645 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:14:49,646 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:14:49,647 - DEBUG - receive_response_body.complete
2024-01-21 17:14:49,647 - DEBUG - response_closed.started
2024-01-21 17:14:49,647 - DEBUG - response_closed.complete
2024-01-21 17:14:49,647 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:14:49,651 - INFO - Received response from OpenAI: 
        if code == "":
            continue
        # Add file path to list
        file_paths.append(file_path)
        # Generate code using the OpenAI API
        generated_code += api.generate(code)
    # Write the generated code to a file in the output directory
    with open(os.path.join(output_directory, 'generated_code.py'), 'w') as f:
        f.write(generated_code)
    # Return the list of file paths
    return file_paths

# Call the function to generate code for the files in the current directory
files = {}  # Initialize an empty dictionary to store file paths and code
output_directory = 'output'
os.makedirs(output_directory, exist_ok=True)  # Create the output directory if it doesn't exist
generate_content(files, output_directory)



```puml
class OpenAIAPI {
    + generate(code: str): str
}

class logging {
    + info(msg: str): void
    + Formatter(fmt: str): void
}

class handlers.RotatingFileHandler {
    + __init__(filename: str, maxBytes: int, backupCount: int): void
}

class os {
    + makedirs(path: str, exist_ok: bool): void
    + path: os.path
...

class logger {
    + addHandler(handler: logging): void
    + setLevel(level: int): void
}

class code_to_uml {
    - log_directory: str
    - log_filename: str
    - log_handler: handlers.RotatingFileHandler
    - log_formatter: logging.Formatter
    - logger: logging
    - generated_code: str
    - file_paths: list

    + generate_content(files: dict, output_directory: str): list
}

os --> code_to_uml: imports
OpenAIAPI --> logger: creates instance
logging --> os: configures
handlers.RotatingFileHandler --> logging: writes to file
code_to_uml --> OpenAIAPI: calls generate()
files --> generate_content: input
code_to_uml --> os: creates output directory if not exist
file_paths --> generate_content: create list
generate_content --> OpenAIAPI: generate code
generate_content --> os: write to file
generate_content --> file_paths: returns list
```
2024-01-21 17:14:49,652 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-21 17:14:49,654 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-21 17:14:49,656 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:14:49,656 - DEBUG - send_request_headers.complete
2024-01-21 17:14:49,656 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:14:49,657 - DEBUG - send_request_body.complete
2024-01-21 17:14:49,657 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:14:53,834 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:14:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4009'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'5bdccd08f69803f209d2e5269811a7e6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84934174de1c4533-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:14:53,836 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:14:53,836 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:14:53,838 - DEBUG - receive_response_body.complete
2024-01-21 17:14:53,838 - DEBUG - response_closed.started
2024-01-21 17:14:53,838 - DEBUG - response_closed.complete
2024-01-21 17:14:53,839 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:14:53,840 - INFO - Received response from OpenAI: _paths})
@startuml

class CodeProcessor {
  -code: string
  -file_path: string
  -generated_code_for_file: string
  +CodeProcessor(code: string, file_path: string)

  #process_code(): void
  #generate_uml_code(): string
}

class Logger {
  -log: string
  +Logger()
  +info(message: string): void
  +error(message: string): void
}

class UMLGeneratorAPI {
  -generated_code: string
  -output_directory: string
  -final_output_path: string
  -file_paths: List<string>
  +UMLGeneratorAPI()
  +generate_from_code(code: string): string
  +save_generated_output(generated_code: string, output_directory: string): string
}

note top:Log the generated UML code

if(code.empty()){
  Logger::info("Skipping empty file: file_path")
  continue
}else{
  Logger::info("Processing file: file_path")
  UMLGeneratorAPI::generate_from_code(code)
  Logger::info("UML code generated for file_path: generated_code_for_file")
  if(generated_code_for_file == null or generated_code_for_file.contains("UML generation failed")){
    Logger::error("Failed to generate UML diagram for file_path")
    throw new ValueError("Failed to generate UML diagram for file_path")
  }
  
  generated_code += generated_code_for_file
  file_name = "{basename(file_path)}.puml"
  final_output_path = UMLGeneratorAPI::save_generated_output(generated_code_for_file, {join(output_directory, file_name)})
  file_paths.append(final_output_path)
}

Logger::info("Generated file paths: file_paths")

@enduml
2024-01-21 17:14:53,841 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-21 17:14:53,843 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-21 17:14:53,844 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:14:53,844 - DEBUG - send_request_headers.complete
2024-01-21 17:14:53,845 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:14:53,845 - DEBUG - send_request_body.complete
2024-01-21 17:14:53,845 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:14:55,721 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:14:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1810'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'60be8c5fa420a5685d40ff6944b2abe2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493418efb174533-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:14:55,722 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:14:55,722 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:14:55,722 - DEBUG - receive_response_body.complete
2024-01-21 17:14:55,722 - DEBUG - response_closed.started
2024-01-21 17:14:55,722 - DEBUG - response_closed.complete
2024-01-21 17:14:55,722 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:14:55,723 - INFO - Received response from OpenAI: 

---------------------------------------------

@startuml

class CodeGenerator {
    - start_path: str
    - file_extensions: List[str]
    - generated_code: str
    + generate_code()
    + __init__(start_path: str, file_extensions: List[str])
    + _get_file_paths(start_path: str, file_extensions: List[str]): List[str]
    + _generate_code(file_paths: List[str]): str
}

CodeGenerator "1" -- "*" File

package Generator {
    class File {
        - file_path: str
        + __init__(file_path: str)
        + get_file_path(): str
        + generate_code(): str
    }
}

CodeGenerator -- File : "1" start_path
CodeGenerator -- File : "1" file_extensions
CodeGenerator -- File : "*" generated_code 

@enduml
2024-01-21 17:14:55,723 - INFO - UML code generated for src/routes/code_to_uml.py: @startuml
title code_to_uml.py
if code == "":
            continue
        # Add file path to list
        file_paths.append(file_path)
        # Generate code using the OpenAI API
        generated_code += api.generate(code)
    # Write the generated code to a file in the output directory
    with open(os.path.join(output_directory, 'generated_code.py'), 'w') as f:
        f.write(generated_code)
    # Return the list of file paths
    return file_paths

# Call the function to generate code for the files in the current directory
files = {}  # Initialize an empty dictionary to store file paths and code
output_directory = 'output'
os.makedirs(output_directory, exist_ok=True)  # Create the output directory if it doesn't exist
generate_content(files, output_directory)



```puml
class OpenAIAPI {
    + generate(code: str): str
}

class logging {
    + info(msg: str): void
    + Formatter(fmt: str): void
}

class handlers.RotatingFileHandler {
    + __init__(filename: str, maxBytes: int, backupCount: int): void
}

class os {
    + makedirs(path: str, exist_ok: bool): void
    + path: os.path
...

class logger {
    + addHandler(handler: logging): void
    + setLevel(level: int): void
}

class code_to_uml {
    - log_directory: str
    - log_filename: str
    - log_handler: handlers.RotatingFileHandler
    - log_formatter: logging.Formatter
    - logger: logging
    - generated_code: str
    - file_paths: list

    + generate_content(files: dict, output_directory: str): list
}

os --> code_to_uml: imports
OpenAIAPI --> logger: creates instance
logging --> os: configures
handlers.RotatingFileHandler --> logging: writes to file
code_to_uml --> OpenAIAPI: calls generate()
files --> generate_content: input
code_to_uml --> os: creates output directory if not exist
file_paths --> generate_content: create list
generate_content --> OpenAIAPI: generate code
generate_content --> os: write to file
generate_content --> file_paths: returns list
```_paths})
@startuml

class CodeProcessor {
  -code: string
  -file_path: string
  -generated_code_for_file: string
  +CodeProcessor(code: string, file_path: string)

  #process_code(): void
  #generate_uml_code(): string
}

class Logger {
  -log: string
  +Logger()
  +info(message: string): void
  +error(message: string): void
}

class UMLGeneratorAPI {
  -generated_code: string
  -output_directory: string
  -final_output_path: string
  -file_paths: List<string>
  +UMLGeneratorAPI()
  +generate_from_code(code: string): string
  +save_generated_output(generated_code: string, output_directory: string): string
}

note top:Log the generated UML code

if(code.empty()){
  Logger::info("Skipping empty file: file_path")
  continue
}else{
  Logger::info("Processing file: file_path")
  UMLGeneratorAPI::generate_from_code(code)
  Logger::info("UML code generated for file_path: generated_code_for_file")
  if(generated_code_for_file == null or generated_code_for_file.contains("UML generation failed")){
    Logger::error("Failed to generate UML diagram for file_path")
    throw new ValueError("Failed to generate UML diagram for file_path")
  }
  
  generated_code += generated_code_for_file
  file_name = "{basename(file_path)}.puml"
  final_output_path = UMLGeneratorAPI::save_generated_output(generated_code_for_file, {join(output_directory, file_name)})
  file_paths.append(final_output_path)
}

Logger::info("Generated file paths: file_paths")

@enduml---------------------------------------------

@startuml

class CodeGenerator {
    - start_path: str
    - file_extensions: List[str]
    - generated_code: str
    + generate_code()
    + __init__(start_path: str, file_extensions: List[str])
    + _get_file_paths(start_path: str, file_extensions: List[str]): List[str]
    + _generate_code(file_paths: List[str]): str
}

CodeGenerator "1" -- "*" File

package Generator {
    class File {
        - file_path: str
        + __init__(file_path: str)
        + get_file_path(): str
        + generate_code(): str
    }
}

CodeGenerator -- File : "1" start_path
CodeGenerator -- File : "1" file_extensions
CodeGenerator -- File : "*" generated_code 

@enduml
2024-01-21 17:14:55,723 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:14:55,723 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:14:55,724 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-21 17:14:55,724 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-21 17:14:55,725 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-21 17:14:55,726 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:14:55,726 - DEBUG - send_request_headers.complete
2024-01-21 17:14:55,726 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:14:55,726 - DEBUG - send_request_body.complete
2024-01-21 17:14:55,726 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:15:02,747 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:15:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'6918'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'4867ee1bf4441180f1cba97f1852160b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493419aaa594533-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:15:02,749 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:15:02,749 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:15:02,750 - DEBUG - receive_response_body.complete
2024-01-21 17:15:02,751 - DEBUG - response_closed.started
2024-01-21 17:15:02,751 - DEBUG - response_closed.complete
2024-01-21 17:15:02,751 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:15:02,754 - INFO - Received response from OpenAI: 
        return repo
    except Exception as e:
        logger.error(f"Error cloning repository: {str(e)}")
        return None


def get_remote_commits(repo):
    commits = []
    for remote in repo.remotes:
        remote.fetch()
        for ref in repo.refs:
            if ref.remote_head == "origin/master":
                commits.append(ref.commit)

    return commits


def get_commit_data(repo, commit):
    commit_data = {}
    commit_data['hash'] = commit.hexsha
    commit_data['author'] = commit.author.name
    commit_data['date'] = commit.authored_datetime.strftime("%m/%d/%Y, %H:%M:%S")
    commit_data['message'] = commit.message
    commit_data['files'] = []

    # Get changed files in commit
    diff_index = commit.diff('HEAD~1')
    for diff in diff_index:
        commit_data['files'].append(diff.a_path)

    return commit_data


@startuml

class Git:
    + clone(repo_url, temp_dir, access_token) 
    + pull() 
    + add(path) 
    + commit(message) 
    + push() 
    + checkout(branch) 
    + diff(commit1, commit2) 

class Json:
    + read(file_path) 
    + write(data, file_path) 

class Os:
    + makedirs(path, exist_ok) 

class Logging:
    + basicConfig(**kwargs) 
    + getLogger(name) 
    + addHandler(handler) 
    + setLevel(level) 
    + warn(msg) 
    + warn(msg, *args)
    + error(msg) 
    + info(msg) 
    + debug(msg)

class handlers.StreamHandler():
    + flush() 
    + emit(record) 
    + flush() 

class handlers.RotatingFileHandler():
    + close() 

class handlers.TimedRotatingFileHandler():
    + close() 

class handlers.SocketHandler():
    + close() 

class handlers.DatagramHandler():
    + close() 

class handlers.SysLogHandler():
    + close() 

class handlers.NTEventLogHandler():
    + close() 

class handlers.HTTPHandler():
    + close() 

class handlers.BufferingHandler():
    + close() 

class Repo():
    + clone_from(repo_url, temp_dir) 
    + remotes() 
    + refs() 
    + pull() 

class Remote():
    + fetch()

class Ref():
    + commit() 

class DiffIndex():
    + diff(a_path)

class Diff():
    + a_path 

class Log_Handler():
    + setFormatter(log_formatter) 
    + emit(record) 

CommitData --> Diff
Diff --> DiffIndex
DiffIndex --> Commit 
Commit --> Ref 
Ref --> Repo
Repo --> Remote 
Remote --> Repo
Repo --> Git
Json --> Json
Os --> Os
Logging --> Logging
Handlers.StreamHandler --> Logging
Handlers.RotatingFileHandler --> Logging
Handlers.TimedRotatingFileHandler --> Logging
Handlers.SocketHandler --> Logging
Handlers.DatagramHandler --> Logging
Handlers.SysLogHandler --> Logging
Handlers.NTEventLogHandler --> Logging
Handlers.HTTPHandler --> Logging
Handlers.BufferingHandler --> Logging
Logging --> Log_Handler

@enduml
2024-01-21 17:15:02,755 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-21 17:15:02,757 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-21 17:15:02,758 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:15:02,759 - DEBUG - send_request_headers.complete
2024-01-21 17:15:02,759 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:15:02,759 - DEBUG - send_request_body.complete
2024-01-21 17:15:02,759 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:15:05,393 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:15:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2488'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'f74c7d02d50ce69aaffd9cb95b5b5fce'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849341c6ab604533-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:15:05,396 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:15:05,397 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:15:05,398 - DEBUG - receive_response_body.complete
2024-01-21 17:15:05,398 - DEBUG - response_closed.started
2024-01-21 17:15:05,398 - DEBUG - response_closed.complete
2024-01-21 17:15:05,398 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:15:05,400 - INFO - Received response from OpenAI:  if file.type == 'blob' and file.name not in ignore_list and (not include_list or file.name in include_list):
                 included_files[file.path] = file.data.decode('utf-8')

        return included_files
    
def display_code(code):
    for file_name in code:
        print(f"Displaying code for file: {file_name}")
        print('-' * 50)
        print(code[file_name])



@startuml

' Main class
class Main {
    - repo
    + retrieve_code(repo, branch_name)
    + display_code(code)
}

' Logger class
class Logger {
    + error(message)
    + info(message)
}

class Repo {
    + git
    + fetch()
    + checkout(branch_name)
}

class JsonConfig {
    - ignore_list
    - include_list
    + load_config(config_file_path)
}

class Code {
    + file_name
    + file_path
    + data
}

Main o--> Logger
Main o--> Repo
Main o--> JsonConfig
Main o--> Code
Repo o--> Git
JsonConfig o--> File
Code o.. code: includes

@enduml
2024-01-21 17:15:05,400 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-21 17:15:05,402 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-21 17:15:05,404 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:15:05,404 - DEBUG - send_request_headers.complete
2024-01-21 17:15:05,404 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:15:05,404 - DEBUG - send_request_body.complete
2024-01-21 17:15:05,405 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:15:08,064 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:15:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2567'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'34ee43b237c31f50c7a03852fb59e00e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849341d728064533-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:15:08,066 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:15:08,067 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:15:08,067 - DEBUG - receive_response_body.complete
2024-01-21 17:15:08,068 - DEBUG - response_closed.started
2024-01-21 17:15:08,068 - DEBUG - response_closed.complete
2024-01-21 17:15:08,068 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:15:08,069 - INFO - Received response from OpenAI: 

@startuml

class CodeRetriever {
    -include_list: List
    -ignore_list: List
    -included_files: Dict

    +__init__(include_list, ignore_list)
    +retrieve_code(path: str): Dict
}

class File {
    -path: str
    -abspath: str
}

class Logger {
    -log_level: int

    +__init__(log_level: str)
    +info(message: str)
    +warning(message: str)
    +error(message: str)
}

class FileNotFoundError
class ValueError

CodeRetriever --> include_list: List
CodeRetriever --> ignore_list: List
CodeRetriever --> included_files: Dict
CodeRetriever --> File
CodeRetriever --> Logger
CodeRetriever --> FileNotFoundError
CodeRetriever --> ValueError

File --> path: str
File --> abspath: str

Logger --> log_level: int
Logger --> info(message: str)
Logger --> warning(message: str)
Logger --> error(message: str)

CodeRetriever --> File
CodeRetriever --> Logger

@enduml
2024-01-21 17:15:08,069 - INFO - UML code generated for src/routes/retrieve_code.py: @startuml
title retrieve_code.py
return repo
    except Exception as e:
        logger.error(f"Error cloning repository: {str(e)}")
        return None


def get_remote_commits(repo):
    commits = []
    for remote in repo.remotes:
        remote.fetch()
        for ref in repo.refs:
            if ref.remote_head == "origin/master":
                commits.append(ref.commit)

    return commits


def get_commit_data(repo, commit):
    commit_data = {}
    commit_data['hash'] = commit.hexsha
    commit_data['author'] = commit.author.name
    commit_data['date'] = commit.authored_datetime.strftime("%m/%d/%Y, %H:%M:%S")
    commit_data['message'] = commit.message
    commit_data['files'] = []

    # Get changed files in commit
    diff_index = commit.diff('HEAD~1')
    for diff in diff_index:
        commit_data['files'].append(diff.a_path)

    return commit_data


@startuml

class Git:
    + clone(repo_url, temp_dir, access_token) 
    + pull() 
    + add(path) 
    + commit(message) 
    + push() 
    + checkout(branch) 
    + diff(commit1, commit2) 

class Json:
    + read(file_path) 
    + write(data, file_path) 

class Os:
    + makedirs(path, exist_ok) 

class Logging:
    + basicConfig(**kwargs) 
    + getLogger(name) 
    + addHandler(handler) 
    + setLevel(level) 
    + warn(msg) 
    + warn(msg, *args)
    + error(msg) 
    + info(msg) 
    + debug(msg)

class handlers.StreamHandler():
    + flush() 
    + emit(record) 
    + flush() 

class handlers.RotatingFileHandler():
    + close() 

class handlers.TimedRotatingFileHandler():
    + close() 

class handlers.SocketHandler():
    + close() 

class handlers.DatagramHandler():
    + close() 

class handlers.SysLogHandler():
    + close() 

class handlers.NTEventLogHandler():
    + close() 

class handlers.HTTPHandler():
    + close() 

class handlers.BufferingHandler():
    + close() 

class Repo():
    + clone_from(repo_url, temp_dir) 
    + remotes() 
    + refs() 
    + pull() 

class Remote():
    + fetch()

class Ref():
    + commit() 

class DiffIndex():
    + diff(a_path)

class Diff():
    + a_path 

class Log_Handler():
    + setFormatter(log_formatter) 
    + emit(record) 

CommitData --> Diff
Diff --> DiffIndex
DiffIndex --> Commit 
Commit --> Ref 
Ref --> Repo
Repo --> Remote 
Remote --> Repo
Repo --> Git
Json --> Json
Os --> Os
Logging --> Logging
Handlers.StreamHandler --> Logging
Handlers.RotatingFileHandler --> Logging
Handlers.TimedRotatingFileHandler --> Logging
Handlers.SocketHandler --> Logging
Handlers.DatagramHandler --> Logging
Handlers.SysLogHandler --> Logging
Handlers.NTEventLogHandler --> Logging
Handlers.HTTPHandler --> Logging
Handlers.BufferingHandler --> Logging
Logging --> Log_Handler

@endumlif file.type == 'blob' and file.name not in ignore_list and (not include_list or file.name in include_list):
                 included_files[file.path] = file.data.decode('utf-8')

        return included_files
    
def display_code(code):
    for file_name in code:
        print(f"Displaying code for file: {file_name}")
        print('-' * 50)
        print(code[file_name])



@startuml

' Main class
class Main {
    - repo
    + retrieve_code(repo, branch_name)
    + display_code(code)
}

' Logger class
class Logger {
    + error(message)
    + info(message)
}

class Repo {
    + git
    + fetch()
    + checkout(branch_name)
}

class JsonConfig {
    - ignore_list
    - include_list
    + load_config(config_file_path)
}

class Code {
    + file_name
    + file_path
    + data
}

Main o--> Logger
Main o--> Repo
Main o--> JsonConfig
Main o--> Code
Repo o--> Git
JsonConfig o--> File
Code o.. code: includes

@enduml@startuml

class CodeRetriever {
    -include_list: List
    -ignore_list: List
    -included_files: Dict

    +__init__(include_list, ignore_list)
    +retrieve_code(path: str): Dict
}

class File {
    -path: str
    -abspath: str
}

class Logger {
    -log_level: int

    +__init__(log_level: str)
    +info(message: str)
    +warning(message: str)
    +error(message: str)
}

class FileNotFoundError
class ValueError

CodeRetriever --> include_list: List
CodeRetriever --> ignore_list: List
CodeRetriever --> included_files: Dict
CodeRetriever --> File
CodeRetriever --> Logger
CodeRetriever --> FileNotFoundError
CodeRetriever --> ValueError

File --> path: str
File --> abspath: str

Logger --> log_level: int
Logger --> info(message: str)
Logger --> warning(message: str)
Logger --> error(message: str)

CodeRetriever --> File
CodeRetriever --> Logger

@enduml
2024-01-21 17:15:08,070 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:15:08,070 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:15:08,071 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-21 17:15:08,071 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-21 17:15:08,072 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-21 17:15:08,073 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:15:08,074 - DEBUG - send_request_headers.complete
2024-01-21 17:15:08,074 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:15:08,074 - DEBUG - send_request_body.complete
2024-01-21 17:15:08,074 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:15:08,208 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:15:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'60'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'f3ec9b574e6b2d04c4af36867e39254a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849341e7dde34533-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:15:08,209 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:15:08,209 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:15:08,209 - DEBUG - receive_response_body.complete
2024-01-21 17:15:08,209 - DEBUG - response_closed.started
2024-01-21 17:15:08,209 - DEBUG - response_closed.complete
2024-01-21 17:15:08,210 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:15:08,211 - INFO - Received response from OpenAI: 
2024-01-21 17:15:08,211 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-21 17:15:08,212 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-21 17:15:08,213 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:15:08,213 - DEBUG - send_request_headers.complete
2024-01-21 17:15:08,213 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:15:08,213 - DEBUG - send_request_body.complete
2024-01-21 17:15:08,213 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:15:17,457 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:15:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'9150'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'c61e444e1dcdcb6241773bcbb07dfb7d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849341e8bf334533-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:15:17,460 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:15:17,460 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:15:17,461 - DEBUG - receive_response_body.complete
2024-01-21 17:15:17,461 - DEBUG - response_closed.started
2024-01-21 17:15:17,462 - DEBUG - response_closed.complete
2024-01-21 17:15:17,462 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:15:17,463 - INFO - Received response from OpenAI: )  

 @startuml

class ConfigReader

class GithubManager {
  - thub_access_token
  - branch_name
  - git_repo_url
  - output_directory
  - github_access_token

  + clone_repo()
}

class Logger {
  + error()
  + info()
}

class TempFileManager {
  + mkdtemp()
  + rmtree()
}

class JsonLoader {
  + load()
}

' Main function
ConfigReader --> Logger : log error
ConfigReader --> TempFileManager : manage temp directory
TempFileManager --> GithubManager : clone repository
GithubManager --> JsonLoader : load config
JsonLoader --> ConfigReader : retrieve config

@enduml

The UML diagram for this code represents the following classes: ConfigReader, GithubManager, Logger, TempFileManager, and JsonLoader. 

ConfigReader class: This class is responsible for reading the configuration data and retrieving the required parameters.

GithubManager class: This class handles the cloning of the repository and uses the Github API to retrieve the required data. It also has private variables for storing the access token, branch name, repository URL, and output directory.

Logger class: This class is used for logging any errors or information during the UML generation process.

TempFileManager class: This class manages the temporary directory for generating the UML diagrams. It has methods for creating and deleting the temporary directory.

JsonLoader class: This class loads the config file from the specified location and provides the data to the ConfigReader class.

The main function in the code calls the ConfigReader class to retrieve the required parameters, which then uses the Logger class to log any errors. It also uses the TempFileManager class to manage the temporary directory and the GithubManager class to clone the repository. The GithubManager class, in turn, uses the JsonLoader class to load the config file.

The UML diagram for this code can be visualized as follows:

           <<Class>>         <<Class>>                   <<Class>>
      +---------+       +----------------+          +-------------------+
      | Config  |       | GithubManager  |          |       Logger      |
      | Reader  |       |   +------------+          |    +----+----+     |
      +---------+       |   | thub_access|          |    | error   |     |
          |             |   | _token     |  calls   |    | info    |     |
          | retrieve    |   | branch_name|<---------|----+---------+-----+
          | config.     |   | git_repo   |          | 
          | data       |   | _url       |          |
          +-------------+   | _output    |          |
                            | _directory |          |
                            +------------+          |
                                 |                   |
                    +-------------+                  |
                    |               |                |
                    |     +------------+             |
                    |     |  JsonLoader |             |
                    |     |  +---------+-------------+
             calls  +-----|---|  load config|      
                    |     |   +------------+
             returns     |
             some data   |
                    +------------+
                    |  |         |
                    |  v         v
         <<Class>>      |   <<Class>>
   +-----------------+  | +-------------------+
   | TempFileManager |  | | GithubApi         |
   |   +---------+   |  | | +---------------+ |    calls
   |   |          |   |  | | | clone_repo    |<-------------+
   |   | mkdtemp  |   |  | | +---------------+ |             |
   |   | rmtree   |   |  | +----------+--------+-------------+
   +---|-----------+   |               |
       +----------------+               |
                                         |
                             +-----------+
                             |
                             v
                     <<Class>>
                 +---------------+
                 | OutputManager |
                 +---------------+
2024-01-21 17:15:17,464 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-21 17:15:17,466 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-21 17:15:17,467 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:15:17,468 - DEBUG - send_request_headers.complete
2024-01-21 17:15:17,468 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:15:17,468 - DEBUG - send_request_body.complete
2024-01-21 17:15:17,468 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:15:20,575 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:15:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2967'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'ab1c713f418abe348e066e8451016600'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493422298104533-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:15:20,577 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:15:20,577 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:15:20,578 - DEBUG - receive_response_body.complete
2024-01-21 17:15:20,579 - DEBUG - response_closed.started
2024-01-21 17:15:20,579 - DEBUG - response_closed.complete
2024-01-21 17:15:20,579 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:15:20,582 - INFO - Received response from OpenAI: 

@startuml

class TraverseDirectories{
    - repo: Repository
    - temp_dir: String
    - config: Configuration
    + traverse_directories(repo, temp_dir, config): included_files
}

class Repository{
    + tree(): Tree
}

class Tree{
    + traverse(): Traverser
}

class Traverser{
    - current_item: item
    + next(): item
}

class Item{
    - type: String
    - path: String
}

class Configuration{
    - include: List<String>
}

class Logger{
    + debug(message: String)
    + info(message: String)
}

class GenerateContent{
    - output_directory: String
    + generate_content(included_files): final_output_paths
}

class IncludedFiles{
    - files: List<File>
    + add_file(file: File): void
}

class File{
    + path: String
    - content: String
    + read_content(): String
}

TraverseDirectories o--> Repository
TraverseDirectories o--> Configuration
TraverseDirectories "1..*" *--> IncludedFiles
TraverseDirectories "1" --> Logger

Traverser ..> Item

IncludedFiles o--> File
GenerateContent o--> IncludedFiles

@enduml
2024-01-21 17:15:20,582 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-21 17:15:20,585 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-21 17:15:20,586 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:15:20,587 - DEBUG - send_request_headers.complete
2024-01-21 17:15:20,587 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:15:20,587 - DEBUG - send_request_body.complete
2024-01-21 17:15:20,587 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:15:23,763 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:15:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3081'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'dfed526cf953b111324a0ce57c8c2411'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493423619a64533-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:15:23,765 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:15:23,765 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:15:23,766 - DEBUG - receive_response_body.complete
2024-01-21 17:15:23,766 - DEBUG - response_closed.started
2024-01-21 17:15:23,767 - DEBUG - response_closed.complete
2024-01-21 17:15:23,767 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:15:23,769 - INFO - Received response from OpenAI:  @enduml

 @startuml
 class UMLGenerator {
 - included_files: list
 - output_directory: string
 - git_repo_url: string
 - logger: logger

 + t(): list
 + generate_UML(): dict
}
UMLGenerator o--> string

class logger {
 + info(): void
 + error(): void
}
logger o-- string

class list {
 + append(): void
 + remove(): void
}

class dict {
 + get(): void
}

t --> included_files
t --> output_directory
t --> logger

logger --> included_files
logger --> output_directory

class shutil {
 + rmtree(): void
}

t --> shutil

included_files ..> list

UMLGenerator --> generate_UML
generate_UML --> logger
generate_UML --> git_repo_url
generate_UML --> final_output_paths
logger --> final_output_paths
git_repo_url --> final_output_paths

final_output_paths ..> list
dict --> git_repo_url
dict --> final_output_paths

generate_UML --> git_repo_url
generate_UML --> final_output_paths

final_output_paths ..> list
dict --> git_repo_url
dict --> final_output_paths

generate_UML --> git_repo_url
generate_UML --> final_output_paths

shutil --> temp_dir

final_output_paths --> included_files

class temp_dir {
 + remove(): void
}

shutil --> temp_dir

final_output_paths ..> temp_dir

@enduml
2024-01-21 17:15:23,769 - INFO - UML code generated for src/routes/uml_from_repo.py: @startuml
title uml_from_repo.py
)  

 @startuml

class ConfigReader

class GithubManager {
  - thub_access_token
  - branch_name
  - git_repo_url
  - output_directory
  - github_access_token

  + clone_repo()
}

class Logger {
  + error()
  + info()
}

class TempFileManager {
  + mkdtemp()
  + rmtree()
}

class JsonLoader {
  + load()
}

' Main function
ConfigReader --> Logger : log error
ConfigReader --> TempFileManager : manage temp directory
TempFileManager --> GithubManager : clone repository
GithubManager --> JsonLoader : load config
JsonLoader --> ConfigReader : retrieve config

@enduml
2024-01-21 17:15:23,769 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:15:23,770 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:15:23,770 - INFO - Skipping empty file: src/scripts/__init__.py
2024-01-21 17:15:23,771 - INFO - Processing file: src/scripts/execute_generate_uml.py
2024-01-21 17:15:23,771 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import json
import os
import requests
import logging
from logging import handlers
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure logging to write to a file
log_directory = '../../logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'execute_generate_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


# Configure logging
logging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))
# Configuration file path
config_file_path = os.path.join(cu
2024-01-21 17:15:23,773 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nimport json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(cu", 'max_tokens': 1024}}
2024-01-21 17:15:23,774 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:15:23,775 - DEBUG - send_request_headers.complete
2024-01-21 17:15:23,775 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:15:23,775 - DEBUG - send_request_body.complete
2024-01-21 17:15:23,776 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:15:24,096 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:15:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'228'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'ebba24801a07f15c5768f30da93eb4eb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493424a0b8a4533-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:15:24,098 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:15:24,098 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:15:24,099 - DEBUG - receive_response_body.complete
2024-01-21 17:15:24,100 - DEBUG - response_closed.started
2024-01-21 17:15:24,100 - DEBUG - response_closed.complete
2024-01-21 17:15:24,100 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:15:24,102 - INFO - Received response from OpenAI: rrent_dir, 'config.json')

# Load configuration file
with open(config_file
2024-01-21 17:15:24,102 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

rrent_dir, 'config.json')

# Read configuration from the JSON file
with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

# Retrieve the GitHub access token from environment variables
github_token = os.getenv('GITHUB_PAT')

# Endpoint URL
url = 'http://127.0.0.1:5000/generate-uml'

# Headers
headers = {
    'Content-Type': 'application/json'
}

# Update the GitHub access token and local directory in the config data
config_data['gitHubAccessToken'] = github_token
config_data['local_dir'] = os.path.join(current_dir, '../..', 'output')

# Log the JSON data being sent in the request
logging.info(f'Sending JSON data to {url}:')
logging.info(json.dumps(config_data, indent=2))

try:
    # Make the POST request
    response = requests.post(url, headers=headers, json=config_data)

    # Log the response from the server
    logging.info(f'Response from server ({url}):')
    logging.info(f'Status Code: {response.status_code}')
    logging.info(f'Response Text: {response.text}')

    #
2024-01-21 17:15:24,104 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nrrent_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    #", 'max_tokens': 1024}}
2024-01-21 17:15:24,105 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:15:24,106 - DEBUG - send_request_headers.complete
2024-01-21 17:15:24,106 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:15:24,106 - DEBUG - send_request_body.complete
2024-01-21 17:15:24,107 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:15:28,106 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:15:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3884'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'b61f01dfe146d9373ea9d59d0efd141f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493424c1dfd4533-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:15:28,108 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:15:28,109 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:15:28,110 - DEBUG - receive_response_body.complete
2024-01-21 17:15:28,111 - DEBUG - response_closed.started
2024-01-21 17:15:28,111 - DEBUG - response_closed.complete
2024-01-21 17:15:28,111 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:15:28,113 - INFO - Received response from OpenAI:  Check for successful response
    if response.status_code == 200:
        # Retrieve the UML data from the response
        uml_data = response.json()['uml']

        # Write the UML data to a file
        with open('diagram.puml', 'w') as uml_file:
            uml_file.write(uml_data)

        # Log success message
        logging.info('UML diagram successfully generated')

    else:
        # Log error message
        logging.error('UML diagram generation failed')

except requests.exceptions.RequestException as e:
    # Log error message
    logging.error(f'Error making POST request to {url}: {e}')
```

@startuml

### Package: UML Generator

class Main {
    - main()
}

class ConfigReader {
    - config_file_path : str
    - config_data : dict
    + read_config()
}

class EnvironmentManager {
    - github_token : str
    + get_github_token()
}

interface RequestHandler {
    + url : str
    + headers : dict
    + make_request()
}

class Logger {
    + log_info()
    + log_error()
}

### Package: Dependencies

class json
class os
class requests

Main --> ConfigReader : create_instance
Main --> EnvironmentManager : create_instance
Main --> RequestHandler : create_instance
Main --> Logger : create_instance

ConfigReader "1" o-left- Logger : log_info()
EnvironmentManager "1" o-left- Logger : log_info()

ConfigReader --> json : load()
EnvironmentManager ---> os : getenv()
RequestHandler ---> requests : post()
Logger -- RequestHandler : make_request()

@enduml
2024-01-21 17:15:28,113 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

 Print the response from the server
    print(response.text)

    # Save the response to a file in the output directory
    output_dir = os.path.join(current_dir, '../..', 'output')
    os.makedirs(output_dir, exist_ok=True)
    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:
        json.dump(response.json(), output_file, indent=2)

except Exception as e:
    # Log any exceptions that occur
    logging.error(f'Error occurred: {str(e)}')
2024-01-21 17:15:28,115 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')", 'max_tokens': 1024}}
2024-01-21 17:15:28,116 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:15:28,116 - DEBUG - send_request_headers.complete
2024-01-21 17:15:28,116 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:15:28,117 - DEBUG - send_request_body.complete
2024-01-21 17:15:28,117 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:15:29,375 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:15:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1183'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'4e194ddb91c4a8dc2d73cb200e77e84f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849342652d8b4533-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:15:29,376 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:15:29,376 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:15:29,376 - DEBUG - receive_response_body.complete
2024-01-21 17:15:29,376 - DEBUG - response_closed.started
2024-01-21 17:15:29,376 - DEBUG - response_closed.complete
2024-01-21 17:15:29,376 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:15:29,377 - INFO - Received response from OpenAI: 

@startuml
Class PrintResponse {
    - response
    - output_dir
    - current_dir
    - output_file
    
    + printResponse() : void
    + saveToFile() : void
    + logException() : void
}

PrintResponse --|> Exception

class Exception {
    - e
    
    + getExceptionStackTrace() : void
}

PrintResponse "1" --|> "1..*" Exception

@enduml
2024-01-21 17:15:29,377 - INFO - UML code generated for src/scripts/execute_generate_uml.py: @startuml
title execute_generate_uml.py
rrent_dir, 'config.json')

# Load configuration file
with open(config_fileCheck for successful response
    if response.status_code == 200:
        # Retrieve the UML data from the response
        uml_data = response.json()['uml']

        # Write the UML data to a file
        with open('diagram.puml', 'w') as uml_file:
            uml_file.write(uml_data)

        # Log success message
        logging.info('UML diagram successfully generated')

    else:
        # Log error message
        logging.error('UML diagram generation failed')

except requests.exceptions.RequestException as e:
    # Log error message
    logging.error(f'Error making POST request to {url}: {e}')
```

@startuml

### Package: UML Generator

class Main {
    - main()
}

class ConfigReader {
    - config_file_path : str
    - config_data : dict
    + read_config()
}

class EnvironmentManager {
    - github_token : str
    + get_github_token()
}

interface RequestHandler {
    + url : str
    + headers : dict
    + make_request()
}

class Logger {
    + log_info()
    + log_error()
}

### Package: Dependencies

class json
class os
class requests

Main --> ConfigReader : create_instance
Main --> EnvironmentManager : create_instance
Main --> RequestHandler : create_instance
Main --> Logger : create_instance

ConfigReader "1" o-left- Logger : log_info()
EnvironmentManager "1" o-left- Logger : log_info()

ConfigReader --> json : load()
EnvironmentManager ---> os : getenv()
RequestHandler ---> requests : post()
Logger -- RequestHandler : make_request()

@enduml@startuml
Class PrintResponse {
    - response
    - output_dir
    - current_dir
    - output_file
    
    + printResponse() : void
    + saveToFile() : void
    + logException() : void
}

PrintResponse --|> Exception

class Exception {
    - e
    
    + getExceptionStackTrace() : void
}

PrintResponse "1" --|> "1..*" Exception

@enduml
2024-01-21 17:15:29,378 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:15:29,378 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:15:29,378 - INFO - Generated file paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 17:15:29,378 - INFO - Final output paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 17:15:29,379 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:15:29,379 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:15:29,379 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:15:29,379 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:15:29,379 - INFO - Cleaning up temporary directory
2024-01-21 17:15:29,546 - INFO - 127.0.0.1 - - [21/Jan/2024 17:15:29] "POST /generate-uml HTTP/1.1" 200 -
2024-01-21 17:26:12,954 - INFO -  * Detected change in '/Users/preston/Documents/gitRepos/diagrammr/src/openai_api.py', reloading
2024-01-21 17:26:13,016 - INFO -  * Restarting with stat
2024-01-21 17:26:13,290 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 17:26:13,291 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 17:26:13,299 - WARNING -  * Debugger is active!
2024-01-21 17:26:13,305 - INFO -  * Debugger PIN: 139-904-016
2024-01-21 17:26:19,009 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 17:26:19,010 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 17:26:19,020 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-21 17:26:19,020 - INFO - [33mPress CTRL+C to quit[0m
2024-01-21 17:26:19,020 - INFO -  * Restarting with stat
2024-01-21 17:26:19,304 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 17:26:19,305 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 17:26:19,313 - WARNING -  * Debugger is active!
2024-01-21 17:26:19,318 - INFO -  * Debugger PIN: 139-904-016
2024-01-21 17:26:21,624 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-21 17:26:21,624 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-21 17:26:21,624 - INFO - Received local_dir: ./output
2024-01-21 17:26:21,624 - INFO - Received gitHubAccessToken: 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
2024-01-21 17:26:21,625 - INFO - Cleaning up temporary directory
2024-01-21 17:26:21,626 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 17:26:21,628 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-21 17:26:21,628 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpm0_p_ycr'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-21 17:26:26,413 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpm0_p_ycr'])'s unused stdout: 
2024-01-21 17:26:26,415 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 17:26:26,415 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpm0_p_ycr, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 17:26:26,424 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpm0_p_ycr, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 17:26:26,447 - DEBUG - Type of included_files: <class 'dict'>
2024-01-21 17:26:26,447 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 17:26:26,447 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-21 17:26:26,448 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 17:26:26,448 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-21 17:26:26,448 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-21 17:26:26,448 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-21 17:26:26,449 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-21 17:26:26,464 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-21 17:26:26,552 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105b92190>
2024-01-21 17:26:26,552 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105a95b50> server_hostname='api.openai.com' timeout=5.0
2024-01-21 17:26:26,577 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105eba590>
2024-01-21 17:26:26,577 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:26:26,578 - DEBUG - send_request_headers.complete
2024-01-21 17:26:26,578 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:26:26,578 - DEBUG - send_request_body.complete
2024-01-21 17:26:26,578 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:26:30,479 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:26:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3808'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'362308bf558fcc2a91aa9e7b0f774805'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=7vvUZQmxdU1EqdMz8GzZEPFHlv3rqqlev26xuhZjfLk-1705879590-1-ATfuGmN8itpiDPaOmAZLyAbcx/WHT1lY1YhTKuz1ktkFGAtH2tnuVrKBQJYFdsGmb7vVCcDz+q2IeyyXC9s8BFo=; path=/; expires=Sun, 21-Jan-24 23:56:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=pRxgH.BzVoPVZrFNpbr9GWF1eOKkrXoZANyRJ2SJKMY-1705879590519-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849352788e9cadad-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:26:30,482 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:26:30,483 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:26:30,483 - DEBUG - receive_response_body.complete
2024-01-21 17:26:30,484 - DEBUG - response_closed.started
2024-01-21 17:26:30,484 - DEBUG - response_closed.complete
2024-01-21 17:26:30,484 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:26:30,487 - INFO - Received response from OpenAI: 
        if code.strip() == "":
            logging.warning(f"Empty code found in file: {file_path}")
            continue
        # Add the file path to the list
        file_paths.append(file_path)
        # Generate OpenAI API output
        output = api.generate(code)
        # Append the output to the generated code
        generated_code += output
    # Write the generated code to a file
    output_file = os.path.join(output_directory, "generated_code.txt")
    with open(output_file, "w") as f:
        f.write(generated_code)

# Create a list of file paths
files = {
    'code/file1.py': 'x = 5\ny = x*2\nprint(y)',
    'code/file2.py': '# This is a comment\nx = 3.14\ny = x*2\nprint(y)'
} 
# Specify the output directory
output_directory = 'output'
# Generate the content from the files
generate_content(files, output_directory)

@startuml
class OpenAIAPI {
    +generate(code)
}

class logging
class handlers

OpenAIAPI --> logging
handlers <|-- RotatingFileHandler
logging <|-- handlers
RotatingFileHandler --> logging
class Logger {
    -log_handler : RotatingFileHandler
    -log_formatter : logging.Formatter
    +getLogger()
    +log(message)
}

OpenAIAPI --> Logger
Logger --> logging

class CodeToUML {
    +generate_content(files, output_directory)
}

CodeToUML --> logging
CodeToUML --> OpenAIAPI
CodeToUML --> Os
CodeToUML --> Logger
CodeToUML --> FileHandler
CodeToUML --> Formatter
CodeToUML --> OutputFile

note left of CodeToUML: CodeToUML.py

@enduml
2024-01-21 17:26:30,489 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-21 17:26:30,491 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-21 17:26:30,492 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:26:30,492 - DEBUG - send_request_headers.complete
2024-01-21 17:26:30,492 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:26:30,493 - DEBUG - send_request_body.complete
2024-01-21 17:26:30,493 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:26:33,793 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:26:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3209'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'358e13f48cc45c508c9094040688f9bd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935290feaaadad-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:26:33,794 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:26:33,795 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:26:33,796 - DEBUG - receive_response_body.complete
2024-01-21 17:26:33,796 - DEBUG - response_closed.started
2024-01-21 17:26:33,796 - DEBUG - response_closed.complete
2024-01-21 17:26:33,797 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:26:33,798 - INFO - Received response from OpenAI: _paths})

      
```
@startuml

class UMLGeneratorLogger {
    -logger: Logger
    +info(message: String)
    +error(message: String)
}

class UMLGenerator {
    -api: CodeToUMLGeneratorAPI
    -logging: UMLGeneratorLogger
    -file_paths: List<String>
    -generated_code: String
    -generated_code_for_file: String
    -file_name: String
    -final_output_path: String
    -output_directory: String
    +create(file_paths: List<String>, output_directory: String)
    +execute()
}

class CodeToUMLGeneratorAPI {
    -generator: UMLGenerator
    -code: String
    +generate_from_code(code: String): String
    +save_generated_output(generated_code: String, output_path: String): String
}

UMLGenerator -right-> UMLGeneratorLogger
UMLGenerator -down-> CodeToUMLGeneratorAPI

CodeToUMLGeneratorAPI --> CodeToUMLGeneratorLogger

note right of UMLGenerator: main function

if not code.string()\n  logging.info()\n  continue\nlogging.info()\n  generated_code_for_file = api.generate_from_code()\nif not generated_code_for_file\n  raise ValueError()\ngenerated_code += generated_code_for_file\nfile_name = f"{os.path.basename(file_path)}\nfinal_output_path = api.save_generated_output()\nlogging.info()\nfile_paths.append()\nlogging.info()\ncontinue

@enduml 
```
2024-01-21 17:26:33,799 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-21 17:26:33,800 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-21 17:26:33,801 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:26:33,801 - DEBUG - send_request_headers.complete
2024-01-21 17:26:33,801 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:26:33,802 - DEBUG - send_request_body.complete
2024-01-21 17:26:33,802 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:26:34,595 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:26:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'726'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'c96d522ddeeb6aed9e75764bc76b284f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849352a5abbdadad-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:26:34,599 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:26:34,599 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:26:34,600 - DEBUG - receive_response_body.complete
2024-01-21 17:26:34,600 - DEBUG - response_closed.started
2024-01-21 17:26:34,600 - DEBUG - response_closed.complete
2024-01-21 17:26:34,600 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:26:34,602 - INFO - Received response from OpenAI: 

![UML diagram for generate_code function](https://imgur.com/KI9mB23.png)


@startuml
class Generator {
  - file_paths: list
  - generated_code: string
  + __init__(paths)
  + generate_code()
}

class File {
}

Generator --> File
@enduml 
2024-01-21 17:26:34,603 - INFO - UML code generated for src/routes/code_to_uml.py: @startuml
title code_to_uml.py
if code.strip() == "":
            logging.warning(f"Empty code found in file: {file_path}")
            continue
        # Add the file path to the list
        file_paths.append(file_path)
        # Generate OpenAI API output
        output = api.generate(code)
        # Append the output to the generated code
        generated_code += output
    # Write the generated code to a file
    output_file = os.path.join(output_directory, "generated_code.txt")
    with open(output_file, "w") as f:
        f.write(generated_code)

# Create a list of file paths
files = {
    'code/file1.py': 'x = 5\ny = x*2\nprint(y)',
    'code/file2.py': '# This is a comment\nx = 3.14\ny = x*2\nprint(y)'
} 
# Specify the output directory
output_directory = 'output'
# Generate the content from the files
generate_content(files, output_directory)

@startuml
class OpenAIAPI {
    +generate(code)
}

class logging
class handlers

OpenAIAPI --> logging
handlers <|-- RotatingFileHandler
logging <|-- handlers
RotatingFileHandler --> logging
class Logger {
    -log_handler : RotatingFileHandler
    -log_formatter : logging.Formatter
    +getLogger()
    +log(message)
}

OpenAIAPI --> Logger
Logger --> logging

class CodeToUML {
    +generate_content(files, output_directory)
}

CodeToUML --> logging
CodeToUML --> OpenAIAPI
CodeToUML --> Os
CodeToUML --> Logger
CodeToUML --> FileHandler
CodeToUML --> Formatter
CodeToUML --> OutputFile

note left of CodeToUML: CodeToUML.py

@enduml_paths})

      
```
@startuml

class UMLGeneratorLogger {
    -logger: Logger
    +info(message: String)
    +error(message: String)
}

class UMLGenerator {
    -api: CodeToUMLGeneratorAPI
    -logging: UMLGeneratorLogger
    -file_paths: List<String>
    -generated_code: String
    -generated_code_for_file: String
    -file_name: String
    -final_output_path: String
    -output_directory: String
    +create(file_paths: List<String>, output_directory: String)
    +execute()
}

class CodeToUMLGeneratorAPI {
    -generator: UMLGenerator
    -code: String
    +generate_from_code(code: String): String
    +save_generated_output(generated_code: String, output_path: String): String
}

UMLGenerator -right-> UMLGeneratorLogger
UMLGenerator -down-> CodeToUMLGeneratorAPI

CodeToUMLGeneratorAPI --> CodeToUMLGeneratorLogger

note right of UMLGenerator: main function

if not code.string()\n  logging.info()\n  continue\nlogging.info()\n  generated_code_for_file = api.generate_from_code()\nif not generated_code_for_file\n  raise ValueError()\ngenerated_code += generated_code_for_file\nfile_name = f"{os.path.basename(file_path)}\nfinal_output_path = api.save_generated_output()\nlogging.info()\nfile_paths.append()\nlogging.info()\ncontinue

@enduml 
```![UML diagram for generate_code function](https://imgur.com/KI9mB23.png)


@startuml
class Generator {
  - file_paths: list
  - generated_code: string
  + __init__(paths)
  + generate_code()
}

class File {
}

Generator --> File
@enduml
2024-01-21 17:26:34,603 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:26:34,604 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:26:34,605 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-21 17:26:34,605 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-21 17:26:34,607 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-21 17:26:34,608 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:26:34,609 - DEBUG - send_request_headers.complete
2024-01-21 17:26:34,610 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:26:34,610 - DEBUG - send_request_body.complete
2024-01-21 17:26:34,610 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:26:38,982 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:26:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4242'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'90340b3358b22e4b6533d7bfa5bd4bcb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849352aab8a0adad-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:26:38,983 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:26:38,984 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:26:38,985 - DEBUG - receive_response_body.complete
2024-01-21 17:26:38,985 - DEBUG - response_closed.started
2024-01-21 17:26:38,986 - DEBUG - response_closed.complete
2024-01-21 17:26:38,986 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:26:38,989 - INFO - Received response from OpenAI: 
        # Get the latest commit hash
        head_commit = repo.head.object.hexsha
        logger.info(f"Latest commit hash: {head_commit}")
        
        # Create a JSON file to store the commit hash
        commit_hash_file = os.path.join(temp_dir, 'head_commit.json')
        with open(commit_hash_file, 'w+') as f:
            json.dump({'commit_hash': head_commit}, f)
        logger.info(f"Stored latest commit hash in file: {commit_hash_file}")
        
        return repo
    
    except git.exc.GitCommandError as e:
        logger.error(f"Failed to clone repository: {repo_url}")
        logger.error(f"Error message: {e}")
        return None


# UML Diagram:

@startuml

class Git {
    +Repo clone_from(repo_url, temp_dir)
    +head {object}
}

class logging {
    +handlers
    +handlers.RotatingFileHandler(log_filename, maxBytes, backupCount)
    +handlers.RotatingFileHandler.setFormatter(log_formatter)
}

class os {
    +makedirs(log_directory, exist_ok)
    +path
}

class json {
    +open(commit_hash_file, mode)
    +dump(data, f)
}

class Repository {
    +url
    +access_token
}

class Logger {
    +info(message)
    +error(message)
}


Repository --> Git
Repository --> Logger
Logger --> logging
logging --> handlers
logging --> format
Git --> checkout
checkout --> head
head --> object
logging --> os
os --> makedirs
os --> path
logging --> json
json --> open
open --> dump
Logger --> access_token
access_token --> url
access_token --> temp_dir
Repository --> temp_dir
Git --> repo
Logger --> repo

@enduml
2024-01-21 17:26:38,990 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-21 17:26:38,991 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-21 17:26:38,992 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:26:38,993 - DEBUG - send_request_headers.complete
2024-01-21 17:26:38,993 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:26:38,994 - DEBUG - send_request_body.complete
2024-01-21 17:26:38,994 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:26:45,561 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:26:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'6484'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'5bc695fc375956f68b3254fb8b91859f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849352c62e24adad-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:26:45,565 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:26:45,570 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:26:45,571 - DEBUG - receive_response_body.complete
2024-01-21 17:26:45,574 - DEBUG - response_closed.started
2024-01-21 17:26:45,575 - DEBUG - response_closed.complete
2024-01-21 17:26:45,575 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:26:45,577 - INFO - Received response from OpenAI:  if file.name not in ignore_list and (file.name.endswith('.py') or file.name.endswith('.ipynb')):  # Only include Python and Jupyter Notebook files
                 included_files[file.name] = file.decoded_content.decode('utf-8')

        # Loop through the list of included files and extract code from them
        code_snippets = {}
        for file_path, code in included_files.items():
            if file_path.endswith('.py'):
                for node in ast.walk(ast.parse(code)):
                    if isinstance(node, ast.FunctionDef):
                        code_snippets[node.name] = ast.get_source_segment(code, node)
        code_snippets = [ast.get_source_segment(code, node).strip() for code in code_snippets.values()]

        # Process the code snippets
        processed = [c.strip() for c in code_snippets if c]

def
```plantuml
@startuml

class Repo {
    - url : string
    - files : list

    + clone() : bool
    + fetch() : bool
    + checkout(branch_name: string) : bool
}

class Logger {
    + error(message: string) : void
    + info(message: string) : void
}

class Config {
    - ignore_list: list
    - include_list: list
}

class File {
    - name: string
    - decoded_content: string
    + fetch() : string
}

class CodeSnippet {
    - path: string
    - code: string
    - processed_code: string
    + extract_code() : string
    + process_code() : string
}

class Exception {
    - message: string
}

class ValueError {
    - message: string
}

class RetrieveCode {
    - repo: Repo
    - branch_name: string
    - config_file_path: string
    - config: Config

    + retrieve_code(repo: Repo, branch_name: string) : void
}

class ConfigFile {
    - path: string
    - json_data: json

    + load() : json
}

class ASTModule {
    - code: string

    + walk(node: ASTNode) : void
    + get_source_segment(code: string, node: ASTNode) : string
}

class ASTNode {
    - type: string
}

class DiagnosticPrint {
    - branch_name: string

    + print() : void
}

class Main {
    + main() : void
}

Logger --> Exception
Logger --> ValueError

Repo --> Exception
Repo --> ValueError

Config --> Exception
Config --> ValueError

File --> Exception
File --> ValueError

CodeSnippet --> Exception
CodeSnippet --> ValueError

ASTModule --> Exception
ASTModule --> ValueError

Logger --> RetrieveCode
Repo --> RetrieveCode
ConfigFile --> RetrieveCode
DiagnosticPrint --> RetrieveCode
ASTModule --> RetrieveCode

@enduml
```

Note: Some classes and methods in the code were not explicitly declared but have been included in the diagram for completeness and clarity.
2024-01-21 17:26:45,579 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-21 17:26:45,580 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-21 17:26:45,581 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:26:45,582 - DEBUG - send_request_headers.complete
2024-01-21 17:26:45,582 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:26:45,582 - DEBUG - send_request_body.complete
2024-01-21 17:26:45,582 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:26:49,007 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:26:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3309'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'd63245a0532cf836292cfef91724b9ec'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849352ef4f64adad-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:26:49,008 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:26:49,008 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:26:49,009 - DEBUG - receive_response_body.complete
2024-01-21 17:26:49,009 - DEBUG - response_closed.started
2024-01-21 17:26:49,009 - DEBUG - response_closed.complete
2024-01-21 17:26:49,009 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:26:49,010 - INFO - Received response from OpenAI: 

@startuml

class RetrievalManager {
    # include_list: list<String>
    # ignore_list: list<String>
    # logger: Logger
    # included_files: dict<String, String>

    + __init__(include_list: list<String>, ignore_list: list<String>, logger: Logger)
    + retrieve_files() : dict<String, String>

}

class Logger {
    - level: int
    - format: String

    + __init__(level: int = 0, format: String = "%(asctime)s - %(levelname)s - %(message)s")
    + info(message: String) : void
    + warning(message: String) : void
    + error(message: String) : void
}

class File {
    # path: String
    # abspath: String

    + __init__(path: String, abspath: String)
    + endswith(ext: String) : boolean

}

RetrievalManager o-- Logger
RetrievalManager *-- File

note top of RetrievalManager
    include_list: list<String> - The list of file extensions that will be included
    ignore_list: list<String> - The list of files that will be ignored
    logger: Logger - The logger used to record events
    included_files: dict<String, String> - The dictionary of included files and their contents
end note

note top of Logger
    level: int - The logging level
    format: String - The format of the logging messages
end note

note top of File
    path: String - The path of the file
    abspath: String - The absolute path of the file
end note

@enduml
2024-01-21 17:26:49,011 - INFO - UML code generated for src/routes/retrieve_code.py: @startuml
title retrieve_code.py
# Get the latest commit hash
        head_commit = repo.head.object.hexsha
        logger.info(f"Latest commit hash: {head_commit}")
        
        # Create a JSON file to store the commit hash
        commit_hash_file = os.path.join(temp_dir, 'head_commit.json')
        with open(commit_hash_file, 'w+') as f:
            json.dump({'commit_hash': head_commit}, f)
        logger.info(f"Stored latest commit hash in file: {commit_hash_file}")
        
        return repo
    
    except git.exc.GitCommandError as e:
        logger.error(f"Failed to clone repository: {repo_url}")
        logger.error(f"Error message: {e}")
        return None


# UML Diagram:

@startuml

class Git {
    +Repo clone_from(repo_url, temp_dir)
    +head {object}
}

class logging {
    +handlers
    +handlers.RotatingFileHandler(log_filename, maxBytes, backupCount)
    +handlers.RotatingFileHandler.setFormatter(log_formatter)
}

class os {
    +makedirs(log_directory, exist_ok)
    +path
}

class json {
    +open(commit_hash_file, mode)
    +dump(data, f)
}

class Repository {
    +url
    +access_token
}

class Logger {
    +info(message)
    +error(message)
}


Repository --> Git
Repository --> Logger
Logger --> logging
logging --> handlers
logging --> format
Git --> checkout
checkout --> head
head --> object
logging --> os
os --> makedirs
os --> path
logging --> json
json --> open
open --> dump
Logger --> access_token
access_token --> url
access_token --> temp_dir
Repository --> temp_dir
Git --> repo
Logger --> repo

@endumlif file.name not in ignore_list and (file.name.endswith('.py') or file.name.endswith('.ipynb')):  # Only include Python and Jupyter Notebook files
                 included_files[file.name] = file.decoded_content.decode('utf-8')

        # Loop through the list of included files and extract code from them
        code_snippets = {}
        for file_path, code in included_files.items():
            if file_path.endswith('.py'):
                for node in ast.walk(ast.parse(code)):
                    if isinstance(node, ast.FunctionDef):
                        code_snippets[node.name] = ast.get_source_segment(code, node)
        code_snippets = [ast.get_source_segment(code, node).strip() for code in code_snippets.values()]

        # Process the code snippets
        processed = [c.strip() for c in code_snippets if c]

def
```plantuml
@startuml

class Repo {
    - url : string
    - files : list

    + clone() : bool
    + fetch() : bool
    + checkout(branch_name: string) : bool
}

class Logger {
    + error(message: string) : void
    + info(message: string) : void
}

class Config {
    - ignore_list: list
    - include_list: list
}

class File {
    - name: string
    - decoded_content: string
    + fetch() : string
}

class CodeSnippet {
    - path: string
    - code: string
    - processed_code: string
    + extract_code() : string
    + process_code() : string
}

class Exception {
    - message: string
}

class ValueError {
    - message: string
}

class RetrieveCode {
    - repo: Repo
    - branch_name: string
    - config_file_path: string
    - config: Config

    + retrieve_code(repo: Repo, branch_name: string) : void
}

class ConfigFile {
    - path: string
    - json_data: json

    + load() : json
}

class ASTModule {
    - code: string

    + walk(node: ASTNode) : void
    + get_source_segment(code: string, node: ASTNode) : string
}

class ASTNode {
    - type: string
}

class DiagnosticPrint {
    - branch_name: string

    + print() : void
}

class Main {
    + main() : void
}

Logger --> Exception
Logger --> ValueError

Repo --> Exception
Repo --> ValueError

Config --> Exception
Config --> ValueError

File --> Exception
File --> ValueError

CodeSnippet --> Exception
CodeSnippet --> ValueError

ASTModule --> Exception
ASTModule --> ValueError

Logger --> RetrieveCode
Repo --> RetrieveCode
ConfigFile --> RetrieveCode
DiagnosticPrint --> RetrieveCode
ASTModule --> RetrieveCode

@enduml
2024-01-21 17:26:49,012 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:26:49,012 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:26:49,013 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-21 17:26:49,013 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-21 17:26:49,015 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-21 17:26:49,016 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:26:49,016 - DEBUG - send_request_headers.complete
2024-01-21 17:26:49,016 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:26:49,016 - DEBUG - send_request_body.complete
2024-01-21 17:26:49,017 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:26:54,352 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:26:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5234'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'e74a8e10e327dcea7fa4b6a3a12d6eb4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935304bec1adad-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:26:54,354 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:26:54,355 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:26:54,356 - DEBUG - receive_response_body.complete
2024-01-21 17:26:54,357 - DEBUG - response_closed.started
2024-01-21 17:26:54,357 - DEBUG - response_closed.complete
2024-01-21 17:26:54,357 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:26:54,359 - INFO - Received response from OpenAI: t_repo = clone_repo(git_repo_url, output_directory)  # Clone the repository to the output directory  
    code_files = retrieve_code(git_repo)  # Retrieve code files from the repository
    for file in code_files:
        full_path = os.path.join(output_directory, file)
        uml_content = generate_content(full_path)  # Generate the UML content from the code file
        with open(full_path + '.puml', 'w') as uml_file:  # Create a .puml file for the UML content
            uml_file.write(uml_content)
            logger.info('Created .puml file for {}'.format(file))

@startuml
class UMLRepository {
    - log_directory : string
    - log_filename : string
    - log_handler : object
    - log_formatter : object
    - logger : object
    - git_repo : object
    - output_directory : string
    - code_files : list

    + process_request(data)
}

class Clone {
    - git_repo_url : string
    - output_directory : string
    - git : object

    + clone_repo(git_repo_url, output_directory)
}

class RetrieveCode {
    - git_repo : object
    - code_files : list

    + retrieve_code(git_repo)
}

class CodeToUML {
    - full_path : string
    - uml_content : string
    - uml_file : object

    + generate_content(full_path)
}

UMLRepository "1" *-- "1" Clone : uses
UMLRepository "1" *-- "1" RetrieveCode : uses
UMLRepository "1" *-- "1" CodeToUML : uses

Clone "1" *-- "1" git : uses

RetrieveCode "1" *-- "1" git_repo : holds
RetrieveCode "1" *-- "*" code_files : contains

CodeToUML "1" *-- "1" uml_file : uses

note left: Configures logging system\nand creates log file
Note top: process_request is the main function\nthat handles the entire process
Note top: Generates the .puml file\nfor the UML content

@enduml
2024-01-21 17:26:54,360 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-21 17:26:54,362 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-21 17:26:54,364 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:26:54,364 - DEBUG - send_request_headers.complete
2024-01-21 17:26:54,364 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:26:54,365 - DEBUG - send_request_body.complete
2024-01-21 17:26:54,365 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:27:00,240 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:27:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5768'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'c6501b3966f29fe44afe2b155110a372'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849353262a5cadad-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:27:00,242 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:27:00,243 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:27:00,243 - DEBUG - receive_response_body.complete
2024-01-21 17:27:00,244 - DEBUG - response_closed.started
2024-01-21 17:27:00,244 - DEBUG - response_closed.complete
2024-01-21 17:27:00,244 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:27:00,246 - INFO - Received response from OpenAI: )

        # Get list of files modified in the given branch
        files = get_branch_modified_files(repo, branch_name)

         # Generate plantuml code from modified files
        puml_code = generate_puml_code(files, config)

        # Generate image from plantuml code
        image = generate_image(puml_code)

        # Save image to output directory
        image.save(output_directory + '/uml_diagram.png')

        # Clean up the cloned repo
        logger.info("Cleaning up cloned repository")
        shutil.rmtree(temp_dir)

        # Return success response
        return {"message": "UML diagram successfully generated"}, 200

@startuml

class Data {
    -gitHubAccessToken
    +get('gitHubAccessToken')
}

class Config {
    -files
    -puml_code
    +get_branch_modified_files()
    +generate_puml_code()
}

class TempDir {
    -temp_dir
    +mkdtemp()
    -rmtree()
}

class Image {
    -puml_code
    -output_directory
    +generate_image()
    +save()
}

class Logger {
    -log ()
    +info()
    +error()
}

class Repo {
    -git_repo_url
    -temp_dir
    -github_access_token
    +clone_repo()
}

class Routes {
    -config.json
    -branch_name
    +open()
}

Data "1" <-- "1" Logger
TempDir "0..1" <-- "1" Logger
Repo "1" <-- "1" Logger
Config "1" <-- "1" Routes
Image "1" <-- "1" Routes
Repo "1" <-- "1" TempDir

start
:thub_access_token = Data.get('gitHubAccessToken');
:branch_name = Data.get('branchName', 'master');
if (not git_repo_url or not output_directory or not github_access_token or not branch_name) then
    :log("Missing required parameters");
else
    :temp_dir = TempDir.mkdtemp();
    :repo = Repo.clone_repo();
    :config = Routes.open('src/routes/config.json');
    :files = Config.get_branch_modified_files();
    :puml_code = Config.generate_puml_code();
    :image = Image.generate_image(puml_code);
    :image.save(output_directory + '/uml_diagram.png');
    :Logger.info("Cleaning up cloned repository");
    :TempDir.rmtree();
    :Logger.error("Error during UML generation: {str(e)}", exc_info=True);
    :return {"message": "UML diagram successfully generated"}, 200;
endif
stop

@enduml
2024-01-21 17:27:00,247 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-21 17:27:00,249 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-21 17:27:00,250 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:27:00,250 - DEBUG - send_request_headers.complete
2024-01-21 17:27:00,251 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:27:00,251 - DEBUG - send_request_body.complete
2024-01-21 17:27:00,251 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:27:04,509 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:27:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4184'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'1016bb837ab95172fa32c38e9785bd7b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493534af844adad-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:27:04,511 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:27:04,512 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:27:04,512 - DEBUG - receive_response_body.complete
2024-01-21 17:27:04,513 - DEBUG - response_closed.started
2024-01-21 17:27:04,513 - DEBUG - response_closed.complete
2024-01-21 17:27:04,513 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:27:04,515 - INFO - Received response from OpenAI: t_diagram(included_files, config, output_directory)
        
@startuml

class traverse_directories {
    - included_files: dict
    + traverse_directories(repo, temp_dir, config): dict
}
note "This function traverses the repository tree and retrieves included files based on given configurations." as n1

class repo {
    - tree(): tree
}
note "The repository object, used to access the repository's tree data." as n2

class tree {
    - type: str
    + traverse(): list
}
note "The tree object, used to iterate through the repository's tree structure." as n3

class temp_dir {
    <#4bd22a>- included_files: dict
}
note "A temporary directory used to store retrieved files from the repository." as n4

class config {
    - include: list
}
note "The configuration object, used to specify which files to include from the repository." as n5

class fnmatch {
    + fnmatch(path, pattern): bool
}
note "A function used to compare the repository's file paths with the given patterns in the configuration." as n6

class logger {
    + debug(message): void
    + info(message): void
}
note "A logging system used to track progress and output information." as n7

class output_directory {
    + generate_content_diagram(included_files, config, output_directory): list
}
note "A function used to generate a UML content diagram based on the retrieved files from the repository." as n8

traverse_directories ..> repo: uses
traverse_directories ..> temp_dir: creates
traverse_directories ..> config: uses
repo ..> tree: accesses
tree ..> fnmatch: uses
temp_dir ..> fnmatch: uses
logger ..> output_directory: uses
output_directory ..> included_files: uses
included_files ..> fnmatch: uses
@enduml
2024-01-21 17:27:04,516 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-21 17:27:04,518 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-21 17:27:04,519 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:27:04,520 - DEBUG - send_request_headers.complete
2024-01-21 17:27:04,520 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:27:04,520 - DEBUG - send_request_body.complete
2024-01-21 17:27:04,520 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:27:06,902 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:27:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2261'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'bfc63b7392f3d54037eb32514cd8d7ac'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935365ab56adad-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:27:06,903 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:27:06,904 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:27:06,906 - DEBUG - receive_response_body.complete
2024-01-21 17:27:06,907 - DEBUG - response_closed.started
2024-01-21 17:27:06,907 - DEBUG - response_closed.complete
2024-01-21 17:27:06,907 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:27:06,908 - INFO - Received response from OpenAI:  ____________________________________________________________________
|                              t : function                       |
|__________________________________________________________________|
| + included_files : list                                          |
| + output_directory : string                                      |
|__________________________________________________________________|
| + final_output_paths : list                                      |
| - temp_dir : string                                              |
|__________________________________________________________________|
| + logger : Logger                                                |
| + git_repo_url : string                                          |
|__________________________________________________________________|
| + t(included_files, output_directory) : Dictionary, int         |
|__________________________________________________________________|
| + __main__()                                                     |
|__________________________________________________________________|
| + __generate_uml__(included_files, output_directory) : list      |
|__________________________________________________________________|
| + __log_output_paths__(final_output_paths) : None                |
|__________________________________________________________________|
| + __cleanup__(temp_dir) : None                                   |
|__________________________________________________________________| 
2024-01-21 17:27:06,910 - INFO - UML code generated for src/routes/uml_from_repo.py: @startuml
title uml_from_repo.py
t_repo = clone_repo(git_repo_url, output_directory)  # Clone the repository to the output directory  
    code_files = retrieve_code(git_repo)  # Retrieve code files from the repository
    for file in code_files:
        full_path = os.path.join(output_directory, file)
        uml_content = generate_content(full_path)  # Generate the UML content from the code file
        with open(full_path + '.puml', 'w') as uml_file:  # Create a .puml file for the UML content
            uml_file.write(uml_content)
            logger.info('Created .puml file for {}'.format(file))

@startuml
class UMLRepository {
    - log_directory : string
    - log_filename : string
    - log_handler : object
    - log_formatter : object
    - logger : object
    - git_repo : object
    - output_directory : string
    - code_files : list

    + process_request(data)
}

class Clone {
    - git_repo_url : string
    - output_directory : string
    - git : object

    + clone_repo(git_repo_url, output_directory)
}

class RetrieveCode {
    - git_repo : object
    - code_files : list

    + retrieve_code(git_repo)
}

class CodeToUML {
    - full_path : string
    - uml_content : string
    - uml_file : object

    + generate_content(full_path)
}

UMLRepository "1" *-- "1" Clone : uses
UMLRepository "1" *-- "1" RetrieveCode : uses
UMLRepository "1" *-- "1" CodeToUML : uses

Clone "1" *-- "1" git : uses

RetrieveCode "1" *-- "1" git_repo : holds
RetrieveCode "1" *-- "*" code_files : contains

CodeToUML "1" *-- "1" uml_file : uses

note left: Configures logging system\nand creates log file
Note top: process_request is the main function\nthat handles the entire process
Note top: Generates the .puml file\nfor the UML content

@enduml)

        # Get list of files modified in the given branch
        files = get_branch_modified_files(repo, branch_name)

         # Generate plantuml code from modified files
        puml_code = generate_puml_code(files, config)

        # Generate image from plantuml code
        image = generate_image(puml_code)

        # Save image to output directory
        image.save(output_directory + '/uml_diagram.png')

        # Clean up the cloned repo
        logger.info("Cleaning up cloned repository")
        shutil.rmtree(temp_dir)

        # Return success response
        return {"message": "UML diagram successfully generated"}, 200

@startuml

class Data {
    -gitHubAccessToken
    +get('gitHubAccessToken')
}

class Config {
    -files
    -puml_code
    +get_branch_modified_files()
    +generate_puml_code()
}

class TempDir {
    -temp_dir
    +mkdtemp()
    -rmtree()
}

class Image {
    -puml_code
    -output_directory
    +generate_image()
    +save()
}

class Logger {
    -log ()
    +info()
    +error()
}

class Repo {
    -git_repo_url
    -temp_dir
    -github_access_token
    +clone_repo()
}

class Routes {
    -config.json
    -branch_name
    +open()
}

Data "1" <-- "1" Logger
TempDir "0..1" <-- "1" Logger
Repo "1" <-- "1" Logger
Config "1" <-- "1" Routes
Image "1" <-- "1" Routes
Repo "1" <-- "1" TempDir

start
:thub_access_token = Data.get('gitHubAccessToken');
:branch_name = Data.get('branchName', 'master');
if (not git_repo_url or not output_directory or not github_access_token or not branch_name) then
    :log("Missing required parameters");
else
    :temp_dir = TempDir.mkdtemp();
    :repo = Repo.clone_repo();
    :config = Routes.open('src/routes/config.json');
    :files = Config.get_branch_modified_files();
    :puml_code = Config.generate_puml_code();
    :image = Image.generate_image(puml_code);
    :image.save(output_directory + '/uml_diagram.png');
    :Logger.info("Cleaning up cloned repository");
    :TempDir.rmtree();
    :Logger.error("Error during UML generation: {str(e)}", exc_info=True);
    :return {"message": "UML diagram successfully generated"}, 200;
endif
stop

@endumlt_diagram(included_files, config, output_directory)
        
@startuml

class traverse_directories {
    - included_files: dict
    + traverse_directories(repo, temp_dir, config): dict
}
note "This function traverses the repository tree and retrieves included files based on given configurations." as n1

class repo {
    - tree(): tree
}
note "The repository object, used to access the repository's tree data." as n2

class tree {
    - type: str
    + traverse(): list
}
note "The tree object, used to iterate through the repository's tree structure." as n3

class temp_dir {
    <#4bd22a>- included_files: dict
}
note "A temporary directory used to store retrieved files from the repository." as n4

class config {
    - include: list
}
note "The configuration object, used to specify which files to include from the repository." as n5

class fnmatch {
    + fnmatch(path, pattern): bool
}
note "A function used to compare the repository's file paths with the given patterns in the configuration." as n6

class logger {
    + debug(message): void
    + info(message): void
}
note "A logging system used to track progress and output information." as n7

class output_directory {
    + generate_content_diagram(included_files, config, output_directory): list
}
note "A function used to generate a UML content diagram based on the retrieved files from the repository." as n8

traverse_directories ..> repo: uses
traverse_directories ..> temp_dir: creates
traverse_directories ..> config: uses
repo ..> tree: accesses
tree ..> fnmatch: uses
temp_dir ..> fnmatch: uses
logger ..> output_directory: uses
output_directory ..> included_files: uses
included_files ..> fnmatch: uses
@enduml____________________________________________________________________
|                              t : function                       |
|__________________________________________________________________|
| + included_files : list                                          |
| + output_directory : string                                      |
|__________________________________________________________________|
| + final_output_paths : list                                      |
| - temp_dir : string                                              |
|__________________________________________________________________|
| + logger : Logger                                                |
| + git_repo_url : string                                          |
|__________________________________________________________________|
| + t(included_files, output_directory) : Dictionary, int         |
|__________________________________________________________________|
| + __main__()                                                     |
|__________________________________________________________________|
| + __generate_uml__(included_files, output_directory) : list      |
|__________________________________________________________________|
| + __log_output_paths__(final_output_paths) : None                |
|__________________________________________________________________|
| + __cleanup__(temp_dir) : None                                   |
|__________________________________________________________________|
@enduml
2024-01-21 17:27:06,912 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:27:06,913 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:27:06,913 - INFO - Skipping empty file: src/scripts/__init__.py
2024-01-21 17:27:06,913 - INFO - Processing file: src/scripts/execute_generate_uml.py
2024-01-21 17:27:06,913 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import json
import os
import requests
import logging
from logging import handlers
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure logging to write to a file
log_directory = '../../logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'execute_generate_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


# Configure logging
logging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))
# Configuration file path
config_file_path = os.path.join(cu
2024-01-21 17:27:06,915 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nimport json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(cu", 'max_tokens': 1024}}
2024-01-21 17:27:06,916 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:27:06,917 - DEBUG - send_request_headers.complete
2024-01-21 17:27:06,917 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:27:06,917 - DEBUG - send_request_body.complete
2024-01-21 17:27:06,917 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:27:11,045 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:27:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4059'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'f127ac79eaf6036fab350b46fc7fc5ae'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849353749a96adad-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:27:11,046 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:27:11,047 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:27:11,047 - DEBUG - receive_response_body.complete
2024-01-21 17:27:11,048 - DEBUG - response_closed.started
2024-01-21 17:27:11,048 - DEBUG - response_closed.complete
2024-01-21 17:27:11,048 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:27:11,050 - INFO - Received response from OpenAI: urrent_dir, 'config.json')

# Read configuration file
with open(config_file_path) as config_file:
    config = json.load(config_file)

# Define API key
api_key = config['api_key']
# Endpoint URL
endpoint_url = config['endpoint_url']

# Send GET request to API endpoint
response = requests.get(endpoint_url, headers={'Authorization': api_key})

# Check if response is successful
if response.status_code == requests.codes.ok:
    # If successful, convert response to json
    response_json = response.json()
   # Loop through each item in response
    for item in response_json:
        # Get name and type of item
        name = item['name']
        type = item['type']
        # Print out name and type
        print(f'name: {name}, type: {type}')

@startuml
class Config {
  -logger: Logger
  -api_key: String
  -endpoint_url: String
  +setLogger(logger: Logger)
  +getLogger(): Logger
  +setApiKey(api_key: String)
  +getApiKey(): String
  +setEndpointUrl(endpoint_url: String)
  +getEndpointUrl(): String
}

class Logger {
  -log_handler: RotatingFileHandler
  -log_formatter: Formatter
  +setLogHandler(log_handler: RotatingFileHandler)
  +getLogHandler(): RotatingFileHandler
  +setLogFormatter(log_formatter: Formatter)
  +getLogFormatter(): Formatter
  +writeLog(message: String, level: String, timestamp: String)
}

class ConfigLoader {
  -config_file_path: String
  -api_key: String
  +loadConfig(config_file_path: String)
  +getApiKey(): String
}

Config o-- Logger
Logger *-- RotatingFileHandler
Logger *-- Formatter
ConfigLoader *-- Config

@enduml
2024-01-21 17:27:11,051 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

rrent_dir, 'config.json')

# Read configuration from the JSON file
with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

# Retrieve the GitHub access token from environment variables
github_token = os.getenv('GITHUB_PAT')

# Endpoint URL
url = 'http://127.0.0.1:5000/generate-uml'

# Headers
headers = {
    'Content-Type': 'application/json'
}

# Update the GitHub access token and local directory in the config data
config_data['gitHubAccessToken'] = github_token
config_data['local_dir'] = os.path.join(current_dir, '../..', 'output')

# Log the JSON data being sent in the request
logging.info(f'Sending JSON data to {url}:')
logging.info(json.dumps(config_data, indent=2))

try:
    # Make the POST request
    response = requests.post(url, headers=headers, json=config_data)

    # Log the response from the server
    logging.info(f'Response from server ({url}):')
    logging.info(f'Status Code: {response.status_code}')
    logging.info(f'Response Text: {response.text}')

    #
2024-01-21 17:27:11,054 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nrrent_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    #", 'max_tokens': 1024}}
2024-01-21 17:27:11,055 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:27:11,056 - DEBUG - send_request_headers.complete
2024-01-21 17:27:11,056 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:27:11,056 - DEBUG - send_request_body.complete
2024-01-21 17:27:11,056 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:27:15,158 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:27:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3933'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'5a1929b70b9ea4df115a493ca1a5d8f4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493538e7d76adad-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:27:15,160 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:27:15,160 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:27:15,161 - DEBUG - receive_response_body.complete
2024-01-21 17:27:15,162 - DEBUG - response_closed.started
2024-01-21 17:27:15,162 - DEBUG - response_closed.complete
2024-01-21 17:27:15,163 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:27:15,164 - INFO - Received response from OpenAI:  Check if the response was successful and log the results
    if response.status_code == 200:
        logging.info('Successfully generated UML diagrams!')
    else:
        logging.error('Error generating UML diagrams.')
except requests.exceptions.RequestException as e:
    # Log any errors that occur during the request
    logging.error(f'An error occurred during the request: {e}')

@startuml
class GenerateUML {
    - current_dir: str
    - config_file_path: str
    - config_data: str
    - github_token: str
    - url: str
    - headers: dict
    - response: str
    - e: requests.exceptions.RequestException

    + main() : void
    + generate_uml() : void
}

class json {
    + load() : dict
    + dumps() : str
}

class os {
    + getenv() : str
    + path: str
    + join() : str
}

class logging {
    + info() : void
    + error() : void
}

class requests {
    + post() : str
}

GenerateUML *-right- json
GenerateUML *-right- os
GenerateUML *-right- logging
GenerateUML *-right- requests
GenerateUML o-config_data : config_json
GenerateUML o-url : endpoint_url
GenerateUML o-headers : headers
GenerateUML o-e : RequestException
json <|-down- GenerateUML : config_data
os <|-down- GenerateUML : current_dir
logging <|-down- GenerateUML : logging
requests <|-down- GenerateUML : response

note top of GenerateUML : Generate UML Diagrams\nfrom Config Data

@enduml
2024-01-21 17:27:15,165 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

 Print the response from the server
    print(response.text)

    # Save the response to a file in the output directory
    output_dir = os.path.join(current_dir, '../..', 'output')
    os.makedirs(output_dir, exist_ok=True)
    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:
        json.dump(response.json(), output_file, indent=2)

except Exception as e:
    # Log any exceptions that occur
    logging.error(f'Error occurred: {str(e)}')
2024-01-21 17:27:15,167 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')", 'max_tokens': 1024}}
2024-01-21 17:27:15,168 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:27:15,169 - DEBUG - send_request_headers.complete
2024-01-21 17:27:15,169 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:27:15,169 - DEBUG - send_request_body.complete
2024-01-21 17:27:15,169 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:27:18,365 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:27:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3123'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'f5faddb5e7c89152aa435587ebcefad4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849353a83963adad-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:27:18,366 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:27:18,367 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:27:18,368 - DEBUG - receive_response_body.complete
2024-01-21 17:27:18,368 - DEBUG - response_closed.started
2024-01-21 17:27:18,368 - DEBUG - response_closed.complete
2024-01-21 17:27:18,369 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:27:18,370 - INFO - Received response from OpenAI: 

@startuml
class Client {
    - response: Response
    + print(response: Response): void
}
note top
    This is the client class that makes a request to the server and handles the response.
end note

Client --> Response: makeRequest()

Response --> Client: response

@enduml

@startuml
class Response {
    - text: String
    - json: JsonObject
    + getText(): String
    + getJson(): JsonObject
}
note top
    This is the response class that stores the data from the server's response.
end note

Response --> Client: response

@enduml

@startuml
class Main {
    - current_dir: String
    - output_dir: String
    + main(): void
}
note top
    This is the main class that controls the flow of the program.
end note

Main --> Client: makeRequest()
Main --> Response: response
main --> Client: print(response)
main --> OS: join(current_dir, '../..', 'output')
main --> OS: makedirs(output_dir, exist_ok=True)
main --> OS: open(join(output_dir, 'response.json'), 'w')
OS --> File: write(json.dump(response.json(), output_file, indent=2))
main --> Exception: handleException(e)
@enduml

@startuml
class Exception {
    - e: Exception
    - logging: Logger
    + handleException(e: Exception): void
}
note top
    This is the exception class that handles any errors that occur during the program's execution.
end note

Exception --> Logging: log(f'Error occurred: {str(e)}')
Exception --> Client: response

@enduml
2024-01-21 17:27:18,371 - INFO - UML code generated for src/scripts/execute_generate_uml.py: @startuml
title execute_generate_uml.py
urrent_dir, 'config.json')

# Read configuration file
with open(config_file_path) as config_file:
    config = json.load(config_file)

# Define API key
api_key = config['api_key']
# Endpoint URL
endpoint_url = config['endpoint_url']

# Send GET request to API endpoint
response = requests.get(endpoint_url, headers={'Authorization': api_key})

# Check if response is successful
if response.status_code == requests.codes.ok:
    # If successful, convert response to json
    response_json = response.json()
   # Loop through each item in response
    for item in response_json:
        # Get name and type of item
        name = item['name']
        type = item['type']
        # Print out name and type
        print(f'name: {name}, type: {type}')

@startuml
class Config {
  -logger: Logger
  -api_key: String
  -endpoint_url: String
  +setLogger(logger: Logger)
  +getLogger(): Logger
  +setApiKey(api_key: String)
  +getApiKey(): String
  +setEndpointUrl(endpoint_url: String)
  +getEndpointUrl(): String
}

class Logger {
  -log_handler: RotatingFileHandler
  -log_formatter: Formatter
  +setLogHandler(log_handler: RotatingFileHandler)
  +getLogHandler(): RotatingFileHandler
  +setLogFormatter(log_formatter: Formatter)
  +getLogFormatter(): Formatter
  +writeLog(message: String, level: String, timestamp: String)
}

class ConfigLoader {
  -config_file_path: String
  -api_key: String
  +loadConfig(config_file_path: String)
  +getApiKey(): String
}

Config o-- Logger
Logger *-- RotatingFileHandler
Logger *-- Formatter
ConfigLoader *-- Config

@endumlCheck if the response was successful and log the results
    if response.status_code == 200:
        logging.info('Successfully generated UML diagrams!')
    else:
        logging.error('Error generating UML diagrams.')
except requests.exceptions.RequestException as e:
    # Log any errors that occur during the request
    logging.error(f'An error occurred during the request: {e}')

@startuml
class GenerateUML {
    - current_dir: str
    - config_file_path: str
    - config_data: str
    - github_token: str
    - url: str
    - headers: dict
    - response: str
    - e: requests.exceptions.RequestException

    + main() : void
    + generate_uml() : void
}

class json {
    + load() : dict
    + dumps() : str
}

class os {
    + getenv() : str
    + path: str
    + join() : str
}

class logging {
    + info() : void
    + error() : void
}

class requests {
    + post() : str
}

GenerateUML *-right- json
GenerateUML *-right- os
GenerateUML *-right- logging
GenerateUML *-right- requests
GenerateUML o-config_data : config_json
GenerateUML o-url : endpoint_url
GenerateUML o-headers : headers
GenerateUML o-e : RequestException
json <|-down- GenerateUML : config_data
os <|-down- GenerateUML : current_dir
logging <|-down- GenerateUML : logging
requests <|-down- GenerateUML : response

note top of GenerateUML : Generate UML Diagrams\nfrom Config Data

@enduml@startuml
class Client {
    - response: Response
    + print(response: Response): void
}
note top
    This is the client class that makes a request to the server and handles the response.
end note

Client --> Response: makeRequest()

Response --> Client: response

@enduml
2024-01-21 17:27:18,372 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:27:18,373 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:27:18,374 - INFO - Generated file paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 17:27:18,374 - INFO - Final output paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 17:27:18,374 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:27:18,375 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:27:18,375 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:27:18,375 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:27:18,376 - INFO - Cleaning up temporary directory
2024-01-21 17:27:18,555 - INFO - 127.0.0.1 - - [21/Jan/2024 17:27:18] "POST /generate-uml HTTP/1.1" 200 -
2024-01-21 17:30:34,655 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-21 17:30:34,656 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-21 17:30:34,656 - INFO - Received local_dir: ./output
2024-01-21 17:30:34,656 - INFO - Received gitHubAccessToken: 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
2024-01-21 17:30:34,656 - INFO - Cleaning up temporary directory
2024-01-21 17:30:34,656 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 17:30:34,656 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpoza0936j'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-21 17:30:38,725 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpoza0936j'])'s unused stdout: 
2024-01-21 17:30:38,727 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 17:30:38,728 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpoza0936j, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 17:30:38,734 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpoza0936j, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 17:30:38,757 - DEBUG - Type of included_files: <class 'dict'>
2024-01-21 17:30:38,757 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 17:30:38,758 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-21 17:30:38,758 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 17:30:38,758 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-21 17:30:38,758 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-21 17:30:38,758 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-21 17:30:38,759 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-21 17:30:38,760 - DEBUG - close.started
2024-01-21 17:30:38,760 - DEBUG - close.complete
2024-01-21 17:30:38,760 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-21 17:30:38,801 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105ed2b50>
2024-01-21 17:30:38,801 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105a95b50> server_hostname='api.openai.com' timeout=5.0
2024-01-21 17:30:38,824 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105ed28d0>
2024-01-21 17:30:38,825 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:30:38,825 - DEBUG - send_request_headers.complete
2024-01-21 17:30:38,825 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:30:38,825 - DEBUG - send_request_body.complete
2024-01-21 17:30:38,825 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:30:46,963 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:30:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'7995'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'5051420024bd89f7da138eedcf5a134a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849358a10edbadb9-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:30:46,964 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:30:46,965 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:30:46,966 - DEBUG - receive_response_body.complete
2024-01-21 17:30:46,966 - DEBUG - response_closed.started
2024-01-21 17:30:46,966 - DEBUG - response_closed.complete
2024-01-21 17:30:46,967 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:30:46,969 - INFO - Received response from OpenAI:  or does not have .py extension
        if not code or not file_path.endswith('.py'):
            continue
        file_paths.append(file_path)
        # Generate code using the OpenAI API
        generated_code += api.generate_code(code)
    
    # Save the generated code to a file in the output directory
    with open(os.path.join(output_directory, 'generated_code.py'), 'w') as f:
        f.write(generated_code)

    logging.info("Generated code successfully saved to output directory")  # Log successful saving of code

if __name__ == '__main__':
    # Set the input files and output directory
    files = {'utils.py': 'def add(x, y):\n    return x + y\n',
            'main.py': 'from utils import add\n\na = 5\nb = 10\nprint(add(a, b))'}
    output_directory = 'output'

    # Call the generate_content function with the input files and output directory
    generate_content(files, output_directory)

[puml_source]

@startuml
class "OpenAIAPI" {
    + generate_code(code): string
}

class "handlers" {
    - RotatingFileHandler(log_filename, maxBytes, backupCount)
}

class "OpenAIAPI"
class "logging" {
    - logger
    # logger_type

    # instantiate_logger()
    + info(message)
    + setLevel(level)
    + setFormatter(formatter)
}

class "os" {

}

class "code_to_uml" {
    - api: OpenAIAPI
    - log_directory
    - log_filename
    - log_handler
    - log_formatter
    - logger: logging
    - generated_code
    - file_paths
    ~ generate_content(files, output_directory)

    # main()
}

class "generated_code.py"
class "output_directory"

class "input_files" {
    - utils.py
    - main.py
}

OpenAIAPI "1" -- code_to_uml "1"
handlers "1" -- code_to_uml "1"
logging "1" -- code_to_uml "1"
os "1" -- code_to_uml "1"
logging "1" -- code_to_uml "1"
code_to_uml "1" -- output_directory "1"
code_to_uml "1" -- "input_files" "2"

class "OpenAIAPI" {
    + generate_code(code): string
}

class "handlers" {
    - RotatingFileHandler(log_filename, maxBytes, backupCount)
}

class "logging" {
    - logger
    # logger_type

    # instantiate_logger()
    + info(message)
    + setLevel(level)
    + setFormatter(formatter)
}

class "main.py" {
    + main()
}

class "utils.py" {
    + add(x, y)
}

input_files "2" -- "utils.py"
input_files "2" -- "main.py"
OpenAIAPI "1" -- "api: OpenAIAPI" "1" : creates
logging "1" -- "log_directory" : creates
logging "1" -- "log_filename" : creates
"log_handler" -- "maxBytes"
"log_handler" -- "backupCount"
"generated_code.py" <-- "generated_code"
code_to_uml "1" -- "generated_code.py"
generated_code "2" -- "output_directory"

@enduml
2024-01-21 17:30:46,970 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-21 17:30:46,973 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-21 17:30:46,974 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:30:46,975 - DEBUG - send_request_headers.complete
2024-01-21 17:30:46,975 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:30:46,975 - DEBUG - send_request_body.complete
2024-01-21 17:30:46,975 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:30:49,371 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:30:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2293'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'9efd579ccd65f621ebbb8405fe398161'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849358d3f9dbadb9-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:30:49,372 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:30:49,373 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:30:49,374 - DEBUG - receive_response_body.complete
2024-01-21 17:30:49,374 - DEBUG - response_closed.started
2024-01-21 17:30:49,375 - DEBUG - response_closed.complete
2024-01-21 17:30:49,375 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:30:49,377 - INFO - Received response from OpenAI: _paths})


*Please note that the code may not be complete and the UML diagrams are for representation purposes only.

@startuml

class CodeAnalyzer
CodeAnalyzer : -logger : Logger
CodeAnalyzer : -file_paths : List<String>
CodeAnalyzer : -generated_code : String
CodeAnalyzer : -output_directory : String
CodeAnalyzer : -api : API

CodeAnalyzer : +main()

CodeAnalyzer : +generateUML(code: String, file_path: String) : String
CodeAnalyzer : +saveUMLFile(generated_code: String, output_path: String) : String
CodeAnalyzer : +run() : List<String>

@enduml

@startuml

class Logger
Logger : +info(message : String)
Logger : +error(message : String)

@enduml

@startuml

class API
API : +generate_from_code(code : String) : String
API : +save_generated_output(generated_code : String, output_path : String) : String

@enduml
2024-01-21 17:30:49,378 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-21 17:30:49,379 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-21 17:30:49,380 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:30:49,381 - DEBUG - send_request_headers.complete
2024-01-21 17:30:49,381 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:30:49,382 - DEBUG - send_request_body.complete
2024-01-21 17:30:49,382 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:30:51,460 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:30:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2011'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'8eacdafef0b3ec5fc700b855b3c871af'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849358e30eaaadb9-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:30:51,461 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:30:51,462 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:30:51,462 - DEBUG - receive_response_body.complete
2024-01-21 17:30:51,463 - DEBUG - response_closed.started
2024-01-21 17:30:51,463 - DEBUG - response_closed.complete
2024-01-21 17:30:51,463 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:30:51,465 - INFO - Received response from OpenAI: 

}

class CodeGenerator {
    -language: string
    -project_name: string
    -number_of_files: int
    -author: string

    +constructor(language: string, project_name: string, number_of_files: int, author: string)
    +generate_code(): string
}

```

```
@startuml

class FileGenerator{
    -file_paths : string
    +generate_file_path() : string
    +generate_code() : string
}

class CodeGenerator{
    -language : string
    -project_name : string
    -number_of_files : int
    -author : string
    +constructor(language: string, project_name: string, number_of_files: int, author: string)
    +generate_code() : string
}

FileGenerator ..> CodeGenerator : uses

@enduml
2024-01-21 17:30:51,466 - INFO - UML code generated for src/routes/code_to_uml.py: @startuml
title code_to_uml.py
or does not have .py extension
        if not code or not file_path.endswith('.py'):
            continue
        file_paths.append(file_path)
        # Generate code using the OpenAI API
        generated_code += api.generate_code(code)
    
    # Save the generated code to a file in the output directory
    with open(os.path.join(output_directory, 'generated_code.py'), 'w') as f:
        f.write(generated_code)

    logging.info("Generated code successfully saved to output directory")  # Log successful saving of code

if __name__ == '__main__':
    # Set the input files and output directory
    files = {'utils.py': 'def add(x, y):\n    return x + y\n',
            'main.py': 'from utils import add\n\na = 5\nb = 10\nprint(add(a, b))'}
    output_directory = 'output'

    # Call the generate_content function with the input files and output directory
    generate_content(files, output_directory)

[puml_source]

@startuml
class "OpenAIAPI" {
    + generate_code(code): string
}

class "handlers" {
    - RotatingFileHandler(log_filename, maxBytes, backupCount)
}

class "OpenAIAPI"
class "logging" {
    - logger
    # logger_type

    # instantiate_logger()
    + info(message)
    + setLevel(level)
    + setFormatter(formatter)
}

class "os" {

}

class "code_to_uml" {
    - api: OpenAIAPI
    - log_directory
    - log_filename
    - log_handler
    - log_formatter
    - logger: logging
    - generated_code
    - file_paths
    ~ generate_content(files, output_directory)

    # main()
}

class "generated_code.py"
class "output_directory"

class "input_files" {
    - utils.py
    - main.py
}

OpenAIAPI "1" -- code_to_uml "1"
handlers "1" -- code_to_uml "1"
logging "1" -- code_to_uml "1"
os "1" -- code_to_uml "1"
logging "1" -- code_to_uml "1"
code_to_uml "1" -- output_directory "1"
code_to_uml "1" -- "input_files" "2"

class "OpenAIAPI" {
    + generate_code(code): string
}

class "handlers" {
    - RotatingFileHandler(log_filename, maxBytes, backupCount)
}

class "logging" {
    - logger
    # logger_type

    # instantiate_logger()
    + info(message)
    + setLevel(level)
    + setFormatter(formatter)
}

class "main.py" {
    + main()
}

class "utils.py" {
    + add(x, y)
}

input_files "2" -- "utils.py"
input_files "2" -- "main.py"
OpenAIAPI "1" -- "api: OpenAIAPI" "1" : creates
logging "1" -- "log_directory" : creates
logging "1" -- "log_filename" : creates
"log_handler" -- "maxBytes"
"log_handler" -- "backupCount"
"generated_code.py" <-- "generated_code"
code_to_uml "1" -- "generated_code.py"
generated_code "2" -- "output_directory"

@enduml_paths})


*Please note that the code may not be complete and the UML diagrams are for representation purposes only.

@startuml

class CodeAnalyzer
CodeAnalyzer : -logger : Logger
CodeAnalyzer : -file_paths : List<String>
CodeAnalyzer : -generated_code : String
CodeAnalyzer : -output_directory : String
CodeAnalyzer : -api : API

CodeAnalyzer : +main()

CodeAnalyzer : +generateUML(code: String, file_path: String) : String
CodeAnalyzer : +saveUMLFile(generated_code: String, output_path: String) : String
CodeAnalyzer : +run() : List<String>

@enduml
2024-01-21 17:30:51,467 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:30:51,469 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:30:51,470 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-21 17:30:51,470 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-21 17:30:51,471 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-21 17:30:51,472 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:30:51,473 - DEBUG - send_request_headers.complete
2024-01-21 17:30:51,474 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:30:51,474 - DEBUG - send_request_body.complete
2024-01-21 17:30:51,474 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:30:56,925 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:30:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5297'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'308d5608d5d999efb27a6bd17a8ea16b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849358f01a93adb9-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:30:56,926 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:30:56,927 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:30:56,928 - DEBUG - receive_response_body.complete
2024-01-21 17:30:56,928 - DEBUG - response_closed.started
2024-01-21 17:30:56,928 - DEBUG - response_closed.complete
2024-01-21 17:30:56,929 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:30:56,930 - INFO - Received response from OpenAI: 
        # Return the repo object imported from GitPython
        return repo
        
    except Exception as e:
        logger.error(f"Error cloning repository: {repo_url}")
        logger.debug(f"Full exception: {e}")
        raise e


def retrieve_code(repo_url, temp_dir, access_token=None):
    # Clone the repository using its URL
    repo = clone_repo(repo_url, temp_dir, access_token)
    
    # Get all the files in the repository and save them in a list
    files = [f.path for f in repo.head.commit.tree]
    
    # Get the latest commit and save its message in a text file
    commit_message = repo.head.commit.message
    commit_file = os.path.join(temp_dir, 'commit_message.txt')
    with open(commit_file, 'w') as f:
        f.write(commit_message)

    # Return the list of files and the commit message
    return files, commit_message


# Define the main function
def main():
    # Load configuration data from JSON file
    with open('config.json') as f:
        config = json.load(f)
    
    # Set the repository URL
    repo_url = config['REPO_URL']
    
    # Set the temporary directory for the cloned repository
    temp_dir = config['TEMP_DIR']
    
    # Retrieve the code from the repository
    files, commit_message = retrieve_code(repo_url, temp_dir, config.get('ACCESS_TOKEN'))
    
    # Print the list of files and the commit message
    print('Files retrieved: ')
    for file in files:
        print(file)
    print(f"Commit message: {commit_message}")


main()

@startuml
class GitPython
GitPython : - repo_url
GitPython : - temp_dir
GitPython : - access_token
GitPython : + logger

GitPython : + clone_repo(repo_url, temp_dir, access_token)
GitPython : + retrieve_code(repo_url, temp_dir, access_token=None)
GitPython : + main()

GitPython --|> logging.Logger
GitPython --|> os
GitPython --|> handlers.RotatingFileHandler
GitPython --|> logging.Formatter
GitPython --|> git.Repo

main ..> GitPython : creates instance
clone_repo ..> GitPython : uses instance
retrieve_code ..> GitPython : uses instance

note bottom : Create GitPython instance

@enduml
2024-01-21 17:30:56,932 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-21 17:30:56,934 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-21 17:30:56,935 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:30:56,936 - DEBUG - send_request_headers.complete
2024-01-21 17:30:56,936 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:30:56,937 - DEBUG - send_request_body.complete
2024-01-21 17:30:56,937 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:00,113 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:31:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2954'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'44bb8f823ee0e4628afc3874242f2345'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849359123b5badb9-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:31:00,116 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:31:00,117 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:31:00,118 - DEBUG - receive_response_body.complete
2024-01-21 17:31:00,118 - DEBUG - response_closed.started
2024-01-21 17:31:00,118 - DEBUG - response_closed.complete
2024-01-21 17:31:00,119 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:31:00,120 - INFO - Received response from OpenAI:  if file.path.endswith('.py') and file.path not in ignore_list and file.path in include_list:
                 included_files[file.path] = file.data_stream.read().decode("utf-8")
        
        return included_files

@startuml

class Logger {
    - error() : void
    - info() : void
}

class Exception {
    + e : Exception
}

class ValueError {
    + e : Exception
}

class Repository
class Branch_name
class Config
class File
class Code

class RepoRetriever {
    + retrieve_code() : dict
}

class RepoCloner {
    ** repo : Repository
    - logger : Logger
    
    + clone() : Repository
    ~ ** retrieve_code(repo, branch_name) : dict
}

RepoRetriever ..> RepoCloner : uses
Exception <|-- Logger
ValueError <|-- RepoCloner

RepoCloner --> Repository
RepoRetriever --> Repository
RepoCloner --> Branch_name
RepoRetriever --> Branch_name

File o-- Code

RepoCloner --> Logger

RepoCloner --> Config
Branch_name --> Config
Code --> File
Config --> File
RepoRetriever --> Config
RepoRetriever --> File

Exception --> RepoCloner : is thrown
ValueError --> RepoCloner : is thrown

@enduml
2024-01-21 17:31:00,121 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-21 17:31:00,123 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-21 17:31:00,124 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:00,125 - DEBUG - send_request_headers.complete
2024-01-21 17:31:00,125 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:00,125 - DEBUG - send_request_body.complete
2024-01-21 17:31:00,125 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:01,639 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:31:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1418'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'5f33cf0ce18d61c7a78d88dfe4d7850f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849359262ef5adb9-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:31:01,640 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:31:01,641 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:31:01,641 - DEBUG - receive_response_body.complete
2024-01-21 17:31:01,641 - DEBUG - response_closed.started
2024-01-21 17:31:01,642 - DEBUG - response_closed.complete
2024-01-21 17:31:01,642 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:31:01,643 - INFO - Received response from OpenAI: 

@startuml

class UML {
    string include_list
    string ignore_list
    string file
    string file.path
    string ignored_file
    string file.abspath
    map included_files
    string f
}

UML --> file
UML --> logger

class file {
    string path
    string abspath
}

class logger {
    string info
    string warning
    string error
}

file --> logger

UML --> include_list
UML --> ignore_list

include_list --> file.path
ignore_list --> file.path
file --> included_files
included_files --> logger

@enduml
2024-01-21 17:31:01,644 - INFO - UML code generated for src/routes/retrieve_code.py: @startuml
title retrieve_code.py
# Return the repo object imported from GitPython
        return repo
        
    except Exception as e:
        logger.error(f"Error cloning repository: {repo_url}")
        logger.debug(f"Full exception: {e}")
        raise e


def retrieve_code(repo_url, temp_dir, access_token=None):
    # Clone the repository using its URL
    repo = clone_repo(repo_url, temp_dir, access_token)
    
    # Get all the files in the repository and save them in a list
    files = [f.path for f in repo.head.commit.tree]
    
    # Get the latest commit and save its message in a text file
    commit_message = repo.head.commit.message
    commit_file = os.path.join(temp_dir, 'commit_message.txt')
    with open(commit_file, 'w') as f:
        f.write(commit_message)

    # Return the list of files and the commit message
    return files, commit_message


# Define the main function
def main():
    # Load configuration data from JSON file
    with open('config.json') as f:
        config = json.load(f)
    
    # Set the repository URL
    repo_url = config['REPO_URL']
    
    # Set the temporary directory for the cloned repository
    temp_dir = config['TEMP_DIR']
    
    # Retrieve the code from the repository
    files, commit_message = retrieve_code(repo_url, temp_dir, config.get('ACCESS_TOKEN'))
    
    # Print the list of files and the commit message
    print('Files retrieved: ')
    for file in files:
        print(file)
    print(f"Commit message: {commit_message}")


main()

@startuml
class GitPython
GitPython : - repo_url
GitPython : - temp_dir
GitPython : - access_token
GitPython : + logger

GitPython : + clone_repo(repo_url, temp_dir, access_token)
GitPython : + retrieve_code(repo_url, temp_dir, access_token=None)
GitPython : + main()

GitPython --|> logging.Logger
GitPython --|> os
GitPython --|> handlers.RotatingFileHandler
GitPython --|> logging.Formatter
GitPython --|> git.Repo

main ..> GitPython : creates instance
clone_repo ..> GitPython : uses instance
retrieve_code ..> GitPython : uses instance

note bottom : Create GitPython instance

@endumlif file.path.endswith('.py') and file.path not in ignore_list and file.path in include_list:
                 included_files[file.path] = file.data_stream.read().decode("utf-8")
        
        return included_files

@startuml

class Logger {
    - error() : void
    - info() : void
}

class Exception {
    + e : Exception
}

class ValueError {
    + e : Exception
}

class Repository
class Branch_name
class Config
class File
class Code

class RepoRetriever {
    + retrieve_code() : dict
}

class RepoCloner {
    ** repo : Repository
    - logger : Logger
    
    + clone() : Repository
    ~ ** retrieve_code(repo, branch_name) : dict
}

RepoRetriever ..> RepoCloner : uses
Exception <|-- Logger
ValueError <|-- RepoCloner

RepoCloner --> Repository
RepoRetriever --> Repository
RepoCloner --> Branch_name
RepoRetriever --> Branch_name

File o-- Code

RepoCloner --> Logger

RepoCloner --> Config
Branch_name --> Config
Code --> File
Config --> File
RepoRetriever --> Config
RepoRetriever --> File

Exception --> RepoCloner : is thrown
ValueError --> RepoCloner : is thrown

@enduml@startuml

class UML {
    string include_list
    string ignore_list
    string file
    string file.path
    string ignored_file
    string file.abspath
    map included_files
    string f
}

UML --> file
UML --> logger

class file {
    string path
    string abspath
}

class logger {
    string info
    string warning
    string error
}

file --> logger

UML --> include_list
UML --> ignore_list

include_list --> file.path
ignore_list --> file.path
file --> included_files
included_files --> logger

@enduml
2024-01-21 17:31:01,645 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:31:01,646 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:31:01,646 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-21 17:31:01,646 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-21 17:31:01,649 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-21 17:31:01,650 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:01,651 - DEBUG - send_request_headers.complete
2024-01-21 17:31:01,651 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:01,651 - DEBUG - send_request_body.complete
2024-01-21 17:31:01,651 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:01,761 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:31:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'44'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'0c147d9fd1485013c4a5d8e26319d442'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493592fbb4cadb9-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:31:01,762 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:31:01,762 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:31:01,763 - DEBUG - receive_response_body.complete
2024-01-21 17:31:01,763 - DEBUG - response_closed.started
2024-01-21 17:31:01,763 - DEBUG - response_closed.complete
2024-01-21 17:31:01,763 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:31:01,764 - INFO - Received response from OpenAI: 
2024-01-21 17:31:01,765 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-21 17:31:01,766 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-21 17:31:01,766 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:01,767 - DEBUG - send_request_headers.complete
2024-01-21 17:31:01,767 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:01,767 - DEBUG - send_request_body.complete
2024-01-21 17:31:01,767 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:05,309 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:31:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3395'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'660b08c16e15ea4e803197dffe36f3cf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849359307c60adb9-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:31:05,310 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:31:05,310 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:31:05,311 - DEBUG - receive_response_body.complete
2024-01-21 17:31:05,311 - DEBUG - response_closed.started
2024-01-21 17:31:05,312 - DEBUG - response_closed.complete
2024-01-21 17:31:05,312 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:31:05,314 - INFO - Received response from OpenAI: )
            
        # Generate the UML diagram
        plantuml = PlantUML(config)
        uml = plantuml.generate(repo, output_directory, branch_name, config)

---- Storage ----

Data
    - gitHubAccessToken
    - branchName : String = 'master'

---- Main ----
- thub_access_token : String  // Stores the gitHubAccessToken from the data object
- branch_name : String  // Stores the branchName from the data object
- git_repo_url : String  // Stores the git repository URL
- output_directory : String  // Stores the output directory
- github_access_token : String  // Stores the GitHub access token
- temp_dir : String  // Stores the temporary directory path
- repo : Repository  // Stores the cloned repository
- config : Configuration  // Stores the configuration settings
- plantuml : PlantUML  // Object for UML generation
- uml : UMLDiagram  // Stores the generated UML diagram

---- Methods ----
+ main()  // Entry point of the program
- clone_repo(url: String, temp_dir: String, github_access_token: String) : Repository  // Clone the git repository and returns the Repository object
+ generate_uml()  // Generates the UML diagram
+ load_config()  // Loads the config settings from the file
- clean_up(temp_dir: String)  // Removes the temporary directory and its contents

---- Dependencies ----
Data --> Main
Main -> Repository
Main -> Configuration
Main -> PlantUML
Main -> UMLDiagram
2024-01-21 17:31:05,315 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-21 17:31:05,318 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-21 17:31:05,319 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:05,320 - DEBUG - send_request_headers.complete
2024-01-21 17:31:05,320 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:05,320 - DEBUG - send_request_body.complete
2024-01-21 17:31:05,320 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:07,495 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:31:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2083'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'f7d36f218e832b2d1d9f03b967e4f386'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849359469bbfadb9-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:31:07,496 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:31:07,497 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:31:07,497 - DEBUG - receive_response_body.complete
2024-01-21 17:31:07,497 - DEBUG - response_closed.started
2024-01-21 17:31:07,497 - DEBUG - response_closed.complete
2024-01-21 17:31:07,497 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:31:07,498 - INFO - Received response from OpenAI: 

@startuml

class Repo {
    - tree : Tree
    + tree() : Tree
}

class Tree {
    - items : Collection
    + traverse() : Collection
}

class Config {
    - include : List
}

class File {
    - type : String
    - path : String
}

class TraverseDirectories {
    - repo : Repo
    - temp_dir : String
    - config : Config
    - included_files : Map
    + traverse_directories() : Map
}

class Logger {
    + debug() : void
    + info() : void
}

class GenerateContent {
    - output_directory : String
    + generate_content() : Collection
}

Repo --> Tree
Config --> TraverseDirectories
TraverseDirectories --> File
TraverseDirectories --> Logger
TraverseDirectories --> GenerateContent
Logger --> GenerateContent

@enduml
2024-01-21 17:31:07,499 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-21 17:31:07,501 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-21 17:31:07,502 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:07,502 - DEBUG - send_request_headers.complete
2024-01-21 17:31:07,502 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:07,502 - DEBUG - send_request_body.complete
2024-01-21 17:31:07,503 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:16,985 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 17:31:16,986 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 17:31:16,996 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-21 17:31:16,996 - INFO - [33mPress CTRL+C to quit[0m
2024-01-21 17:31:16,996 - INFO -  * Restarting with stat
2024-01-21 17:31:17,254 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 17:31:17,255 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 17:31:17,262 - WARNING -  * Debugger is active!
2024-01-21 17:31:17,269 - INFO -  * Debugger PIN: 139-904-016
2024-01-21 17:31:26,302 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-21 17:31:26,302 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-21 17:31:26,302 - INFO - Received local_dir: ./output
2024-01-21 17:31:26,302 - INFO - Received gitHubAccessToken: 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
2024-01-21 17:31:26,303 - INFO - Cleaning up temporary directory
2024-01-21 17:31:26,303 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 17:31:26,307 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-21 17:31:26,308 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpz207kg_b'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-21 17:31:29,826 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpz207kg_b'])'s unused stdout: 
2024-01-21 17:31:29,827 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 17:31:29,828 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpz207kg_b, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 17:31:29,834 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmpz207kg_b, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 17:31:29,857 - DEBUG - Type of included_files: <class 'dict'>
2024-01-21 17:31:29,857 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 17:31:29,858 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-21 17:31:29,858 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 17:31:29,858 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-21 17:31:29,858 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-21 17:31:29,858 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-21 17:31:29,859 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-21 17:31:29,873 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-21 17:31:29,981 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104f11310>
2024-01-21 17:31:29,981 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103f95b50> server_hostname='api.openai.com' timeout=5.0
2024-01-21 17:31:30,015 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104b92510>
2024-01-21 17:31:30,015 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:30,016 - DEBUG - send_request_headers.complete
2024-01-21 17:31:30,016 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:30,016 - DEBUG - send_request_body.complete
2024-01-21 17:31:30,016 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:35,010 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:31:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4918'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'502dd9bd8f93685c5f7b2548c8449e03'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=BN7MW3Nomv80Hbfgtdu2Vn_Nxrm1g006Vd2rJ3PALhg-1705879895-1-AZoxOXKm2PSl1ej8K3nX/VTORNXMQnlLrjEXlMS3SeQcUpiq0GlUSWcBuGmo01xQ8ZA6oMg1AnkZDbHYLUnHI6Q=; path=/; expires=Mon, 22-Jan-24 00:01:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=MXe5oXkmqU6t.T2o0oHlnkPHcNAvzxlYO5MSLOrK95Q-1705879895041-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849359e0fdf2672e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:31:35,012 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:31:35,013 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:31:35,014 - DEBUG - receive_response_body.complete
2024-01-21 17:31:35,014 - DEBUG - response_closed.started
2024-01-21 17:31:35,015 - DEBUG - response_closed.complete
2024-01-21 17:31:35,015 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:31:35,019 - INFO - Received response from OpenAI: 
        if not code:
            logging.warning(f"{file_path} is empty. Skipping...")
            continue
        # Parse the code with the OpenAI API
        generated_code += api.parse_code(code)
        file_paths.append(file_path)
    # Write the generated code to a file in the output directory
    output_filename = "generated_code.txt"
    output_path = os.path.join(output_directory, output_filename)
    with open(output_path, 'w') as f:
        f.write(generated_code)
    # Log the output file path
    logging.info(f"Generated code saved to: {output_path}")
    return file_paths, output_path
    
# Get the current directory
current_directory = os.getcwd()
# Define the input directory
input_directory = 'input'
# Define the output directory
output_directory = 'output'

# Create the input directory if it doesn't exist
os.makedirs(input_directory, exist_ok=True)

# Get a list of files in the input directory
files = os.listdir(input_directory)
# Filter out non-code files
code_files = []
for file in files:
    if file.endswith('.py'):
        code_files.append(os.path.join(current_directory, input_directory, file))

# Generate content from the code files
file_paths, output_path = generate_content(code_files, output_directory)

# Display results
print(f"Processed files: {file_paths}")
print(f"Output path: {output_path}")

@startuml

Class OpenAIAPI #orange {
}

Class logging. #orange {
}

Class handlers. #orange {
}

Class generated code {
}

Class parse code #orange {
}

Class output path #orange {
}

Class input directory #orange {
}

Class output directory #orange {
}

Class current directory #orange {
}

Class files #orange {
}

Class code_files #orange {
}

Class generate content #orange {
}

OpenAIAPI o-- logging.
logging. -- handlers.
input directory -- code_files
output directory -- output path
current directory -- input directory
current directory -- output directory
files -- code_files
code_files ..> parse code
output path -- output_directory
current directory -- code_files


generate content -- files
generated code -- parse code
parse code -- OpenAIAPI 
2024-01-21 17:31:35,020 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-21 17:31:35,022 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-21 17:31:35,023 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:35,024 - DEBUG - send_request_headers.complete
2024-01-21 17:31:35,024 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:35,024 - DEBUG - send_request_body.complete
2024-01-21 17:31:35,024 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:37,536 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:31:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2450'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'0f28648c5a5d0c489a8a9787cc9696b5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935a004ea7672e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:31:37,537 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:31:37,537 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:31:37,538 - DEBUG - receive_response_body.complete
2024-01-21 17:31:37,538 - DEBUG - response_closed.started
2024-01-21 17:31:37,538 - DEBUG - response_closed.complete
2024-01-21 17:31:37,538 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:31:37,539 - INFO - Received response from OpenAI: _paths})

    

@startuml

class Main

Main : code = code.strip()

if (not code.strip())
Main --|> Logger
Main : logging.info("Skipping empty file: {file_path}")
Main : continue
else
Main : logging.info("Processing file: {file_path}")
Main --|> API
Main : generated_code_for_file = api.generate_from_code(code)
Main : logging.info("UML code generated for {file_path}: {generated_code_for_file}")
if (not generated_code_for_file or "UML generation failed" in generated_code_for_file)
Main --|> Logger
Main : logging.error("Failed to generate UML diagram for {file_path}")
throw new ValueError("Failed to generate UML diagram for {file_path}")
else
Main : generated_code += generated_code_for_file
Main --|> API
Main : file_name = f"{os.path.basename(file_path)}.puml"
Main : final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
Main : file_paths.append(final_output_path)
end if

Main : logging.info("Generated file paths: {file_paths}")

@enduml
2024-01-21 17:31:37,540 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-21 17:31:37,541 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-21 17:31:37,541 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:37,542 - DEBUG - send_request_headers.complete
2024-01-21 17:31:37,542 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:37,542 - DEBUG - send_request_body.complete
2024-01-21 17:31:37,542 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:40,036 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:31:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2402'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'55e00b9311d3f5d2271268f67b952812'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935a0ffd3f672e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:31:40,037 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:31:40,038 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:31:40,038 - DEBUG - receive_response_body.complete
2024-01-21 17:31:40,039 - DEBUG - response_closed.started
2024-01-21 17:31:40,039 - DEBUG - response_closed.complete
2024-01-21 17:31:40,039 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:31:40,040 - INFO - Received response from OpenAI: 

```
**Class Diagram**
```puml
@startuml

class CodeGenerator {
    - file_paths: list
    - generated_code: str

    + generate_code(instructions: list)
    + _generate_code_for_line(line: str)
    + _write_code_to_file(file: str)
    + _get_file_paths()
    + _format_file_paths()
    + get_output()
}

@enduml
```

**Sequence Diagram**
```puml
@startuml

actor User
participant CodeGenerator
participant Instructions

User -> CodeGenerator: generate_code(instructions)
activate CodeGenerator
CodeGenerator -> Instructions: loop through instructions
activate Instructions
Instructions -> CodeGenerator: _generate_code_for_line(line)
activate CodeGenerator
CodeGenerator -> CodeGenerator: _write_code_to_file(file)
activate CodeGenerator
CodeGenerator -> CodeGenerator: _get_file_paths()
activate CodeGenerator
CodeGenerator -> CodeGenerator: _format_file_paths()
activate CodeGenerator
CodeGenerator --> User: return file_paths, generated_code
deactivate CodeGenerator

@enduml
```
2024-01-21 17:31:40,041 - INFO - UML code generated for src/routes/code_to_uml.py: @startuml
title code_to_uml.py
if not code:
            logging.warning(f"{file_path} is empty. Skipping...")
            continue
        # Parse the code with the OpenAI API
        generated_code += api.parse_code(code)
        file_paths.append(file_path)
    # Write the generated code to a file in the output directory
    output_filename = "generated_code.txt"
    output_path = os.path.join(output_directory, output_filename)
    with open(output_path, 'w') as f:
        f.write(generated_code)
    # Log the output file path
    logging.info(f"Generated code saved to: {output_path}")
    return file_paths, output_path
    
# Get the current directory
current_directory = os.getcwd()
# Define the input directory
input_directory = 'input'
# Define the output directory
output_directory = 'output'

# Create the input directory if it doesn't exist
os.makedirs(input_directory, exist_ok=True)

# Get a list of files in the input directory
files = os.listdir(input_directory)
# Filter out non-code files
code_files = []
for file in files:
    if file.endswith('.py'):
        code_files.append(os.path.join(current_directory, input_directory, file))

# Generate content from the code files
file_paths, output_path = generate_content(code_files, output_directory)

# Display results
print(f"Processed files: {file_paths}")
print(f"Output path: {output_path}")

@startuml

Class OpenAIAPI #orange {
}

Class logging. #orange {
}

Class handlers. #orange {
}

Class generated code {
}

Class parse code #orange {
}

Class output path #orange {
}

Class input directory #orange {
}

Class output directory #orange {
}

Class current directory #orange {
}

Class files #orange {
}

Class code_files #orange {
}

Class generate content #orange {
}

OpenAIAPI o-- logging.
logging. -- handlers.
input directory -- code_files
output directory -- output path
current directory -- input directory
current directory -- output directory
files -- code_files
code_files ..> parse code
output path -- output_directory
current directory -- code_files


generate content -- files
generated code -- parse code
parse code -- OpenAIAPI_paths})

    

@startuml

class Main

Main : code = code.strip()

if (not code.strip())
Main --|> Logger
Main : logging.info("Skipping empty file: {file_path}")
Main : continue
else
Main : logging.info("Processing file: {file_path}")
Main --|> API
Main : generated_code_for_file = api.generate_from_code(code)
Main : logging.info("UML code generated for {file_path}: {generated_code_for_file}")
if (not generated_code_for_file or "UML generation failed" in generated_code_for_file)
Main --|> Logger
Main : logging.error("Failed to generate UML diagram for {file_path}")
throw new ValueError("Failed to generate UML diagram for {file_path}")
else
Main : generated_code += generated_code_for_file
Main --|> API
Main : file_name = f"{os.path.basename(file_path)}.puml"
Main : final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
Main : file_paths.append(final_output_path)
end if

Main : logging.info("Generated file paths: {file_paths}")

@enduml```
**Class Diagram**
```puml
@startuml

class CodeGenerator {
    - file_paths: list
    - generated_code: str

    + generate_code(instructions: list)
    + _generate_code_for_line(line: str)
    + _write_code_to_file(file: str)
    + _get_file_paths()
    + _format_file_paths()
    + get_output()
}

@enduml
2024-01-21 17:31:40,042 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:31:40,043 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:31:40,043 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-21 17:31:40,044 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-21 17:31:40,045 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-21 17:31:40,046 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:40,047 - DEBUG - send_request_headers.complete
2024-01-21 17:31:40,047 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:40,047 - DEBUG - send_request_body.complete
2024-01-21 17:31:40,048 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:44,857 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:31:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4733'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'b087afc7f90262e860de7d891e4d92f1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935a1fabe3672e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:31:44,861 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:31:44,862 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:31:44,862 - DEBUG - receive_response_body.complete
2024-01-21 17:31:44,862 - DEBUG - response_closed.started
2024-01-21 17:31:44,863 - DEBUG - response_closed.complete
2024-01-21 17:31:44,863 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:31:44,865 - INFO - Received response from OpenAI: 
        # Get the commit history
        commits = list(repo.iter_commits())
        
        # Get the list of files in the repository
        files = []
        for file in repo.head.commit.tree.traverse():
            if file.type == 'blob':
                files.append(str(file))
        return {'commits': commits, 'files': files}
    
    except Exception as e:
        logger.error(f"Error cloning repository: {repo_url} - {str(e)}")
        return None


# Define class
class CodeRetriever:
    def __init__(self, access_token):
        self.access_token = access_token
        
    def retrieve_code(self, repo_url):
        # Create temporary directory for storing cloned repository
        temp_dir = 'temp_repo'
        
        # Clone the repository
        result = clone_repo(repo_url, temp_dir, self.access_token)
        if not result:
            return None
        else:
            commits = result['commits']
            files = result['files']
            return {'commits': commits, 'files': files}

```

@startuml

package "Import" {
    class git
    class json
    class os

    package "logging" {
        class logging
        package "handlers" {
            class handlers
        }
    }
}

git --> handlers
json --> handlers
os --> handlers

class CodeRetriever {
    -access_token: string
    +retrieve_code(repo_url: string)
}

logging <|-- CodeRetriever

note right of CodeRetriever: Create temporary directory \nfor storing cloned repo
note left of CodeRetriever: Log to file \nwith rotation

CodeRetriever --> git: clone_repo(repo_url, temp_dir, access_token)
handlers --> logging: write to file
CodeRetriever --> handlers: set level
CodeRetriever --> handlers: set formatter
CodeRetriever --> handlers: add handler
CodeRetriever --> logger: set level
CodeRetriever --> logger: add handler

@enduml
2024-01-21 17:31:44,866 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-21 17:31:44,868 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-21 17:31:44,869 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:44,870 - DEBUG - send_request_headers.complete
2024-01-21 17:31:44,870 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:44,870 - DEBUG - send_request_body.complete
2024-01-21 17:31:44,871 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:45,504 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:31:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'541'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'a62c1c2959dd4a331cbf4562203d3c0a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935a3dc8a5672e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:31:45,506 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:31:45,507 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:31:45,507 - DEBUG - receive_response_body.complete
2024-01-21 17:31:45,508 - DEBUG - response_closed.started
2024-01-21 17:31:45,508 - DEBUG - response_closed.complete
2024-01-21 17:31:45,509 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:31:45,510 - INFO - Received response from OpenAI:  if file.path in ignore_list:
                 continue
             # Check if the file is in the include list
             if include_list:
                 for pattern in include_list:
                     if fnmatch.fnmatch(file.path, pattern):
           
2024-01-21 17:31:45,511 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-21 17:31:45,513 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-21 17:31:45,515 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:45,515 - DEBUG - send_request_headers.complete
2024-01-21 17:31:45,516 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:45,516 - DEBUG - send_request_body.complete
2024-01-21 17:31:45,516 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:47,152 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:31:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1546'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'e464dd2d08cbce8164e85429b1d7df72'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935a41cdee672e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:31:47,152 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:31:47,153 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:31:47,153 - DEBUG - receive_response_body.complete
2024-01-21 17:31:47,153 - DEBUG - response_closed.started
2024-01-21 17:31:47,153 - DEBUG - response_closed.complete
2024-01-21 17:31:47,153 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:31:47,154 - INFO - Received response from OpenAI: 

@startuml

class Main {
    - include_list: String[]
    - ignore_list: String[]
    
    + retrieve_files(): Dictionary
    
    + Main(include_list, ignore_list): void
}

Main -- file.path: Boolean
Main -- ignored_file: Boolean
Main -- file.abspath: Path

class Logger {
    - log: String
    
    + info(message): void
    + warning(message): void
    + error(message): void
}

Main --> Logger: Uses

class File {
    - path: Path
    - abspath: Path
    
    + endswith(extension): Boolean
    + read(): String
}

Main -- File: Has

File --> Logger: Uses

@enduml
2024-01-21 17:31:47,154 - INFO - UML code generated for src/routes/retrieve_code.py: @startuml
title retrieve_code.py
# Get the commit history
        commits = list(repo.iter_commits())
        
        # Get the list of files in the repository
        files = []
        for file in repo.head.commit.tree.traverse():
            if file.type == 'blob':
                files.append(str(file))
        return {'commits': commits, 'files': files}
    
    except Exception as e:
        logger.error(f"Error cloning repository: {repo_url} - {str(e)}")
        return None


# Define class
class CodeRetriever:
    def __init__(self, access_token):
        self.access_token = access_token
        
    def retrieve_code(self, repo_url):
        # Create temporary directory for storing cloned repository
        temp_dir = 'temp_repo'
        
        # Clone the repository
        result = clone_repo(repo_url, temp_dir, self.access_token)
        if not result:
            return None
        else:
            commits = result['commits']
            files = result['files']
            return {'commits': commits, 'files': files}

```

@startuml

package "Import" {
    class git
    class json
    class os

    package "logging" {
        class logging
        package "handlers" {
            class handlers
        }
    }
}

git --> handlers
json --> handlers
os --> handlers

class CodeRetriever {
    -access_token: string
    +retrieve_code(repo_url: string)
}

logging <|-- CodeRetriever

note right of CodeRetriever: Create temporary directory \nfor storing cloned repo
note left of CodeRetriever: Log to file \nwith rotation

CodeRetriever --> git: clone_repo(repo_url, temp_dir, access_token)
handlers --> logging: write to file
CodeRetriever --> handlers: set level
CodeRetriever --> handlers: set formatter
CodeRetriever --> handlers: add handler
CodeRetriever --> logger: set level
CodeRetriever --> logger: add handler

@endumlif file.path in ignore_list:
                 continue
             # Check if the file is in the include list
             if include_list:
                 for pattern in include_list:
                     if fnmatch.fnmatch(file.path, pattern):@startuml

class Main {
    - include_list: String[]
    - ignore_list: String[]
    
    + retrieve_files(): Dictionary
    
    + Main(include_list, ignore_list): void
}

Main -- file.path: Boolean
Main -- ignored_file: Boolean
Main -- file.abspath: Path

class Logger {
    - log: String
    
    + info(message): void
    + warning(message): void
    + error(message): void
}

Main --> Logger: Uses

class File {
    - path: Path
    - abspath: Path
    
    + endswith(extension): Boolean
    + read(): String
}

Main -- File: Has

File --> Logger: Uses

@enduml
2024-01-21 17:31:47,154 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:31:47,154 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:31:47,155 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-21 17:31:47,155 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-21 17:31:47,155 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-21 17:31:47,156 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:47,156 - DEBUG - send_request_headers.complete
2024-01-21 17:31:47,156 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:47,157 - DEBUG - send_request_body.complete
2024-01-21 17:31:47,157 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:50,312 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:31:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3054'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'7fd84ce7203337f8d5a0aeac21902ccc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935a4c1bd2672e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:31:50,312 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:31:50,312 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:31:50,312 - DEBUG - receive_response_body.complete
2024-01-21 17:31:50,313 - DEBUG - response_closed.started
2024-01-21 17:31:50,313 - DEBUG - response_closed.complete
2024-01-21 17:31:50,313 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:31:50,313 - INFO - Received response from OpenAI: t_username = data.get('gitUsername')
    git_password = data.get('gitPassword')

## Class diagram:

@startuml
class UmlFromRepo {
    - git_repo_url: string
    - output_directory: string
    - git_username: string
    - git_password: string
    - log_directory: string
    - log_filename: string
    - logger: logger

    + process_request(data): void
}

class RetrieveCode {
    - clone_repo(git_repo_url, output_directory, git_username=null, git_password=null): void
    - retrieve_code(output_directory): string[]
}

class CodeToUml {
    - generate_content(files): void
}
@enduml

## Activity diagram:

@startuml
start
:Initialize logging;
if (Output directory does not exist?) then (yes)
    :Create output directory;
else (no)
    :Continue;
endif
:Retrieve request data;
:Process request;
if (Git repo URL is valid?) then (yes)
    :Clone repository;
    :Retrieve code from repository;
    if (Code is successfully retrieved?) then (yes)
        :Generate UML content;
        if (UML content is generated successfully?) then (yes)
            :Write UML content to file;
            :Log success message;
        else (no)
            :Log error message;
        endif
    else (no)
        :Log error message;
    endif
else (no)
    :Log error message;
endif
stop
@enduml
2024-01-21 17:31:50,314 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-21 17:31:50,314 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-21 17:31:50,315 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:50,315 - DEBUG - send_request_headers.complete
2024-01-21 17:31:50,315 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:50,316 - DEBUG - send_request_body.complete
2024-01-21 17:31:50,316 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:58,089 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:31:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'7598'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'33e7ccf9e63d438f8aad05574d534a33'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935a605a33672e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:31:58,090 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:31:58,090 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:31:58,090 - DEBUG - receive_response_body.complete
2024-01-21 17:31:58,091 - DEBUG - response_closed.started
2024-01-21 17:31:58,091 - DEBUG - response_closed.complete
2024-01-21 17:31:58,091 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:31:58,092 - INFO - Received response from OpenAI: )

        # Generate UML diagrams
        generate_uml_diagrams(repo, config, output_directory)
        
Note: I am unable to include the 'generate_uml_diagrams' method as it is not defined in the code.

@startuml
class Main {
    - github_access_token : String
    - branch_name : String
    - git_repo_url : String
    - output_directory: String
    - logger : Logger
    - temp_dir : String
    - repo : Repository
    - config : JSON

    + Main()
    + Main(github_access_token, branch_name)
    + Main(github_access_token, branch_name, git_repo_url)
    + Main(github_access_token, branch_name, git_repo_url, output_directory)
    + Main(github_access_token, branch_name, git_repo_url, output_directory, logger)
    + Main(github_access_token, branch_name, git_repo_url, output_directory, logger, temp_dir)

    - validate_parameters() : boolean
    - clone_repo(git_repo_url, temp_dir, github_access_token) : Repository
    - generate_uml_diagrams(repo, config, output_directory)

    + run() : Object
    - cleanup_temp_dir()

    # Missing required parameters

    + <<create>> Logger
    + <<create>> Repository
    + <<create>> JSON
    + <<use>> tempfile
    + <<use>> shutil
    + <<use>> json

    |||

    class tempfile {
        + mkdtemp() : String
    }

    class shutil {
        + rmtree(directory)
    }

    class json {
        + load(file) : JSON
    }
}

Main o--> Logger
Main o--> Repository
Main o--> tempfile
Main o--> shutil
Main o--> json
Main --> generate_uml_diagrams
Main --> clone_repo
Main --> tempfile : use
Main --> shutil : use
Main --> json : use

Logger --> logger : has a
Repository --> repo : has a
JSON --> config : has a

main : Gets data
main --> data : gets data

main --> "if not git_repo_url or not output_directory or not github_access_token or not branch_name"
main --> Logger : <<create>>
main --> "Missing required parameters"
main --> JSON : <<create>>
main --> "Error during UML generation"
main --> return {"error": "Missing required parameters"}, 400

Logger --> error(message)
"Missing required parameters" --> error : Logs message

main --> tempfile : <<use>>
"Error during UML generation" --> tempfile
tempfile --> mkdtemp()
tempfile : return temp_dir

tempfile --> shutil : <<use>>
main --> "Cleaning up temporary directory" : info
"Cleaning up temporary directory" --> logger : call .info()

tempfile --> rmtree(temp_dir)

main --> "Clone the repository"
"Clone the repository" --> clone_repo
clone_repo --> git_repo_url, temp_dir, github_access_token : parameters
clone_repo --> Repository : <<create>>
clone_repo : return repo

main --> json : <<use>>
main --> config : <<create>>
main --> "Generate UML diagrams"
"Generate UML diagrams" --> generate_uml_diagrams
generate_uml_diagrams --> repo, config, output_directory : parameters
generate_uml_diagrams --> Repository : use
generate_uml_diagrams --> JSON : use
2024-01-21 17:31:58,093 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-21 17:31:58,094 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-21 17:31:58,095 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:58,096 - DEBUG - send_request_headers.complete
2024-01-21 17:31:58,096 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:58,096 - DEBUG - send_request_body.complete
2024-01-21 17:31:58,096 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:31:58,350 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:31:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'152'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'9c74b72a7412d17ab5521824db0f75c0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935a906ce5672e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:31:58,351 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:31:58,351 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:31:58,351 - DEBUG - receive_response_body.complete
2024-01-21 17:31:58,351 - DEBUG - response_closed.started
2024-01-21 17:31:58,352 - DEBUG - response_closed.complete
2024-01-21 17:31:58,352 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:31:58,353 - INFO - Received response from OpenAI: 
2024-01-21 17:31:58,354 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-21 17:31:58,355 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-21 17:31:58,357 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:31:58,357 - DEBUG - send_request_headers.complete
2024-01-21 17:31:58,357 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:31:58,357 - DEBUG - send_request_body.complete
2024-01-21 17:31:58,358 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:32:02,246 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:32:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3800'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'b23eac16a79e752f7badb67145f9bf35'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935a920ef1672e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:32:02,247 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:32:02,247 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:32:02,247 - DEBUG - receive_response_body.complete
2024-01-21 17:32:02,247 - DEBUG - response_closed.started
2024-01-21 17:32:02,248 - DEBUG - response_closed.complete
2024-01-21 17:32:02,248 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:32:02,249 - INFO - Received response from OpenAI:  ```plantuml
      @startuml
         class t {
            -included_files
            -output_directory
            
            +__init__(included_files, output_directory)
            +generate_diagrams()
         }
         
         class logger {
            -log_messages
            -log_errors
            
            +info(message)
            +error(message)
         }
         
         class final_output_paths {
            -paths
            
            +add_path(path)
         }
         
         t *.. logger
         
         t *-- final_output_paths
         
         final_output_paths *- "1..*" path
         
         t ..> "repository url" :use
         t ..> "path list" :use
         
         class git_repo_url {
            -url
         }
         
         class except {
            -e
         }
         
         t ..> except
         
         class shutil {
            +rmtree()
         }
         
         t ..> shutil
         
         logger "1" *- "1..*" log_messages
         logger "1" *- "1..*" log_errors
         
         class output {
            -message
            -details
            
            +get_message()
            +get_details()
         }
         
         t ..> output
         
         note right of t : calling function
         note left of final_output_paths : updating list
         note left of logger : logging path
         note bottom of output : returning message and details
         
      @enduml
  ```
2024-01-21 17:32:02,250 - INFO - UML code generated for src/routes/uml_from_repo.py: @startuml
title uml_from_repo.py
t_username = data.get('gitUsername')
    git_password = data.get('gitPassword')

## Class diagram:

@startuml
class UmlFromRepo {
    - git_repo_url: string
    - output_directory: string
    - git_username: string
    - git_password: string
    - log_directory: string
    - log_filename: string
    - logger: logger

    + process_request(data): void
}

class RetrieveCode {
    - clone_repo(git_repo_url, output_directory, git_username=null, git_password=null): void
    - retrieve_code(output_directory): string[]
}

class CodeToUml {
    - generate_content(files): void
}
@enduml
2024-01-21 17:32:02,250 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:32:02,251 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:32:02,251 - INFO - Skipping empty file: src/scripts/__init__.py
2024-01-21 17:32:02,251 - INFO - Processing file: src/scripts/execute_generate_uml.py
2024-01-21 17:32:02,251 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import json
import os
import requests
import logging
from logging import handlers
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure logging to write to a file
log_directory = '../../logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'execute_generate_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


# Configure logging
logging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))
# Configuration file path
config_file_path = os.path.join(cu
2024-01-21 17:32:02,253 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nimport json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(cu", 'max_tokens': 1024}}
2024-01-21 17:32:02,254 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:32:02,254 - DEBUG - send_request_headers.complete
2024-01-21 17:32:02,254 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:32:02,255 - DEBUG - send_request_body.complete
2024-01-21 17:32:02,255 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:32:08,290 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:32:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'5924'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'fdff95096e910d543425a8c23cfc7c6b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935aaa68d9672e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:32:08,291 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:32:08,292 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:32:08,292 - DEBUG - receive_response_body.complete
2024-01-21 17:32:08,292 - DEBUG - response_closed.started
2024-01-21 17:32:08,292 - DEBUG - response_closed.complete
2024-01-21 17:32:08,293 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:32:08,294 - INFO - Received response from OpenAI: rrent_dir, 'config.yml')

# Load configuration file
with open(config_file_path) as config_file:
    config = yaml.load(config_file, Loader=yaml.FullLoader)

@inituml
class UMLGenerator:
  # Instance variable
  config = None

  def __init__(self):
    self.config = config

  def generate_uml(self, source_code, style='default'):
    """
    Generates UML diagrams for the given source code using the specified style.
    :param source_code: The source code to generate UML from
    :param style: The style of the generated UML diagrams (default or plantuml)
    :return: The generated UML diagrams in string format
    """
    try:
        # Make a POST request to the UML generation API
        api_url = self.config['uml_generator_api']  # Retrieve API URL from config file
        payload = {'source_code': source_code, 'style': style}
        response = requests.post(api_url, json=payload)  # Send POST request with source code and style
        response.raise_for_status()  # Raise error if response code is not in 200 range
        # Convert response to JSON format
        result = response.json()
        # Return generated UML diagrams
        return result['uml_diagrams']
    except requests.exceptions.HTTPError as e:
        logger.error('An HTTP error occurred: %s', e)
    except requests.exceptions.ConnectionError as e:
        logger.error('A connection error occurred: %s', e)
    except requests.exceptions.Timeout as e:
        logger.error('The request timed out: %s', e)
    except requests.exceptions.RequestException as e:
        logger.error('An unknown error occurred: %s', e)

    
/```

UML Diagram:

```
@startuml

class UMLGenerator {
    - config
    + __init__()
    + generate_uml()
}

UMLGenerator --|> inituml
UMLGenerator --> requests
UMLGenerator --> logging
UMLGenerator --> json
UMLGenerator --> os
UMLGenerator --> dotenv
UMLGenerator --> yaml
UMLGenerator --> handlers

requests --> requests.exceptions
requests --> requests.exceptions.exceptions
requests --> requests.exceptions.HTTPError
requests --> requests.exceptions.ConnectionError
requests --> requests.exceptions.Timeout
requests --> requests.exceptions.RequestException

logging --> logging.handlers
logging --> logging.basicConfig
logging --> logging.getLogger
logging --> logging.Formatter
logging --> logging.RotatingFileHandler

handlers --> handlers.RotatingFileHandler
handlers --> handlers.BaseRotatingHandler

UMLGenerator o-- config

config --> yaml.load
config --> yaml.FullLoader

@enduml
```

2024-01-21 17:32:08,295 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

rrent_dir, 'config.json')

# Read configuration from the JSON file
with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

# Retrieve the GitHub access token from environment variables
github_token = os.getenv('GITHUB_PAT')

# Endpoint URL
url = 'http://127.0.0.1:5000/generate-uml'

# Headers
headers = {
    'Content-Type': 'application/json'
}

# Update the GitHub access token and local directory in the config data
config_data['gitHubAccessToken'] = github_token
config_data['local_dir'] = os.path.join(current_dir, '../..', 'output')

# Log the JSON data being sent in the request
logging.info(f'Sending JSON data to {url}:')
logging.info(json.dumps(config_data, indent=2))

try:
    # Make the POST request
    response = requests.post(url, headers=headers, json=config_data)

    # Log the response from the server
    logging.info(f'Response from server ({url}):')
    logging.info(f'Status Code: {response.status_code}')
    logging.info(f'Response Text: {response.text}')

    #
2024-01-21 17:32:08,297 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nrrent_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    #", 'max_tokens': 1024}}
2024-01-21 17:32:08,299 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:32:08,299 - DEBUG - send_request_headers.complete
2024-01-21 17:32:08,299 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:32:08,300 - DEBUG - send_request_body.complete
2024-01-21 17:32:08,300 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:32:10,330 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:32:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1927'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'e6f1036aa75ec0fabc1aed2c58f82ca7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935ad03dc5672e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:32:10,334 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:32:10,335 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:32:10,336 - DEBUG - receive_response_body.complete
2024-01-21 17:32:10,336 - DEBUG - response_closed.started
2024-01-21 17:32:10,336 - DEBUG - response_closed.complete
2024-01-21 17:32:10,337 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:32:10,338 - INFO - Received response from OpenAI:  Check if response was successful
    if response.status_code == 200:
        print('UML diagrams generated successfully!')
    
    # If response is not successful, print error message
    else:
        print('An error occurred while generating UML diagrams.')
        
except Exception as e:
    # Log any exceptions that occur during the request
    logging.error(f'An exception occurred during the request: {e}')
```

@startuml
class Main #LightSkyBlue{
+ current_dir : String
+ config_file_path : String
+ config_data : JSONObject
+ github_token : String
+ url : String
+ headers : Map<String,String>

+read_config()
+retrieve_github_token()
+update_config_data()
+make_post_request()
+print_response()

}

Main --down> config_data
Main --down> github_token
Main --down> url
Main --down> headers
Main --down> config_file_path

@enduml
2024-01-21 17:32:10,339 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

 Print the response from the server
    print(response.text)

    # Save the response to a file in the output directory
    output_dir = os.path.join(current_dir, '../..', 'output')
    os.makedirs(output_dir, exist_ok=True)
    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:
        json.dump(response.json(), output_file, indent=2)

except Exception as e:
    # Log any exceptions that occur
    logging.error(f'Error occurred: {str(e)}')
2024-01-21 17:32:10,341 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')", 'max_tokens': 1024}}
2024-01-21 17:32:10,342 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 17:32:10,343 - DEBUG - send_request_headers.complete
2024-01-21 17:32:10,343 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 17:32:10,343 - DEBUG - send_request_body.complete
2024-01-21 17:32:10,343 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 17:32:12,426 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jan 2024 23:32:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1929'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'f71d2c8de1e12707db622d55cc695182'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84935adcfe52672e-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 17:32:12,426 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 17:32:12,427 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 17:32:12,427 - DEBUG - receive_response_body.complete
2024-01-21 17:32:12,427 - DEBUG - response_closed.started
2024-01-21 17:32:12,427 - DEBUG - response_closed.complete
2024-01-21 17:32:12,427 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 17:32:12,428 - INFO - Received response from OpenAI: 

@startuml

class Server
Server : - response
Server : - text
Server : - json
Server : + printResponse()

class os
os : - output dir
os : - os.makedirs()
os : - output_file

Server --> os : save response

class logging

Server --> logging : log exceptions
logging : - e

@enduml

@startuml

Server : - response

Server -> Server: print(text)
Server: response --> print

Server -> os: output_dir
Server: os.makedirs(output_dir)

os --> output_dir
Server -> Server: open(output_json, 'w')
Server: response.json() --> open
Server: ident = 2
os --> output_json
Server -> logging : log exception
Server: exception --> logging
logging --> print

@enduml
2024-01-21 17:32:12,429 - INFO - UML code generated for src/scripts/execute_generate_uml.py: @startuml
title execute_generate_uml.py
rrent_dir, 'config.yml')

# Load configuration file
with open(config_file_path) as config_file:
    config = yaml.load(config_file, Loader=yaml.FullLoader)

@inituml
class UMLGenerator:
  # Instance variable
  config = None

  def __init__(self):
    self.config = config

  def generate_uml(self, source_code, style='default'):
    """
    Generates UML diagrams for the given source code using the specified style.
    :param source_code: The source code to generate UML from
    :param style: The style of the generated UML diagrams (default or plantuml)
    :return: The generated UML diagrams in string format
    """
    try:
        # Make a POST request to the UML generation API
        api_url = self.config['uml_generator_api']  # Retrieve API URL from config file
        payload = {'source_code': source_code, 'style': style}
        response = requests.post(api_url, json=payload)  # Send POST request with source code and style
        response.raise_for_status()  # Raise error if response code is not in 200 range
        # Convert response to JSON format
        result = response.json()
        # Return generated UML diagrams
        return result['uml_diagrams']
    except requests.exceptions.HTTPError as e:
        logger.error('An HTTP error occurred: %s', e)
    except requests.exceptions.ConnectionError as e:
        logger.error('A connection error occurred: %s', e)
    except requests.exceptions.Timeout as e:
        logger.error('The request timed out: %s', e)
    except requests.exceptions.RequestException as e:
        logger.error('An unknown error occurred: %s', e)

    
/```

UML Diagram:

```
@startuml

class UMLGenerator {
    - config
    + __init__()
    + generate_uml()
}

UMLGenerator --|> inituml
UMLGenerator --> requests
UMLGenerator --> logging
UMLGenerator --> json
UMLGenerator --> os
UMLGenerator --> dotenv
UMLGenerator --> yaml
UMLGenerator --> handlers

requests --> requests.exceptions
requests --> requests.exceptions.exceptions
requests --> requests.exceptions.HTTPError
requests --> requests.exceptions.ConnectionError
requests --> requests.exceptions.Timeout
requests --> requests.exceptions.RequestException

logging --> logging.handlers
logging --> logging.basicConfig
logging --> logging.getLogger
logging --> logging.Formatter
logging --> logging.RotatingFileHandler

handlers --> handlers.RotatingFileHandler
handlers --> handlers.BaseRotatingHandler

UMLGenerator o-- config

config --> yaml.load
config --> yaml.FullLoader

@enduml
2024-01-21 17:32:12,429 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:32:12,429 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:32:12,429 - INFO - Generated file paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 17:32:12,429 - INFO - Final output paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 17:32:12,429 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 17:32:12,430 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 17:32:12,430 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 17:32:12,430 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 17:32:12,430 - INFO - Cleaning up temporary directory
2024-01-21 17:32:12,590 - INFO - 127.0.0.1 - - [21/Jan/2024 17:32:12] "POST /generate-uml HTTP/1.1" 200 -
2024-01-21 18:12:42,359 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 18:12:42,361 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 18:12:42,370 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-01-21 18:12:42,371 - INFO - [33mPress CTRL+C to quit[0m
2024-01-21 18:12:42,371 - INFO -  * Restarting with stat
2024-01-21 18:12:42,645 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-21 18:12:42,646 - DEBUG - load_verify_locations cafile='/Users/preston/Documents/gitRepos/diagrammr/venv/lib/python3.11/site-packages/certifi/cacert.pem'
2024-01-21 18:12:42,654 - WARNING -  * Debugger is active!
2024-01-21 18:12:42,661 - INFO -  * Debugger PIN: 139-904-016
2024-01-21 18:12:45,697 - INFO - Received JSON data: {'gitRepoUrl': 'https://github.com/mprestonsparks/diagrammr.git', 'local_dir': '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output', 'gitHubAccessToken': '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'}
2024-01-21 18:12:45,697 - INFO - Received gitRepoUrl: https://github.com/mprestonsparks/diagrammr.git
2024-01-21 18:12:45,697 - INFO - Received local_dir: ./output
2024-01-21 18:12:45,697 - INFO - Received gitHubAccessToken: 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
2024-01-21 18:12:45,698 - INFO - Cleaning up temporary directory
2024-01-21 18:12:45,698 - INFO - Cloning repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 18:12:45,700 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')
2024-01-21 18:12:45,701 - DEBUG - Popen(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp6zrdjc1l'], cwd=/Users/preston/Documents/gitRepos/diagrammr, stdin=None, shell=False, universal_newlines=True)
2024-01-21 18:12:52,302 - DEBUG - Cmd(['git', 'clone', '-v', '--', 'https://*****@github.com/mprestonsparks/diagrammr.git', '/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp6zrdjc1l'])'s unused stdout: 
2024-01-21 18:12:52,304 - INFO - Successfully cloned repository: https://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@github.com/mprestonsparks/diagrammr.git
2024-01-21 18:12:52,304 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp6zrdjc1l, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 18:12:52,310 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/var/folders/pc/c8njlgpx5t52sk4gvk520t780000gn/T/tmp6zrdjc1l, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-01-21 18:12:52,332 - DEBUG - Type of included_files: <class 'dict'>
2024-01-21 18:12:52,333 - DEBUG - Value of included_files: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 18:12:52,333 - INFO - Saving UML diagram to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output
2024-01-21 18:12:52,333 - INFO - Files to process: {'src/routes/__init__.py': '', 'src/routes/code_to_uml.py': '# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'src/routes/retrieve_code.py': 'import git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        return repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'src/routes/uml_from_repo.py': '# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'uml_from_repo.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get(\'gitRepoUrl\')\n    output_directory = data.get(\'local_dir\')  # Get the output directory from the request data\n    github_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_content(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'src/scripts/__init__.py': '', 'src/scripts/execute_generate_uml.py': "import json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(current_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    # Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')"}
2024-01-21 18:12:52,333 - INFO - Skipping empty file: src/routes/__init__.py
2024-01-21 18:12:52,333 - INFO - Processing file: src/routes/code_to_uml.py
2024-01-21 18:12:52,333 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# code_to_uml.py
import os
from openai_api import OpenAIAPI 
import logging
from logging import handlers  


# Create an instance of the OpenAI API
api = OpenAIAPI()

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'code_to_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def generate_content(files, output_directory):
    logging.info(f"Files to process: {files}")  # Log the files dictionary
    generated_code = ""  # Initialize generated_code
    file_paths = []  # Initialize a list to store the file paths
    for file_path, code in files.items():
        # Skip if the file is empty
2024-01-21 18:12:52,334 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n# code_to_uml.py\nimport os\nfrom openai_api import OpenAIAPI \nimport logging\nfrom logging import handlers  \n\n\n# Create an instance of the OpenAI API\napi = OpenAIAPI()\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'code_to_uml.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef generate_content(files, output_directory):\n    logging.info(f"Files to process: {files}")  # Log the files dictionary\n    generated_code = ""  # Initialize generated_code\n    file_paths = []  # Initialize a list to store the file paths\n    for file_path, code in files.items():\n        # Skip if the file is empty', 'max_tokens': 1024}}
2024-01-21 18:12:52,349 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-21 18:12:52,469 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1071961d0>
2024-01-21 18:12:52,470 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106595b50> server_hostname='api.openai.com' timeout=5.0
2024-01-21 18:12:52,508 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1073131d0>
2024-01-21 18:12:52,508 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 18:12:52,509 - DEBUG - send_request_headers.complete
2024-01-21 18:12:52,509 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 18:12:52,509 - DEBUG - send_request_body.complete
2024-01-21 18:12:52,509 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 18:12:57,602 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 22 Jan 2024 00:12:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4879'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'ab2a1e730ff77af7993b4bab65a926f6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=G79sAlRXZJwRQnd56r5e41yRy75mWxOVIS9iT1R6hug-1705882377-1-AVXd7YYY0dkGArRdA58etrUf5MzJitgZiafXqSGzKKECodk67W2cP2QlhRXuzrXlM6EppsfI3wTpXZB5SXI99RI=; path=/; expires=Mon, 22-Jan-24 00:42:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=bCiSv7QSP4Whw_VGPTNcVMj2u7ZLJ5kBvCxPx21Si3A-1705882377531-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493967cba7c44e2-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 18:12:57,607 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 18:12:57,608 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 18:12:57,608 - DEBUG - receive_response_body.complete
2024-01-21 18:12:57,609 - DEBUG - response_closed.started
2024-01-21 18:12:57,609 - DEBUG - response_closed.complete
2024-01-21 18:12:57,609 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 18:12:57,612 - INFO - Received response from OpenAI: 
        if code == "":
            continue
        # Add file path to list
        file_paths.append(file_path)
        # Generate code from the OpenAI API
        generated_code += api.generate(code)  # Concatenate the generated code
    # Write the generated code to a file in the output directory
    with open(os.path.join(output_directory, 'generated_code.py'), 'w+') as f:
        f.write(generated_code)
    return file_paths  # Return the list of processed file paths

````

@startuml

class OpenAIAPI {
    # api_key: string
    +generate(text: string): string
}

class Logging {
    -logger: Logger
    -level: int
    +Debug()
    +Info()
    +Warn()
    +Error()
}

class Logger {
    -log_handler: RotatingFileHandler
    -log_formatter: Formatter
    -log_filename: string
    +setLevel(level: int)
    +addHandler(handler: Handler)
    +debug(msg: string)
    +info(msg: string)
    +warn(msg: string)
    +error(msg: string)
}

class Handler {
    #level: int
    +setFormatter(formatter: Formatter)
    +emit(record: LogRecord)
}

class RotatingFileHandler {
    -maxBytes: int
    -backupCount: int
    +doRollover()
    +rotate(filename: string)
}

class Formatter {
    +format(record: LogRecord): string
}

class File {
    -file_name: string
    -content: string
    +write(content: string)
}

class CodeToUML {
    -api: OpenAIAPI
    -file_paths: list
    -generated_code: string
    +generate_content(files: dict, output_directory: string): list
}

CodeToUML --> OpenAIAPI
CodeToUML --> Logging
Logging --> Logger
Logger --> Handler
Handler --> Formatter
RotatingFileHandler <|-- Handler
File <|-- CodeToUML

@enduml
2024-01-21 18:12:57,614 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:


        if not code.strip():
            logging.info(f"Skipping empty file: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        generated_code_for_file = api.generate_from_code(code)
        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code
        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:
            logging.error(f"Failed to generate UML diagram for {file_path}")
            raise ValueError(f"Failed to generate UML diagram for {file_path}")
        generated_code += generated_code_for_file

        # Save the UML code for each file to a separate .puml file
        file_name = f"{os.path.basename(file_path)}.puml"
        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))
        file_paths.append(final_output_path)  # Append the file path to the list

    logging.info(f"Generated file paths: {file
2024-01-21 18:12:57,616 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n\n        if not code.strip():\n            logging.info(f"Skipping empty file: {file_path}")\n            continue\n        logging.info(f"Processing file: {file_path}")\n        generated_code_for_file = api.generate_from_code(code)\n        logging.info(f"UML code generated for {file_path}: {generated_code_for_file}")  # Log the generated UML code\n        if not generated_code_for_file or "UML generation failed" in generated_code_for_file:\n            logging.error(f"Failed to generate UML diagram for {file_path}")\n            raise ValueError(f"Failed to generate UML diagram for {file_path}")\n        generated_code += generated_code_for_file\n\n        # Save the UML code for each file to a separate .puml file\n        file_name = f"{os.path.basename(file_path)}.puml"\n        final_output_path = api.save_generated_output(generated_code_for_file, os.path.join(output_directory, file_name))\n        file_paths.append(final_output_path)  # Append the file path to the list\n\n    logging.info(f"Generated file paths: {file', 'max_tokens': 1024}}
2024-01-21 18:12:57,617 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 18:12:57,617 - DEBUG - send_request_headers.complete
2024-01-21 18:12:57,618 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 18:12:57,618 - DEBUG - send_request_body.complete
2024-01-21 18:12:57,618 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 18:13:02,315 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 22 Jan 2024 00:13:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'4438'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'9dbaf05da78093bcf016d9cbd07cce45'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493969cc8fa44e2-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 18:13:02,316 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 18:13:02,317 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 18:13:02,317 - DEBUG - receive_response_body.complete
2024-01-21 18:13:02,318 - DEBUG - response_closed.started
2024-01-21 18:13:02,318 - DEBUG - response_closed.complete
2024-01-21 18:13:02,318 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 18:13:02,319 - INFO - Received response from OpenAI: _paths})
    
    @startuml

    |     Main     |
    |--------------|
    | +code        |
    |--------------|
    | +not strip() |                  ------------
    |    +logging.in "Skipping empty file:<$file_path$>" |    |<--        |
    |              |                                         |           |
    |              |                                         |<--        |
    |              |                        True             |           |
    |              |<----------------------------------------|           |
    |              |                                False      |           |
    |              |  -----                                     |           |
    |              +-->|strip()|    --------                |           |
    |                   ----------    |      |               |           |
    |                        |        |      |  <--------   |           |
    |                        |        |      |       True   |           |
    |                        |        |      |   ------------           |
    |             |<---------   -------------->|not generated_code
    |logging.info|                             ----------------->|generated_code_for_file|   | generated_code
    |        "Processing file:<$file_path$>"                         -------------------->|
    |                                                                          |      |
    |                                                                          |      |
    |                                                                          |<-----
    |                                                                ----------- |
    |                                                          |     |<----
    |                                       ------------       |     |
    |                                       |    True  |       |     |
    |                                       |----------->|not generated_code_for_file|
    |                                       |<--------          |  or  |
    |                                       |       False       |"UML generation failed" in generated_code_for_file
    |                                       -----------       |   ------------
    |                                                           |       |<-----
    |                                                               |       |
    |<-----                                                          |       |                                             
    |               logging.error "Failed to generate UML diagram for:<$file_path$>" ---| 
    |<-----           raise ValueError "Failed to generate UML diagram for:<$file_path$>" |
    | generated_code += generated_code_for_file                                            |
    |--------------------------------------------------------------------------------------|


    @enduml
2024-01-21 18:13:02,321 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

_paths}")
    # Return the list of file paths and the generated code
    return file_paths, generated_code
2024-01-21 18:13:02,322 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n_paths}")\n    # Return the list of file paths and the generated code\n    return file_paths, generated_code', 'max_tokens': 1024}}
2024-01-21 18:13:02,323 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 18:13:02,324 - DEBUG - send_request_headers.complete
2024-01-21 18:13:02,324 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 18:13:02,324 - DEBUG - send_request_body.complete
2024-01-21 18:13:02,324 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 18:13:03,515 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 22 Jan 2024 00:13:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1030'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'459824468a1125cef2be2f41fb9f594f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849396ba0c5f44e2-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 18:13:03,515 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 18:13:03,516 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 18:13:03,516 - DEBUG - receive_response_body.complete
2024-01-21 18:13:03,516 - DEBUG - response_closed.started
2024-01-21 18:13:03,516 - DEBUG - response_closed.complete
2024-01-21 18:13:03,516 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 18:13:03,517 - INFO - Received response from OpenAI: 

UML diagrams cannot be created for code snippets as they do not contain enough information about the structure and relationships between classes and objects. UML diagrams are typically created to visualize the design and architecture of a software system, not individual functions or methods. It would therefore be more appropriate to create UML diagrams for the overall design and architecture of the software system in which this code snippet is a part of.
2024-01-21 18:13:03,518 - INFO - UML code generated for src/routes/code_to_uml.py: @startuml
title code_to_uml.py
if code == "":
            continue
        # Add file path to list
        file_paths.append(file_path)
        # Generate code from the OpenAI API
        generated_code += api.generate(code)  # Concatenate the generated code
    # Write the generated code to a file in the output directory
    with open(os.path.join(output_directory, 'generated_code.py'), 'w+') as f:
        f.write(generated_code)
    return file_paths  # Return the list of processed file paths

````

@startuml

class OpenAIAPI {
    # api_key: string
    +generate(text: string): string
}

class Logging {
    -logger: Logger
    -level: int
    +Debug()
    +Info()
    +Warn()
    +Error()
}

class Logger {
    -log_handler: RotatingFileHandler
    -log_formatter: Formatter
    -log_filename: string
    +setLevel(level: int)
    +addHandler(handler: Handler)
    +debug(msg: string)
    +info(msg: string)
    +warn(msg: string)
    +error(msg: string)
}

class Handler {
    #level: int
    +setFormatter(formatter: Formatter)
    +emit(record: LogRecord)
}

class RotatingFileHandler {
    -maxBytes: int
    -backupCount: int
    +doRollover()
    +rotate(filename: string)
}

class Formatter {
    +format(record: LogRecord): string
}

class File {
    -file_name: string
    -content: string
    +write(content: string)
}

class CodeToUML {
    -api: OpenAIAPI
    -file_paths: list
    -generated_code: string
    +generate_content(files: dict, output_directory: string): list
}

CodeToUML --> OpenAIAPI
CodeToUML --> Logging
Logging --> Logger
Logger --> Handler
Handler --> Formatter
RotatingFileHandler <|-- Handler
File <|-- CodeToUML

@enduml_paths})
    
    @startuml

    |     Main     |
    |--------------|
    | +code        |
    |--------------|
    | +not strip() |                  ------------
    |    +logging.in "Skipping empty file:<$file_path$>" |    |<--        |
    |              |                                         |           |
    |              |                                         |<--        |
    |              |                        True             |           |
    |              |<----------------------------------------|           |
    |              |                                False      |           |
    |              |  -----                                     |           |
    |              +-->|strip()|    --------                |           |
    |                   ----------    |      |               |           |
    |                        |        |      |  <--------   |           |
    |                        |        |      |       True   |           |
    |                        |        |      |   ------------           |
    |             |<---------   -------------->|not generated_code
    |logging.info|                             ----------------->|generated_code_for_file|   | generated_code
    |        "Processing file:<$file_path$>"                         -------------------->|
    |                                                                          |      |
    |                                                                          |      |
    |                                                                          |<-----
    |                                                                ----------- |
    |                                                          |     |<----
    |                                       ------------       |     |
    |                                       |    True  |       |     |
    |                                       |----------->|not generated_code_for_file|
    |                                       |<--------          |  or  |
    |                                       |       False       |"UML generation failed" in generated_code_for_file
    |                                       -----------       |   ------------
    |                                                           |       |<-----
    |                                                               |       |
    |<-----                                                          |       |                                             
    |               logging.error "Failed to generate UML diagram for:<$file_path$>" ---| 
    |<-----           raise ValueError "Failed to generate UML diagram for:<$file_path$>" |
    | generated_code += generated_code_for_file                                            |
    |--------------------------------------------------------------------------------------|


    @endumlUML diagrams cannot be created for code snippets as they do not contain enough information about the structure and relationships between classes and objects. UML diagrams are typically created to visualize the design and architecture of a software system, not individual functions or methods. It would therefore be more appropriate to create UML diagrams for the overall design and architecture of the software system in which this code snippet is a part of.
@enduml
2024-01-21 18:13:03,518 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 18:13:03,520 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 18:13:03,520 - INFO - Processing file: src/routes/retrieve_code.py
2024-01-21 18:13:03,520 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import git
import json
import os
import logging
from logging import handlers


# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'retrieve_code.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


def clone_repo(repo_url, temp_dir, access_token):
    try:
        # Modify the URL to include the access token
        if access_token:
            repo_url = repo_url.replace('https://', f'https://{access_token}@')
        logger.info(f"Cloning repository: {repo_url}")
        repo = git.Repo.clone_from(repo_url, temp_dir)
        logger.info(f"Successfully cloned repository: {repo_url}")
        
2024-01-21 18:13:03,521 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nimport git\nimport json\nimport os\nimport logging\nfrom logging import handlers\n\n\n# Configure logging to write to a file\nlog_directory = \'logs\'\n# Create the directory if it doesn\'t exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, \'retrieve_code.log\')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter(\'%(asctime)s - %(levelname)s - %(message)s\')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\ndef clone_repo(repo_url, temp_dir, access_token):\n    try:\n        # Modify the URL to include the access token\n        if access_token:\n            repo_url = repo_url.replace(\'https://\', f\'https://{access_token}@\')\n        logger.info(f"Cloning repository: {repo_url}")\n        repo = git.Repo.clone_from(repo_url, temp_dir)\n        logger.info(f"Successfully cloned repository: {repo_url}")\n        ', 'max_tokens': 1024}}
2024-01-21 18:13:03,522 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 18:13:03,523 - DEBUG - send_request_headers.complete
2024-01-21 18:13:03,523 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 18:13:03,523 - DEBUG - send_request_body.complete
2024-01-21 18:13:03,523 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 18:13:06,935 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 22 Jan 2024 00:13:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3323'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'fbe366fb24391ac0cf0aaa7ee02fa48b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849396c17d4244e2-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 18:13:06,937 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 18:13:06,938 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 18:13:06,940 - DEBUG - receive_response_body.complete
2024-01-21 18:13:06,940 - DEBUG - response_closed.started
2024-01-21 18:13:06,941 - DEBUG - response_closed.complete
2024-01-21 18:13:06,941 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 18:13:06,944 - INFO - Received response from OpenAI: 
        # Get the latest commit from the repository
        head_commit = repo.head.commit
        # Convert the commit information to JSON format
        commit_json = json.dumps({"message": head_commit.message,
                                  "author": head_commit.author.name,
                                  "date": str(head_commit.authored_datetime)})
        logger.debug(f"Latest commit info: {commit_json}")

        # Return the repository object and commit info
        return repo, commit_json
    except git.GitCommandError:
        logger.error("Failed to clone repository. Please check the URL and try again.")
        return None, None
    except Exception as e:
        logger.error(f"An error occurred while cloning repository: {e}")
        return None, None


# Class diagram

@startuml

class git
class json
class os
class logging
class handlers

class repository {
    - repo_url : string
    - temp_dir : string
    - access_token : string
}
class commit {
    - message : string
    - author : string
    - date : string
}

logging -- handlers
handlers -- logging
handlers -- log_file

repository -- logging
repository -- git
commit -- json

@enduml

# Sequence diagram

@startuml

actor User

User -> clone_repo : repo_url, temp_dir, access_token
clone_repo -> repo: git.Repo.clone_from(repo_url, temp_dir)
repo -> head_commit: repo.head.commit
head_commit -> convert_to_json : head_commit.message, head_commit.author.name, head_commit.authored_datetime
convert_to_json -> commit_json : json.dumps
clone_repo --> User : repo, commit_json
@enduml
2024-01-21 18:13:06,946 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

return repo
    except Exception as e:
        logger.error(f"Failed to clone repository: {str(e)}")
        raise ValueError(f"Failed to clone repository: {str(e)}")

def retrieve_code(repo, branch_name):
    try:
        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement
        logger.info(f"Attempting to checkout branch: {branch_name}")
        repo.git.fetch()  # Fetch the latest updates from the remote
        repo.git.checkout(branch_name)
        logger.info(f"Successfully checked out branch: {branch_name}")
        
        # Load the config
        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        with open(config_file_path, 'r') as f:
            config = json.load(f)
        ignore_list = config.get('ignore', [])
        include_list = config.get('include', [])

        # Create a new dictionary to store file paths and their corresponding code
        included_files = {}
        for file in repo.tree():
            
2024-01-21 18:13:06,947 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nreturn repo\n    except Exception as e:\n        logger.error(f"Failed to clone repository: {str(e)}")\n        raise ValueError(f"Failed to clone repository: {str(e)}")\n\ndef retrieve_code(repo, branch_name):\n    try:\n        print(f"Attempting to checkout branch: {branch_name}")  # Diagnostic print statement\n        logger.info(f"Attempting to checkout branch: {branch_name}")\n        repo.git.fetch()  # Fetch the latest updates from the remote\n        repo.git.checkout(branch_name)\n        logger.info(f"Successfully checked out branch: {branch_name}")\n        \n        # Load the config\n        config_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'config.json\')\n        with open(config_file_path, \'r\') as f:\n            config = json.load(f)\n        ignore_list = config.get(\'ignore\', [])\n        include_list = config.get(\'include\', [])\n\n        # Create a new dictionary to store file paths and their corresponding code\n        included_files = {}\n        for file in repo.tree():\n            ', 'max_tokens': 1024}}
2024-01-21 18:13:06,949 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 18:13:06,949 - DEBUG - send_request_headers.complete
2024-01-21 18:13:06,949 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 18:13:06,950 - DEBUG - send_request_body.complete
2024-01-21 18:13:06,950 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 18:13:10,859 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 22 Jan 2024 00:13:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3480'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'ddeda29e2778438463da8b01e74aa0bb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849396d8aad244e2-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 18:13:10,862 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 18:13:10,863 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 18:13:10,864 - DEBUG - receive_response_body.complete
2024-01-21 18:13:10,864 - DEBUG - response_closed.started
2024-01-21 18:13:10,864 - DEBUG - response_closed.complete
2024-01-21 18:13:10,864 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 18:13:10,866 - INFO - Received response from OpenAI:  if file.path in ignore_list:
                  continue
             elif file.path.endswith('.py') or file.path.endswith('.ipynb'):
                 file_path = os.path.join(repo.working_dir, file.path)
                 with open(file_path, 'r') as f:
                     included_files[file.path] = f.read()
        return included_files

@startuml

class Repo {
    - name: string
    - url: string
    - git: Git

    + clone(): void
    + fetch(): void
    + checkout(branch_name: string): void
}

class Exception {
    - error_message: string
}

class Logger {
    - log_file: string
    - error_file: string

    + info(message: string): void
    + error(message: String): void
}

class ValueError {
    - error_message: string

    + __init__(error_message: string)
}

class Config {
    - ignore_list: list
    - include_list: list

    + load_config(): void
}

Repo --> Git
Exception --> Logger
ValueError --> Logger

Repo *--> Exception : throws

Config *--> Config : has-a

note right
    # Config.json file
    {
        "ignore": [],
        "include": []
    }
end note

Repo --> include_files

group Retrieve code
    activate retrieve_code

    loop
        Repo -> include_files : get file paths
        include_files -> Config : load config
        activate Config
        Config -> include_files : get ignore list
        include_files -> include_files : filter out ignored files
        include_files -> Repo : get file contents
    end

    deactivate Config

    return include_files
end group

Repo --> include_files

@enduml
2024-01-21 18:13:10,867 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

if any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):
                try:
                    with open(file.abspath, 'r') as f:
                        included_files[file.path] = f.read()
                    logger.info(f"Included file: {file.path}")
                except FileNotFoundError:
                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement
                    logger.warning(f"Ignoring missing file: {file.path}")

        return included_files
    except Exception as e:
        logger.error(f"Failed to retrieve code: {str(e)}")
        raise ValueError(f"Failed to retrieve code: {str(e)}")
2024-01-21 18:13:10,869 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nif any(file.path.endswith(ext) for ext in include_list) and not any(ignored_file in file.path for ignored_file in ignore_list):\n                try:\n                    with open(file.abspath, \'r\') as f:\n                        included_files[file.path] = f.read()\n                    logger.info(f"Included file: {file.path}")\n                except FileNotFoundError:\n                    print(f"Ignoring missing file: {file.path}")  # Diagnostic print statement\n                    logger.warning(f"Ignoring missing file: {file.path}")\n\n        return included_files\n    except Exception as e:\n        logger.error(f"Failed to retrieve code: {str(e)}")\n        raise ValueError(f"Failed to retrieve code: {str(e)}")', 'max_tokens': 1024}}
2024-01-21 18:13:10,870 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 18:13:10,871 - DEBUG - send_request_headers.complete
2024-01-21 18:13:10,871 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 18:13:10,871 - DEBUG - send_request_body.complete
2024-01-21 18:13:10,871 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 18:13:12,277 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 22 Jan 2024 00:13:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1158'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'4dc6a28a66e15ca031cd216b7aa5f341'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849396f00f1144e2-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 18:13:12,279 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 18:13:12,280 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 18:13:12,280 - DEBUG - receive_response_body.complete
2024-01-21 18:13:12,281 - DEBUG - response_closed.started
2024-01-21 18:13:12,281 - DEBUG - response_closed.complete
2024-01-21 18:13:12,281 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 18:13:12,284 - INFO - Received response from OpenAI: 



@startuml

class CodeRetriever{
    -include_list:String[]
    -ignore_list:String[]
    -included_files:Dictionary

    +retrieveCode():Dict
}


class File{
    -path:String
    -abspath:String
}

class Logger{
    -info(text:String):Void
    -warning(text:String):Void
    -error(text:String):Void
}

CodeRetriever -- File
CodeRetriever o-- Logger


@enduml
2024-01-21 18:13:12,285 - INFO - UML code generated for src/routes/retrieve_code.py: @startuml
title retrieve_code.py
# Get the latest commit from the repository
        head_commit = repo.head.commit
        # Convert the commit information to JSON format
        commit_json = json.dumps({"message": head_commit.message,
                                  "author": head_commit.author.name,
                                  "date": str(head_commit.authored_datetime)})
        logger.debug(f"Latest commit info: {commit_json}")

        # Return the repository object and commit info
        return repo, commit_json
    except git.GitCommandError:
        logger.error("Failed to clone repository. Please check the URL and try again.")
        return None, None
    except Exception as e:
        logger.error(f"An error occurred while cloning repository: {e}")
        return None, None


# Class diagram

@startuml

class git
class json
class os
class logging
class handlers

class repository {
    - repo_url : string
    - temp_dir : string
    - access_token : string
}
class commit {
    - message : string
    - author : string
    - date : string
}

logging -- handlers
handlers -- logging
handlers -- log_file

repository -- logging
repository -- git
commit -- json

@enduml
2024-01-21 18:13:12,285 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 18:13:12,286 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 18:13:12,286 - INFO - Processing file: src/routes/uml_from_repo.py
2024-01-21 18:13:12,287 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

# uml_from_repo.py
import os
import fnmatch
import subprocess
import json
import git
import tempfile
import shutil
import logging
from logging import handlers  
from routes.retrieve_code import clone_repo, retrieve_code
from routes.code_to_uml import generate_content  # Import the function from code_to_uml.py

# Configure logging to write to a file
log_directory = 'logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'uml_from_repo.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)

def process_request(data):
    git_repo_url = data.get('gitRepoUrl')
    output_directory = data.get('local_dir')  # Get the output directory from the request data
    gi
2024-01-21 18:13:12,288 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n# uml_from_repo.py\nimport os\nimport fnmatch\nimport subprocess\nimport json\nimport git\nimport tempfile\nimport shutil\nimport logging\nfrom logging import handlers  \nfrom routes.retrieve_code import clone_repo, retrieve_code\nfrom routes.code_to_uml import generate_content  # Import the function from code_to_uml.py\n\n# Configure logging to write to a file\nlog_directory = 'logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'uml_from_repo.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\ndef process_request(data):\n    git_repo_url = data.get('gitRepoUrl')\n    output_directory = data.get('local_dir')  # Get the output directory from the request data\n    gi", 'max_tokens': 1024}}
2024-01-21 18:13:12,289 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 18:13:12,290 - DEBUG - send_request_headers.complete
2024-01-21 18:13:12,290 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 18:13:12,290 - DEBUG - send_request_body.complete
2024-01-21 18:13:12,291 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 18:13:15,088 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 22 Jan 2024 00:13:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2689'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'9351d836eb5ac1374855ed3b38d7398d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849396f8480f44e2-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 18:13:15,090 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 18:13:15,091 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 18:13:15,091 - DEBUG - receive_response_body.complete
2024-01-21 18:13:15,091 - DEBUG - response_closed.started
2024-01-21 18:13:15,092 - DEBUG - response_closed.complete
2024-01-21 18:13:15,092 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 18:13:15,094 - INFO - Received response from OpenAI: 
t_repo = clone_repo(git_repo_url, output_directory)  # Clone the git repository to the output directory
    if git_repo is not None:
        retrieve_code(output_directory)  # Get all code files from the cloned repository
        generate_content(output_directory)  # Generate UML diagrams from the retrieved code

@startuml

title UML Diagram for uml_from_repo.py

class uml_from_repo {

    - log_directory : string
    - log_filename : string
    - log_handler : handlers.RotatingFileHandler
    - log_formatter : logging.Formatter
    - logger : logging.Logger

    + process_request(data) : void

}

class git {
    - repo_url : string

    + clone_repo(repo_url, output_directory) : git
}

class code_to_uml {
    - output_directory : string

    + retrieve_code(output_directory) : void
    + generate_content(output_directory) : void
}

uml_from_repo *-- logging
logging *-- handlers.RotatingFileHandler
logging *-- logging.Formatter
logging *-- logging.Logger

uml_from_repo *-- routes.retrieve_code
uml_from_repo *-- routes.code_to_uml

routes.retrieve_code *-- git
routes.code_to_uml *-- code_to_uml

@enduml
2024-01-21 18:13:15,095 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

thub_access_token = data.get('gitHubAccessToken')
    branch_name = data.get('branchName', 'master')  # 'master' is the default branch name
    if not git_repo_url or not output_directory or not github_access_token or not branch_name:
        logger.error("Missing required parameters")  
        return {"error": "Missing required parameters"}, 400

    try:
        temp_dir = None
        try:
            temp_dir = tempfile.mkdtemp()
        except Exception as e:
            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)
            return {"error": str(e)}, 500
        finally:
            # Clean up the temporary directory
            if temp_dir is not None:
                logger.info("Cleaning up temporary directory")
                shutil.rmtree(temp_dir)

        # Clone the repository
        repo = clone_repo(git_repo_url, temp_dir, github_access_token)
         
        # Load the config
        with open('src/routes/config.json', 'r') as f:
            config = json.load(f
2024-01-21 18:13:15,097 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nthub_access_token = data.get(\'gitHubAccessToken\')\n    branch_name = data.get(\'branchName\', \'master\')  # \'master\' is the default branch name\n    if not git_repo_url or not output_directory or not github_access_token or not branch_name:\n        logger.error("Missing required parameters")  \n        return {"error": "Missing required parameters"}, 400\n\n    try:\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp()\n        except Exception as e:\n            logger.error(f"Error during UML generation: {str(e)}", exc_info=True)\n            return {"error": str(e)}, 500\n        finally:\n            # Clean up the temporary directory\n            if temp_dir is not None:\n                logger.info("Cleaning up temporary directory")\n                shutil.rmtree(temp_dir)\n\n        # Clone the repository\n        repo = clone_repo(git_repo_url, temp_dir, github_access_token)\n         \n        # Load the config\n        with open(\'src/routes/config.json\', \'r\') as f:\n            config = json.load(f', 'max_tokens': 1024}}
2024-01-21 18:13:15,099 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 18:13:15,099 - DEBUG - send_request_headers.complete
2024-01-21 18:13:15,100 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 18:13:15,100 - DEBUG - send_request_body.complete
2024-01-21 18:13:15,100 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 18:13:18,435 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 22 Jan 2024 00:13:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3241'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'a6b4c1badd47780e3e2c3149860d2644'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84939709dbf444e2-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 18:13:18,437 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 18:13:18,438 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 18:13:18,440 - DEBUG - receive_response_body.complete
2024-01-21 18:13:18,440 - DEBUG - response_closed.started
2024-01-21 18:13:18,441 - DEBUG - response_closed.complete
2024-01-21 18:13:18,441 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 18:13:18,443 - INFO - Received response from OpenAI: )


@startuml

class data {
    + gitHubAccessToken
    + branchName
}

class logger {
    + error(message)
    + info(message)
}

class tempfile {
    + mkdtemp()
}

class Exception

class shutil {
    + rmtree(directory)
}

class repo {
    + clone_repo(git_repo_url, temp_dir, github_access_token)
}

class config

class json {
    + load(file)
}

data <|-- git_repo_url
data <|-- output_directory
data <|-- github_access_token
data <|-- branch_name
logger --> data
tempfile --> logger
Exception <|-- logger
shutil --> logger
repo <|-- git_repo_url
repo <|-- temp_dir
repo <|-- github_access_token
config <|-- json
json <|-- f

if (not git_repo_url or not output_directory or not github_access_token or not branch_name) then (yes)
    logger: error("Missing required parameters")
    : return {"error": "Missing required parameters"}, 400
elseif (not git_repo_url or not output_directory or not github_access_token or not branch_name) then (no)
endif

: temp_dir = None
try
    tempfile: mkdtemp()
catch (Exception e)
    logger: error(f"Error during UML generation: {str(e)}", exc_info=True)
    : return {"error": str(e)}, 500
finally
    if temp_dir is not None then (yes)
        logger: info("Cleaning up temporary directory")
        shutil: rmtree(temp_dir)
endif

repo: clone_repo(git_repo_url, temp_dir, github_access_token)

: with open('src/routes/config.json', 'r') as f
json: load(f)
json --> config

@enduml
2024-01-21 18:13:18,444 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

)
        
        def traverse_directories(repo, temp_dir, config):
            included_files = {}
            for item in repo.tree().traverse():
                if item.type == 'blob':  # This means it's a file, not a directory
                    for pattern in config['include']:
                        if fnmatch.fnmatch(item.path, pattern):
                            with open(os.path.join(temp_dir, item.path), 'r') as f:
                                included_files[item.path] = f.read()
                            break  # No need to check the remaining patterns
            return included_files

        # Retrieve the code from the repository
        included_files = traverse_directories(repo, temp_dir, config)

        logger.debug(f"Type of included_files: {type(included_files)}")
        logger.debug(f"Value of included_files: {included_files}")

        # Save the UML diagram to a file
        logger.info(f"Saving UML diagram to {output_directory}")
        final_output_paths = generate_conten
2024-01-21 18:13:18,446 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\n)\n        \n        def traverse_directories(repo, temp_dir, config):\n            included_files = {}\n            for item in repo.tree().traverse():\n                if item.type == \'blob\':  # This means it\'s a file, not a directory\n                    for pattern in config[\'include\']:\n                        if fnmatch.fnmatch(item.path, pattern):\n                            with open(os.path.join(temp_dir, item.path), \'r\') as f:\n                                included_files[item.path] = f.read()\n                            break  # No need to check the remaining patterns\n            return included_files\n\n        # Retrieve the code from the repository\n        included_files = traverse_directories(repo, temp_dir, config)\n\n        logger.debug(f"Type of included_files: {type(included_files)}")\n        logger.debug(f"Value of included_files: {included_files}")\n\n        # Save the UML diagram to a file\n        logger.info(f"Saving UML diagram to {output_directory}")\n        final_output_paths = generate_conten', 'max_tokens': 1024}}
2024-01-21 18:13:18,448 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 18:13:18,448 - DEBUG - send_request_headers.complete
2024-01-21 18:13:18,448 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 18:13:18,448 - DEBUG - send_request_body.complete
2024-01-21 18:13:18,449 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 18:13:21,962 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 22 Jan 2024 00:13:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3440'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'2328f37adcf857d0c0101edb96ccd7fa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493971ecd5544e2-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 18:13:21,964 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 18:13:21,965 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 18:13:21,966 - DEBUG - receive_response_body.complete
2024-01-21 18:13:21,966 - DEBUG - response_closed.started
2024-01-21 18:13:21,966 - DEBUG - response_closed.complete
2024-01-21 18:13:21,967 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 18:13:21,970 - INFO - Received response from OpenAI: t_diagram(
            included_files, output_directory=output_directory)
        
        
@startuml
class TraverseDirectories:
    - included_files
    - repo : Repository
    - temp_dir : string
    - config : dict
    + traverse_directories(repo, temp_dir, config) : dict
    + included_files : dict
    + logger : logger
    + generate_content_diagram(included_files, output_directory) : string
@enduml

@startuml
class Repository
@enduml

@startuml
class Logger
- debug_level : int
- info_level : int
+ debug(message) : void
+ info(message) : void
@enduml

@startuml
class IncludedFiles
- file_paths : list
- file_contents : dict
+ add_file(file_path, file_content) : void
+ get_file_path(file_content) : string
+ get_file_content(file_path) : string
@enduml

@startuml
class TempDirectory
- dir_path : string
- file_paths : list
+ add_file(file_path) : void
+ get_file_path(index) : string
@enduml

@startuml
class Configuration
- include_patterns : list
+ add_pattern(pattern) : void
+ get_patterns() : list
@enduml

@startuml
class GenerateContentDiagram
- included_files : dict
- output_directory : string
+ generate_content_diagram(included_files, output_directory) : string
@enduml

2024-01-21 18:13:21,972 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

t(included_files, output_directory)  # This is now a list of file paths
        logger.info(f"Final output paths: {final_output_paths}")

        for path in final_output_paths:
            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved

        return {
            "message": "UML diagrams generated successfully",
            "details": {
                "Repository": git_repo_url,
                "Output Paths": final_output_paths  # This is now a list of file paths
            }
        }, 200

    except Exception as e:
        logger.error(f"Error during UML generation: {str(e)}")
        return {"error": str(e)}, 500

    finally:
        # Clean up the temporary directory
        logger.info("Cleaning up temporary directory")
        shutil.rmtree(temp_dir)

 
2024-01-21 18:13:21,974 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': 'Create UML diagrams in .puml format for the following code:\n\nt(included_files, output_directory)  # This is now a list of file paths\n        logger.info(f"Final output paths: {final_output_paths}")\n\n        for path in final_output_paths:\n            logger.info(f"UML diagram saved at: {path}")  # Log the path where each UML diagram was saved\n\n        return {\n            "message": "UML diagrams generated successfully",\n            "details": {\n                "Repository": git_repo_url,\n                "Output Paths": final_output_paths  # This is now a list of file paths\n            }\n        }, 200\n\n    except Exception as e:\n        logger.error(f"Error during UML generation: {str(e)}")\n        return {"error": str(e)}, 500\n\n    finally:\n        # Clean up the temporary directory\n        logger.info("Cleaning up temporary directory")\n        shutil.rmtree(temp_dir)\n\n ', 'max_tokens': 1024}}
2024-01-21 18:13:21,975 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 18:13:21,976 - DEBUG - send_request_headers.complete
2024-01-21 18:13:21,976 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 18:13:21,977 - DEBUG - send_request_body.complete
2024-01-21 18:13:21,978 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 18:13:23,286 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 22 Jan 2024 00:13:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1160'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'e5541f62fb601a20f9a208e897aeab2b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84939734d99e44e2-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 18:13:23,288 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 18:13:23,289 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 18:13:23,290 - DEBUG - receive_response_body.complete
2024-01-21 18:13:23,290 - DEBUG - response_closed.started
2024-01-21 18:13:23,290 - DEBUG - response_closed.complete
2024-01-21 18:13:23,291 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 18:13:23,292 - INFO - Received response from OpenAI: |             UML Section            |
|-------------------------------------|
|-------------------------------------|
|          t(included_files, output_directory)|
|-------------------------------------|
|             logger.info           |
|-------------------------------------|
|        for path in final_output_paths  |
|-------------------------------------|
|             logger.info           |
|-------------------------------------|
|             return                 |
|-------------------------------------|
|             logger.error           |
|-------------------------------------|
|             return                 |
|-------------------------------------|
|         logger.info("Cleaning up temporary directory") |
|-------------------------------------|
|             shutil.rmtree         |
|-------------------------------------|
2024-01-21 18:13:23,293 - INFO - UML code generated for src/routes/uml_from_repo.py: @startuml
title uml_from_repo.py
t_repo = clone_repo(git_repo_url, output_directory)  # Clone the git repository to the output directory
    if git_repo is not None:
        retrieve_code(output_directory)  # Get all code files from the cloned repository
        generate_content(output_directory)  # Generate UML diagrams from the retrieved code

@startuml

title UML Diagram for uml_from_repo.py

class uml_from_repo {

    - log_directory : string
    - log_filename : string
    - log_handler : handlers.RotatingFileHandler
    - log_formatter : logging.Formatter
    - logger : logging.Logger

    + process_request(data) : void

}

class git {
    - repo_url : string

    + clone_repo(repo_url, output_directory) : git
}

class code_to_uml {
    - output_directory : string

    + retrieve_code(output_directory) : void
    + generate_content(output_directory) : void
}

uml_from_repo *-- logging
logging *-- handlers.RotatingFileHandler
logging *-- logging.Formatter
logging *-- logging.Logger

uml_from_repo *-- routes.retrieve_code
uml_from_repo *-- routes.code_to_uml

routes.retrieve_code *-- git
routes.code_to_uml *-- code_to_uml

@enduml)


@startuml

class data {
    + gitHubAccessToken
    + branchName
}

class logger {
    + error(message)
    + info(message)
}

class tempfile {
    + mkdtemp()
}

class Exception

class shutil {
    + rmtree(directory)
}

class repo {
    + clone_repo(git_repo_url, temp_dir, github_access_token)
}

class config

class json {
    + load(file)
}

data <|-- git_repo_url
data <|-- output_directory
data <|-- github_access_token
data <|-- branch_name
logger --> data
tempfile --> logger
Exception <|-- logger
shutil --> logger
repo <|-- git_repo_url
repo <|-- temp_dir
repo <|-- github_access_token
config <|-- json
json <|-- f

if (not git_repo_url or not output_directory or not github_access_token or not branch_name) then (yes)
    logger: error("Missing required parameters")
    : return {"error": "Missing required parameters"}, 400
elseif (not git_repo_url or not output_directory or not github_access_token or not branch_name) then (no)
endif

: temp_dir = None
try
    tempfile: mkdtemp()
catch (Exception e)
    logger: error(f"Error during UML generation: {str(e)}", exc_info=True)
    : return {"error": str(e)}, 500
finally
    if temp_dir is not None then (yes)
        logger: info("Cleaning up temporary directory")
        shutil: rmtree(temp_dir)
endif

repo: clone_repo(git_repo_url, temp_dir, github_access_token)

: with open('src/routes/config.json', 'r') as f
json: load(f)
json --> config

@endumlt_diagram(
            included_files, output_directory=output_directory)
        
        
@startuml
class TraverseDirectories:
    - included_files
    - repo : Repository
    - temp_dir : string
    - config : dict
    + traverse_directories(repo, temp_dir, config) : dict
    + included_files : dict
    + logger : logger
    + generate_content_diagram(included_files, output_directory) : string
@enduml
2024-01-21 18:13:23,294 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 18:13:23,294 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 18:13:23,295 - INFO - Skipping empty file: src/scripts/__init__.py
2024-01-21 18:13:23,295 - INFO - Processing file: src/scripts/execute_generate_uml.py
2024-01-21 18:13:23,295 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

import json
import os
import requests
import logging
from logging import handlers
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure logging to write to a file
log_directory = '../../logs'
# Create the directory if it doesn't exist
os.makedirs(log_directory, exist_ok=True)  
log_filename = os.path.join(log_directory, 'execute_generate_uml.log')
log_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_handler.setFormatter(log_formatter)
logger = logging.getLogger()
logger.addHandler(log_handler)
logger.setLevel(logging.DEBUG)


# Configure logging
logging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))
# Configuration file path
config_file_path = os.path.join(cu
2024-01-21 18:13:23,297 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nimport json\nimport os\nimport requests\nimport logging\nfrom logging import handlers\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging to write to a file\nlog_directory = '../../logs'\n# Create the directory if it doesn't exist\nos.makedirs(log_directory, exist_ok=True)  \nlog_filename = os.path.join(log_directory, 'execute_generate_uml.log')\nlog_handler = handlers.RotatingFileHandler(log_filename, maxBytes=1024*1024, backupCount=5)  # Log file with rotation\nlog_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(log_formatter)\nlogger = logging.getLogger()\nlogger.addHandler(log_handler)\nlogger.setLevel(logging.DEBUG)\n\n\n# Configure logging\nlogging.basicConfig(filename='execute_generate_uml.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Current file's directory\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# Configuration file path\nconfig_file_path = os.path.join(cu", 'max_tokens': 1024}}
2024-01-21 18:13:23,298 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 18:13:23,299 - DEBUG - send_request_headers.complete
2024-01-21 18:13:23,299 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 18:13:23,299 - DEBUG - send_request_body.complete
2024-01-21 18:13:23,299 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 18:13:26,630 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 22 Jan 2024 00:13:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'3082'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'ebe06ddba2fc008e3d5ede989ca91117'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8493973d1ba144e2-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 18:13:26,632 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 18:13:26,633 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 18:13:26,634 - DEBUG - receive_response_body.complete
2024-01-21 18:13:26,634 - DEBUG - response_closed.started
2024-01-21 18:13:26,635 - DEBUG - response_closed.complete
2024-01-21 18:13:26,635 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 18:13:26,636 - INFO - Received response from OpenAI: rrent_dir, 'config.json')

@startuml
Class Importer {
    - json
    - os
    - requests
    - logging
    - load_dotenv
    - log_handler
    - log_formatter
    - logger
    - current_dir
    - config_file_path

    + LoadEnvVariables() 
    + ConfigureLogging() 
    + __init__()
}

Class LoadEnvVariables {
    - dotenv 

    + loadDotEnv()
}

Class ConfigureLogging {
    - os
    - handlers
    - log_directory
    - log_filename
    - log_handler
    - log_formatter
    - logger
    - level

    + __init__()
    + setLogFile()
    + setFormatter()
    + setLevel()
}

Class CurrentDirectory {
    - os
    - absPath

    + __init__()
    + getCurrentDirectory()
}

Class ConfigurationFile {
    - os
    - current_dir
    - fileName

    + __init__()
    + getPath()
}

Class LogDirectory {
    - os
    - parent_dir
    - directory

    + __init__()
    + makeDirectory()
}

Importer --> LoadEnvVariables
Importer --> ConfigureLogging
Importer --> CurrentDirectory
Importer --> ConfigurationFile
LoadEnvVariables --> dotenv
ConfigureLogging --> os
ConfigureLogging --> handlers
ConfigureLogging --> logger
CurrentDirectory --> os
CurrentDirectory --> absPath
ConfigurationFile --> os
ConfigurationFile --> current_dir
ConfigurationFile --> fileName
LogDirectory --> os
LogDirectory --> parent_dir
LogDirectory --> directory

@enduml
2024-01-21 18:13:26,639 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

rrent_dir, 'config.json')

# Read configuration from the JSON file
with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

# Retrieve the GitHub access token from environment variables
github_token = os.getenv('GITHUB_PAT')

# Endpoint URL
url = 'http://127.0.0.1:5000/generate-uml'

# Headers
headers = {
    'Content-Type': 'application/json'
}

# Update the GitHub access token and local directory in the config data
config_data['gitHubAccessToken'] = github_token
config_data['local_dir'] = os.path.join(current_dir, '../..', 'output')

# Log the JSON data being sent in the request
logging.info(f'Sending JSON data to {url}:')
logging.info(json.dumps(config_data, indent=2))

try:
    # Make the POST request
    response = requests.post(url, headers=headers, json=config_data)

    # Log the response from the server
    logging.info(f'Response from server ({url}):')
    logging.info(f'Status Code: {response.status_code}')
    logging.info(f'Response Text: {response.text}')

    #
2024-01-21 18:13:26,640 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\nrrent_dir, 'config.json')\n\n# Read configuration from the JSON file\nwith open(config_file_path, 'r') as config_file:\n    config_data = json.load(config_file)\n\n# Retrieve the GitHub access token from environment variables\ngithub_token = os.getenv('GITHUB_PAT')\n\n# Endpoint URL\nurl = 'http://127.0.0.1:5000/generate-uml'\n\n# Headers\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n# Update the GitHub access token and local directory in the config data\nconfig_data['gitHubAccessToken'] = github_token\nconfig_data['local_dir'] = os.path.join(current_dir, '../..', 'output')\n\n# Log the JSON data being sent in the request\nlogging.info(f'Sending JSON data to {url}:')\nlogging.info(json.dumps(config_data, indent=2))\n\ntry:\n    # Make the POST request\n    response = requests.post(url, headers=headers, json=config_data)\n\n    # Log the response from the server\n    logging.info(f'Response from server ({url}):')\n    logging.info(f'Status Code: {response.status_code}')\n    logging.info(f'Response Text: {response.text}')\n\n    #", 'max_tokens': 1024}}
2024-01-21 18:13:26,641 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 18:13:26,642 - DEBUG - send_request_headers.complete
2024-01-21 18:13:26,642 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 18:13:26,642 - DEBUG - send_request_body.complete
2024-01-21 18:13:26,643 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 18:13:29,577 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 22 Jan 2024 00:13:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'2744'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'89d11ca481c1dbcc72aaa2eebb27840d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'849397520cbf44e2-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 18:13:29,579 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 18:13:29,580 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 18:13:29,581 - DEBUG - receive_response_body.complete
2024-01-21 18:13:29,582 - DEBUG - response_closed.started
2024-01-21 18:13:29,582 - DEBUG - response_closed.complete
2024-01-21 18:13:29,583 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 18:13:29,585 - INFO - Received response from OpenAI:  Write the response to a file
    with open(os.path.join(current_dir, 'uml_diagram.png'), 'wb') as uml_file:
        uml_file.write(response.content)

except requests.exceptions.RequestException as e:
    logging.error(f'An error occurred while making the request: {e}')

@startuml

class UMLCreator {
    - current_dir: string
    - config_file_path: string
    - config_data: json
    - github_token: string
    - url: string
    - headers: dict

    + UMLCreator(current_dir, config_file_path)

    + read_config()
    + get_github_token()
    + generate_diagram()
}

UMLCreator --right--> JSONConverter
UMLCreator --down--> GithubTokenRetriever
UMLCreator --down--> HttpRequester
class JSONConverter {
    + convert_to_json()
}
class GithubTokenRetriever {
    + retrieve_token()
    - github_token: string
}

class HttpRequester {
    + send_post_request()
    + set_url()
    + set_headers()
    - url: string
    - headers: dict
}

@enduml
2024-01-21 18:13:29,586 - INFO - Sending prompt to OpenAI: Create UML diagrams in .puml format for the following code:

 Print the response from the server
    print(response.text)

    # Save the response to a file in the output directory
    output_dir = os.path.join(current_dir, '../..', 'output')
    os.makedirs(output_dir, exist_ok=True)
    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:
        json.dump(response.json(), output_file, indent=2)

except Exception as e:
    # Log any exceptions that occur
    logging.error(f'Error occurred: {str(e)}')
2024-01-21 18:13:29,588 - DEBUG - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': "Create UML diagrams in .puml format for the following code:\n\n Print the response from the server\n    print(response.text)\n\n    # Save the response to a file in the output directory\n    output_dir = os.path.join(current_dir, '../..', 'output')\n    os.makedirs(output_dir, exist_ok=True)\n    with open(os.path.join(output_dir, 'response.json'), 'w') as output_file:\n        json.dump(response.json(), output_file, indent=2)\n\nexcept Exception as e:\n    # Log any exceptions that occur\n    logging.error(f'Error occurred: {str(e)}')", 'max_tokens': 1024}}
2024-01-21 18:13:29,589 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-01-21 18:13:29,590 - DEBUG - send_request_headers.complete
2024-01-21 18:13:29,590 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-01-21 18:13:29,590 - DEBUG - send_request_body.complete
2024-01-21 18:13:29,590 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-01-21 18:13:30,721 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 22 Jan 2024 00:13:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'user-lqvxa4hv7a8o8eyohtzmcoc6'), (b'openai-processing-ms', b'1046'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'248975'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'245ms'), (b'x-request-id', b'a6a472c251b7814576669b5dc1860f20'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84939764891244e2-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-21 18:13:30,722 - INFO - HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
2024-01-21 18:13:30,722 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-01-21 18:13:30,722 - DEBUG - receive_response_body.complete
2024-01-21 18:13:30,722 - DEBUG - response_closed.started
2024-01-21 18:13:30,722 - DEBUG - response_closed.complete
2024-01-21 18:13:30,722 - DEBUG - HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
2024-01-21 18:13:30,723 - INFO - Received response from OpenAI: 

@startuml

class PrintResponse {
    - response: Object
    + print(response) : void
}

class SaveToFile {
    - output_dir: String
    - output_file: Object
    - response: Object

    + saveToFile(response) : void
}

class Log {
    + log(message) : void
}

PrintResponse --> SaveToFile
SaveToFile --> Log

@enduml
2024-01-21 18:13:30,723 - INFO - UML code generated for src/scripts/execute_generate_uml.py: @startuml
title execute_generate_uml.py
rrent_dir, 'config.json')

@startuml
Class Importer {
    - json
    - os
    - requests
    - logging
    - load_dotenv
    - log_handler
    - log_formatter
    - logger
    - current_dir
    - config_file_path

    + LoadEnvVariables() 
    + ConfigureLogging() 
    + __init__()
}

Class LoadEnvVariables {
    - dotenv 

    + loadDotEnv()
}

Class ConfigureLogging {
    - os
    - handlers
    - log_directory
    - log_filename
    - log_handler
    - log_formatter
    - logger
    - level

    + __init__()
    + setLogFile()
    + setFormatter()
    + setLevel()
}

Class CurrentDirectory {
    - os
    - absPath

    + __init__()
    + getCurrentDirectory()
}

Class ConfigurationFile {
    - os
    - current_dir
    - fileName

    + __init__()
    + getPath()
}

Class LogDirectory {
    - os
    - parent_dir
    - directory

    + __init__()
    + makeDirectory()
}

Importer --> LoadEnvVariables
Importer --> ConfigureLogging
Importer --> CurrentDirectory
Importer --> ConfigurationFile
LoadEnvVariables --> dotenv
ConfigureLogging --> os
ConfigureLogging --> handlers
ConfigureLogging --> logger
CurrentDirectory --> os
CurrentDirectory --> absPath
ConfigurationFile --> os
ConfigurationFile --> current_dir
ConfigurationFile --> fileName
LogDirectory --> os
LogDirectory --> parent_dir
LogDirectory --> directory

@endumlWrite the response to a file
    with open(os.path.join(current_dir, 'uml_diagram.png'), 'wb') as uml_file:
        uml_file.write(response.content)

except requests.exceptions.RequestException as e:
    logging.error(f'An error occurred while making the request: {e}')

@startuml

class UMLCreator {
    - current_dir: string
    - config_file_path: string
    - config_data: json
    - github_token: string
    - url: string
    - headers: dict

    + UMLCreator(current_dir, config_file_path)

    + read_config()
    + get_github_token()
    + generate_diagram()
}

UMLCreator --right--> JSONConverter
UMLCreator --down--> GithubTokenRetriever
UMLCreator --down--> HttpRequester
class JSONConverter {
    + convert_to_json()
}
class GithubTokenRetriever {
    + retrieve_token()
    - github_token: string
}

class HttpRequester {
    + send_post_request()
    + set_url()
    + set_headers()
    - url: string
    - headers: dict
}

@enduml@startuml

class PrintResponse {
    - response: Object
    + print(response) : void
}

class SaveToFile {
    - output_dir: String
    - output_file: Object
    - response: Object

    + saveToFile(response) : void
}

class Log {
    + log(message) : void
}

PrintResponse --> SaveToFile
SaveToFile --> Log

@enduml
2024-01-21 18:13:30,723 - INFO - Saving generated output to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 18:13:30,724 - INFO - Generated output saved to /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 18:13:30,724 - INFO - Generated file paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 18:13:30,724 - INFO - Final output paths: ['/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml', '/Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml']
2024-01-21 18:13:30,724 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/code_to_uml.py.puml
2024-01-21 18:13:30,724 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/retrieve_code.py.puml
2024-01-21 18:13:30,724 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/uml_from_repo.py.puml
2024-01-21 18:13:30,724 - INFO - UML diagram saved at: /Users/preston/Documents/gitRepos/diagrammr/src/scripts/../../output/execute_generate_uml.py.puml
2024-01-21 18:13:30,724 - INFO - Cleaning up temporary directory
2024-01-21 18:13:30,890 - INFO - 127.0.0.1 - - [21/Jan/2024 18:13:30] "POST /generate-uml HTTP/1.1" 200 -
